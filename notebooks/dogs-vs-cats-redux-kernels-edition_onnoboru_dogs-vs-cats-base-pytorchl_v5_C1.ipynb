{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f24fb49f",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from pathlib import Path"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cb46b2e5",
   "metadata": {},
   "outputs": [],
   "source": [
    "!pip install lightning\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "de2d9511",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import gc\n",
    "import re\n",
    "import sys\n",
    "import time\n",
    "import copy\n",
    "import random \n",
    "import glob \n",
    "import zipfile\n",
    "import shutil\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "from torch.utils.data import DataLoader, Dataset\n",
    "\n",
    "import lightning.pytorch as pl  \n",
    "from lightning.pytorch import seed_everything\n",
    "from lightning.pytorch.callbacks import ModelCheckpoint, EarlyStopping\n",
    "\n",
    "import timm\n",
    "import albumentations as A\n",
    "from albumentations.pytorch import ToTensorV2   \n",
    "from PIL import Image\n",
    "\n",
    "import transformers\n",
    "\n",
    "from tqdm import tqdm\n",
    "from sklearn.metrics import log_loss, accuracy_score, roc_auc_score\n",
    "from sklearn.model_selection import KFold\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")\n",
    "\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "print(device)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2a026694",
   "metadata": {},
   "outputs": [],
   "source": [
    "class CFG :\n",
    "    debug_one_epoch = True\n",
    "    debug_one_fold = False\n",
    "    only_infer = False\n",
    "    num_workers = 16\n",
    "    batch_size = 64\n",
    "    num_epochs = 10\n",
    "    lr = 1e-3\n",
    "    early_stopping_round = 5\n",
    "    warmup_prop = 0.1\n",
    "    random_seed = 42\n",
    "    n_splits = 5\n",
    "    model_name = \"resnet18\" # timm で使うモデル名\n",
    "    pretrained_path = None\n",
    "    train_dir = None # 学習データセットのパス\n",
    "    test_dir = None # テストデータセットのパス\n",
    "    optimizer = torch.optim.AdamW\n",
    "    criterion = nn.BCEWithLogitsLoss()\n",
    "    scheduler = transformers.get_linear_schedule_with_warmup\n",
    "    input_imgsize = 224\n",
    "    data_dir = \"../input/dogs-vs-cats-redux-kernels-edition/\"\n",
    "    kaggle_working_dir = \"/kaggle/working/\"\n",
    "    \n",
    "def seed_torch(seed):\n",
    "    random.seed(seed)\n",
    "    os.environ['PYTHONHASHSEED'] = str(seed)\n",
    "    np.random.seed(seed)\n",
    "    torch.manual_seed(seed)\n",
    "    torch.cuda.manual_seed(seed)\n",
    "    torch.backends.cudnn.deterministic = True\n",
    "    \n",
    "seed_torch(CFG.random_seed)\n",
    "\n",
    "if  CFG.debug_one_epoch :\n",
    "    CFG.num_epochs = 1\n",
    "\n",
    "print('KAGGLE_URL_BASE' in set(os.environ.keys()))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dd4c0830",
   "metadata": {},
   "outputs": [],
   "source": [
    "submission = pd.read_csv(os.path.join(CFG.data_dir, \"sample_submission.csv\"))\n",
    "if 'KAGGLE_URL_BASE' in set(os.environ.keys()) :\n",
    "    kaggle_train_dir = os.path.join(CFG.kaggle_working_dir, \"train\")\n",
    "    # すでに解凍されている場合は解凍しない\n",
    "    if not os.path.exists(kaggle_train_dir) :\n",
    "        shutil.unpack_archive(os.path.join(CFG.data_dir, \"train.zip\"), CFG.kaggle_working_dir)\n",
    "    \n",
    "    kaggle_test_dir = os.path.join(CFG.kaggle_working_dir, \"test\")\n",
    "    if not os.path.exists(kaggle_test_dir) :\n",
    "        shutil.unpack_archive(os.path.join(CFG.data_dir, \"test.zip\"), CFG.kaggle_working_dir)\n",
    "        \n",
    "    CFG.data_dir = CFG.kaggle_working_dir\n",
    "    \n",
    "CFG.train_dir = os.path.join(CFG.data_dir, \"train\")\n",
    "CFG.test_dir = os.path.join(CFG.data_dir, \"test\")\n",
    "\n",
    "train_list = glob.glob(os.path.join(CFG.data_dir, \"train\", \"*.jpg\"))\n",
    "test_list = glob.glob(os.path.join(CFG.data_dir, \"test\", \"*.jpg\"))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e20f604f",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_df = pd.DataFrame(train_list, columns=[\"path\"])\n",
    "train_df[\"class\"] = train_df[\"path\"].apply(lambda x : x.split(\"/\")[-1].split(\".\")[0])\n",
    "train_df[\"class\"] = train_df[\"class\"].map({\"dog\" : 1, \"cat\" : 0})\n",
    "test_df = pd.DataFrame(test_list, columns=[\"path\"])\n",
    "test_df[\"class\"] = -1\n",
    "# test_df に対しては path の数字が昇順であることを保証するために id を追加\n",
    "test_df[\"id\"] = test_df[\"path\"].apply(lambda x : int(x.split(\"/\")[-1].split(\".\")[0]))\n",
    "test_df = test_df.sort_values(\"id\").reset_index(drop=True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9bb9f490",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_transform = A.Compose([\n",
    "    A.Resize(CFG.input_imgsize, CFG.input_imgsize),\n",
    "    A.HorizontalFlip(p=0.5), # 50% の確率で水平反転\n",
    "    A.Normalize(),\n",
    "    ToTensorV2()\n",
    "])\n",
    "test_transform = A.Compose([\n",
    "    A.Resize(CFG.input_imgsize, CFG.input_imgsize),\n",
    "    A.Normalize(),\n",
    "    ToTensorV2()\n",
    "])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "121eb457",
   "metadata": {},
   "outputs": [],
   "source": [
    "class DogsCatsDataset(Dataset) :\n",
    "    def __init__(self, df, transform=None) :\n",
    "        self.df = df # さっきの pandas dataframe を受け取る\n",
    "        self.transform = transform # 画像の変換処理を受け取る\n",
    "\n",
    "    def __len__(self) :\n",
    "        return len(self.df)\n",
    "    \n",
    "    def __getitem__(self, idx) :\n",
    "        img = Image.open(self.df.iloc[idx, 0])\n",
    "        img = self.transform(image = np.array(img))[\"image\"]\n",
    "        label = self.df.iloc[idx, 1].astype(np.float32)\n",
    "        return img, label\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "293aa5ad",
   "metadata": {},
   "outputs": [],
   "source": [
    "class DogCatModel(nn.Module) :\n",
    "    def __init__(self) :\n",
    "        super(DogCatModel, self).__init__()\n",
    "        self.model = timm.create_model(CFG.model_name, pretrained=True, num_classes=1)\n",
    "        \n",
    "    def forward(self, x) :\n",
    "        return self.model(x)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2b4efb17",
   "metadata": {},
   "outputs": [],
   "source": [
    "class dog_vs_cats_pl_model(pl.LightningModule) :\n",
    "    def __init__(self, model) :\n",
    "        super(dog_vs_cats_pl_model, self).__init__()\n",
    "        self.model = model\n",
    "        self.criterion = CFG.criterion\n",
    "        \n",
    "    def forward(self, x) :\n",
    "        return self.model(x)\n",
    "    \n",
    "    def training_step(self, batch, batch_idx) :\n",
    "        img, label = batch\n",
    "        output = self(img)\n",
    "        loss = self.criterion(output.squeeze(-1), label)\n",
    "        self.log(\"train_loss\", loss, on_step=True, on_epoch=True, prog_bar=True, logger=True)\n",
    "        return loss\n",
    "    \n",
    "    def validation_step(self, batch, batch_idx) :\n",
    "        img, label = batch\n",
    "        output = self(img)\n",
    "        loss = self.criterion(output.squeeze(-1), label)\n",
    "        self.log(\"valid_loss\", loss, on_step=True, on_epoch=True, prog_bar=True, logger=True)\n",
    "        return loss\n",
    "    \n",
    "    def predict_step(self, batch, batch_idx) :\n",
    "        img, _ = batch\n",
    "        output = self(img)\n",
    "        output = torch.sigmoid(output).cpu().numpy()\n",
    "        return output\n",
    "        \n",
    "    \n",
    "    def configure_optimizers(self) :\n",
    "        optimizer = CFG.optimizer(self.parameters(), lr=CFG.lr)\n",
    "        num_training_steps = len(self.train_dataloader)*CFG.num_epochs\n",
    "        num_warmup_steps = int(num_training_steps * CFG.warmup_prop)\n",
    "        scheduler = transformers.get_cosine_schedule_with_warmup(optimizer, num_warmup_steps=num_warmup_steps, num_training_steps=num_training_steps)\n",
    "        return [optimizer], [scheduler]\n",
    "    \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a54d2fc7",
   "metadata": {},
   "outputs": [],
   "source": [
    "def run_train_cv_pl(train, test):\n",
    "    kf = KFold(n_splits=CFG.n_splits, shuffle=True, random_state=CFG.random_seed)\n",
    "    oof = np.zeros((len(train), 1)) \n",
    "    predictions =[]\n",
    "    \n",
    "    for fold, (train_idx, valid_idx) in enumerate(kf.split(train)) :\n",
    "        print(f\"====================fold : {fold}====================\")\n",
    "        train_df = train.iloc[train_idx].reset_index(drop=True)\n",
    "        valid_df = train.iloc[valid_idx].reset_index(drop=True)\n",
    "        \n",
    "        train_dataset = DogsCatsDataset(train_df, transform=train_transform)\n",
    "        valid_dataset = DogsCatsDataset(valid_df, transform=test_transform)\n",
    "        test_dataset = DogsCatsDataset(test_df, transform=test_transform)\n",
    "        \n",
    "        train_loader = DataLoader(train_dataset, batch_size=CFG.batch_size, shuffle=True, num_workers=CFG.num_workers, drop_last=True, pin_memory=True)\n",
    "        valid_loader = DataLoader(valid_dataset, batch_size=CFG.batch_size, shuffle=False, num_workers=CFG.num_workers)\n",
    "        test_loader = DataLoader(test_dataset, batch_size=CFG.batch_size, shuffle=False, num_workers=CFG.num_workers)\n",
    "        \n",
    "        model = DogCatModel()\n",
    "        lightning_model = dog_vs_cats_pl_model(model)\n",
    "        lightning_model.train_dataloader = train_loader\n",
    "        lightning_model.valid_dataloader = valid_loader\n",
    "\n",
    "        early_stopping = EarlyStopping(\n",
    "            monitor=\"valid_loss\",\n",
    "            mode=\"min\", \n",
    "            patience=CFG.early_stopping_round,\n",
    "        )\n",
    "        checkpoint = ModelCheckpoint(\n",
    "            monitor=\"valid_loss\", \n",
    "            mode=\"min\", \n",
    "            dirpath=\"checkpoints\", \n",
    "            filename=f\"{CFG.model_name}_fold{fold}\", \n",
    "            save_top_k=1,\n",
    "        )\n",
    "        seed_everything(CFG.random_seed)\n",
    "        logger = pl.loggers.TensorBoardLogger(\"logs\", name=f\"{CFG.model_name}_fold{fold}\")\n",
    "        trainer = pl.Trainer(max_epochs=CFG.num_epochs, accelerator=\"gpu\", precision=16, logger=logger, callbacks=[early_stopping, checkpoint])\n",
    "        trainer.fit(lightning_model, train_loader, valid_loader)\n",
    "\n",
    "        # best_model = DogCatModel()\n",
    "        # best_model.load_state_dict(torch.load(os.path.join(\"checkpoints\", f\"{CFG.model_name}_fold{fold}.ckpt\"))[\"state_dict\"])\n",
    "        # best_model.eval()\n",
    "        \n",
    "        valid_preds_list = trainer.predict(lightning_model, valid_loader)\n",
    "        valid_preds_arr = np.concatenate(valid_preds_list)\n",
    "        oof[valid_idx] = valid_preds_arr\n",
    "        \n",
    "        test_preds_list = trainer.predict(lightning_model, test_loader)\n",
    "        test_preds_arr = np.concatenate(test_preds_list)\n",
    "        predictions.append(test_preds_arr)\n",
    "        \n",
    "        del model, lightning_model, trainer\n",
    "        gc.collect()\n",
    "        torch.cuda.empty_cache()\n",
    "        \n",
    "        if CFG.debug_one_fold :\n",
    "            break\n",
    "\n",
    "    predictions = np.mean(predictions, axis=0)\n",
    "    return {\n",
    "        \"oof\" : oof,\n",
    "        \"predictions\" : predictions\n",
    "    }\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "56e50e4f",
   "metadata": {},
   "outputs": [],
   "source": [
    "def main() :\n",
    "    if CFG.only_infer :\n",
    "        test_dataset = DogsCatsDataset(test_df, transform=test_transform)\n",
    "        test_loader = DataLoader(test_dataset, batch_size=CFG.batch_size, shuffle=False, num_workers=CFG.num_workers)\n",
    "        model = DogCatModel()\n",
    "        lightning_model = dog_vs_cats_pl_model(model)\n",
    "        predictions = []\n",
    "        for fold in range(CFG.n_splits) :\n",
    "            model = lightning_model.load_from_checkpoint(f\"checkpoints/{CFG.model_name}_fold{fold}.ckpt\")\n",
    "            trainer = pl.Trainer(accelerator=\"gpu\", precision=16, logger=False)\n",
    "            predictions.append(trainer.predict(model, test_loader))\n",
    "        submission[\"label\"] = np.mean(predictions, axis=0)\n",
    "        submission.to_csv(\"submission.csv\", index=False)\n",
    "        \n",
    "    else :\n",
    "        result = run_train_cv_pl(train_df, test_df)\n",
    "        oof_preds = result[\"oof\"]\n",
    "        predictions = result[\"predictions\"]\n",
    "        submission[\"label\"] = predictions\n",
    "        submission.to_csv(\"submission.csv\", index=False)\n",
    "        train_df[\"oof_preds\"] = oof_preds   \n",
    "        train_df.to_csv(\"oof_preds.csv\", index=False)\n",
    "        if CFG.debug_one_fold == False :\n",
    "            print(f\"oof log loss : {log_loss(train_df['class'], oof_preds)}\")\n",
    "        \n",
    "if __name__ == \"__main__\" :\n",
    "    main()\n"
   ]
  }
 ],
 "metadata": {},
 "nbformat": 4,
 "nbformat_minor": 5
}

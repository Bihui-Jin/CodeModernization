{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ec861187",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from pathlib import Path"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c865f67b",
   "metadata": {},
   "outputs": [],
   "source": [
    "tez_path = '../input/tez-lib/'\n",
    "effnet_path = '../input/efficientnet-pytorch/'\n",
    "import sys\n",
    "sys.path.append(tez_path)\n",
    "sys.path.append(effnet_path)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "eb711a89",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import albumentations\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "import tez\n",
    "from tez.datasets import ImageDataset\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "from torch.nn import functional as F\n",
    "\n",
    "from efficientnet_pytorch import EfficientNet\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2a4540af",
   "metadata": {},
   "outputs": [],
   "source": [
    "INPUT_PATH = \"../input/ranzcr-clip-catheter-line-classification/\"\n",
    "IMAGE_PATH = \"../input/ranzcr-clip-catheter-line-classification/test/\"\n",
    "MODEL_PATH = \"../input/ranzcr-effnet5/\"\n",
    "IMAGE_SIZE = 512\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4f0ceea9",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv(os.path.join(INPUT_PATH, \"sample_submission.csv\"))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "de6f64d8",
   "metadata": {},
   "outputs": [],
   "source": [
    "class RanzcrModel(tez.Model):\n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "\n",
    "        self.effnet = EfficientNet.from_name(\"efficientnet-b5\")\n",
    "\n",
    "        self.effnet._conv_stem.in_channels = 1\n",
    "        weight = self.effnet._conv_stem.weight.mean(1, keepdim=True)\n",
    "        self.effnet._conv_stem.weight = torch.nn.Parameter(weight)\n",
    "\n",
    "        self.dropout = nn.Dropout(0.1)\n",
    "        self.out = nn.Linear(2048, 11)\n",
    "\n",
    "    def forward(self, image, targets=None):\n",
    "        batch_size, _, _, _ = image.shape\n",
    "\n",
    "        x = self.effnet.extract_features(image)\n",
    "        x = F.adaptive_avg_pool2d(x, 1).reshape(batch_size, -1)\n",
    "        outputs = self.out(self.dropout(x))\n",
    "        return outputs, None, {}\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a8ced9fd",
   "metadata": {},
   "outputs": [],
   "source": [
    "test_aug = albumentations.Compose(\n",
    "    [\n",
    "        albumentations.Resize(IMAGE_SIZE, IMAGE_SIZE, p=1.0),\n",
    "        albumentations.Normalize(\n",
    "            mean=[0.485],\n",
    "            std=[0.229],\n",
    "            max_pixel_value=255.0,\n",
    "            p=1.0,\n",
    "        ),\n",
    "    ],\n",
    "    p=1.0,\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "16bc7422",
   "metadata": {},
   "outputs": [],
   "source": [
    "test_image_paths = [\n",
    "    os.path.join(IMAGE_PATH, x + \".jpg\") \n",
    "    for x in df.StudyInstanceUID.values\n",
    "]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bdf97a02",
   "metadata": {},
   "outputs": [],
   "source": [
    "test_dataset = ImageDataset(\n",
    "    image_paths=test_image_paths,\n",
    "    targets=[0]*len(test_image_paths),\n",
    "    augmentations=test_aug,\n",
    "    grayscale=True,\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "baeebdc5",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = RanzcrModel()\n",
    "model.load(os.path.join(MODEL_PATH, \"effnet5_fold_0.bin\"))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4f6f9468",
   "metadata": {},
   "outputs": [],
   "source": [
    "preds = model.predict(\n",
    "    test_dataset, batch_size=32, n_jobs=-1, device=\"cuda\"\n",
    ")\n",
    "temp_preds = None\n",
    "for p in preds:\n",
    "    if temp_preds is None:\n",
    "        temp_preds = p\n",
    "    else:\n",
    "        temp_preds = np.vstack((temp_preds, p))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "559bf3f9",
   "metadata": {},
   "outputs": [],
   "source": [
    "target_cols = df.columns[1:]\n",
    "\n",
    "for i in range(temp_preds.shape[1]):\n",
    "    df.loc[:, target_cols[i]] = temp_preds[:, i]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6de45099",
   "metadata": {},
   "outputs": [],
   "source": [
    "df.to_csv('submission.csv', index=False)\n",
    "df.head()\n"
   ]
  }
 ],
 "metadata": {},
 "nbformat": 4,
 "nbformat_minor": 5
}

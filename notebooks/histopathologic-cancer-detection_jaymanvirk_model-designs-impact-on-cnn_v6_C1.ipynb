{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7ba77658",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from pathlib import Path"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7194ae88",
   "metadata": {},
   "outputs": [],
   "source": [
    "# basics\n",
    "import os\n",
    "import time\n",
    "import numpy as np\n",
    "\n",
    "# EDA\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "\n",
    "# Data preprocessing\n",
    "import tensorflow as tf\n",
    "import tensorflow_io as tfio\n",
    "from sklearn.utils import resample\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "# Convolutional neural network\n",
    "from keras.models import Sequential\n",
    "from tensorflow.keras import layers, models\n",
    "from keras.layers import Conv2D, MaxPooling2D, Flatten, Dense\n",
    "from keras.optimizers import Adam\n",
    "\n",
    "# helper functions\n",
    "from PIL import Image\n",
    "from sklearn.metrics import roc_auc_score\n",
    "from tensorflow.keras.models import load_model\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c57b8a56",
   "metadata": {},
   "outputs": [],
   "source": [
    "input_dir = '/kaggle/input/histopathologic-cancer-detection'\n",
    "list_l = [os.path.join(input_dir, x) for x in os.listdir(input_dir)]\n",
    "list_l\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c6afe054",
   "metadata": {},
   "outputs": [],
   "source": [
    "sample_data = pd.read_csv(list_l[0])\n",
    "train_data = pd.read_csv(list_l[1])\n",
    "train_dir = list_l[3] + '/'\n",
    "test_dir = list_l[2] + '/'\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9d41bdfa",
   "metadata": {},
   "outputs": [],
   "source": [
    "def print_short_summary(name, data):\n",
    "    \"\"\"\n",
    "    Prints data head, shape and info.\n",
    "    Args:\n",
    "        name (str): name of dataset\n",
    "        data (dataframe): dataset in a pd.DataFrame format\n",
    "    \"\"\"\n",
    "    print(name)\n",
    "    print('\\n1. Data head:')\n",
    "    print(data.head())\n",
    "    print('\\n2. Data shape: {}'.format(data.shape))\n",
    "    print('\\n3. Data info:')\n",
    "    data.info()\n",
    "    \n",
    "def print_number_files(dirpath):\n",
    "    print('{}: {} files'.format(dirpath, len(os.listdir(dirpath))))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e484d571",
   "metadata": {},
   "outputs": [],
   "source": [
    "print_short_summary('Train data', train_data)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8c752a6e",
   "metadata": {},
   "outputs": [],
   "source": [
    "print_short_summary('Sample data', sample_data)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "068fafa8",
   "metadata": {},
   "outputs": [],
   "source": [
    "print_number_files(train_dir)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cde20682",
   "metadata": {},
   "outputs": [],
   "source": [
    "print_number_files(test_dir)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d0fd52f3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plot horizontal barplot of number of records per label\n",
    "plt.figure(figsize=(16, 9))\n",
    "tmp = train_data['label'].value_counts()\n",
    "sns.barplot(y=['No Cancer', 'Cancer'], x=tmp.values, orient='h')\n",
    "plt.xlabel('Number of records')\n",
    "plt.ylabel('Label')\n",
    "plt.title('Number of records per label')\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "39f1bf35",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_images_to_plot(file_names):\n",
    "    \"\"\"\n",
    "    Returns list of images\n",
    "    Args:\n",
    "        file_names: list of filenames\n",
    "    Returns:\n",
    "        list of image objects\n",
    "    \"\"\"\n",
    "    return [Image.open(f) for f in file_names]\n",
    "\n",
    "def get_image_label(dirname, data, labels, n = 5):\n",
    "    dict_img = {}\n",
    "    for l in labels:\n",
    "        indexes = data['label'] == l\n",
    "        tmp = data[indexes][:n]\n",
    "        tmp = dirname + tmp['id'] + '.tif'\n",
    "        tmp = tmp.values\n",
    "        tmp = get_images_to_plot(tmp)\n",
    "        dict_img[l] = tmp\n",
    "        \n",
    "    return dict_img\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d5a6b692",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Print original image size\n",
    "img_path = train_dir + train_data['id'][0] + '.tif'\n",
    "img = Image.open(img_path)\n",
    "print('Original image size: {}'.format(img.size))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f050a9e3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get 5 filenames per label\n",
    "data = get_image_label(train_dir,train_data, [0,1])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "69964274",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Initialize subplots with 2 rows and 5 columns\n",
    "fig, axes = plt.subplots(nrows=2, ncols=5, figsize=(16, 9))\n",
    "\n",
    "# Loop through the selected images and display in the respective rows\n",
    "labels = ['No Cancer', 'Cancer']\n",
    "for i in range(10):\n",
    "    row = i // 5\n",
    "    col = i % 5\n",
    "    axes[row, col].imshow(data[row][col])\n",
    "    axes[row, col].set_title(labels[row])\n",
    "    axes[row, col].axis('off')\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "68329750",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define sample size to train on in order to reduce runtime\n",
    "SAMPLE_SIZE = 0.2\n",
    "# Majority class\n",
    "no_cancer = train_data[train_data['label'] == 0]\n",
    "# Minority class\n",
    "cancer = train_data[train_data['label'] == 1]\n",
    "cancer = cancer[:int(SAMPLE_SIZE*len(cancer))]\n",
    "\n",
    "# Downsample majority class to match minority class\n",
    "no_cancer_downsampled = resample(no_cancer,\n",
    "                              replace=False, \n",
    "                              n_samples=len(cancer),\n",
    "                              random_state=0)\n",
    "\n",
    "balanced_train_data = pd.concat([no_cancer_downsampled, cancer])\n",
    "\n",
    "# Shuffle train data for training\n",
    "balanced_train_data = balanced_train_data.sample(frac=1, random_state=0).reset_index(drop=True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dc747411",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get full path to image including extension\n",
    "image_paths = train_dir + balanced_train_data['id'] + '.tif'\n",
    "image_paths = image_paths.values\n",
    "\n",
    "labels = balanced_train_data['label'].values\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(image_paths\n",
    "                                                    , labels\n",
    "                                                    , test_size = 0.25\n",
    "                                                    , shuffle = True\n",
    "                                                    , random_state = 0)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "180c34cb",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_decoded_image(image_path, label=None):\n",
    "    \"\"\"\n",
    "    Load and preprocess images using TensorFlow I/O.\n",
    "    Decode image with 4 channels RGBA.\n",
    "    Resize image to 32x32px.\n",
    "    Scale pixels from 0 to 1.\n",
    "    Args:\n",
    "        image_path: path to TIFF image\n",
    "        label (optional): true label from train data\n",
    "    Returns:\n",
    "        (img, label): for train data\n",
    "        img: for test data\n",
    "    \"\"\"\n",
    "    img = tf.io.read_file(image_path)\n",
    "    img = tfio.experimental.image.decode_tiff(img)\n",
    "    img = tf.image.resize(img, [32, 32])\n",
    "    img = tf.cast(img, tf.float32) / 255.0\n",
    "    \n",
    "    return img if label is None else (img, label)\n",
    "\n",
    "def get_prefetched_data(data, batch_size, buffer_size):\n",
    "    \"\"\"\n",
    "    Create a TensorFlow dataset from image paths and labels.\n",
    "    Execution in parallel.\n",
    "    Load, preprocess images, shuffle and batch the data.\n",
    "    Prefetch batches to improve training performance.\n",
    "    Args:\n",
    "        data (tuple): image paths and corresponding labels\n",
    "        batch_size (int): number of samples per batch\n",
    "        buffer_size (int): number of elements from the dataset to buffer while shuffling\n",
    "    Returns:\n",
    "        tf.data.Dataset: preprocessed and preloaded TensorFlow dataset for keras CNN\n",
    "    \"\"\"\n",
    "    # Autotune the degree of parallelism during training\n",
    "    AUTOTUNE = tf.data.experimental.AUTOTUNE\n",
    "    \n",
    "    # Create dataset from image paths and labels\n",
    "    dataset = tf.data.Dataset.from_tensor_slices(data)\n",
    "\n",
    "    # Apply parallel processing to load and preprocess images\n",
    "    dataset = dataset.map(get_decoded_image, num_parallel_calls=AUTOTUNE)\n",
    "    dataset = dataset.shuffle(buffer_size=buffer_size)\n",
    "    dataset = dataset.batch(batch_size)\n",
    "    dataset = dataset.prefetch(buffer_size=AUTOTUNE)\n",
    "    \n",
    "    return dataset\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "55581809",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get train and test datasets for optimal performance\n",
    "BATCH_SIZE = 64\n",
    "TRAIN_BUFFER_SIZE = X_train.shape[0]\n",
    "TEST_BUFFER_SIZE = X_test.shape[0]\n",
    "\n",
    "train_dataset = get_prefetched_data((X_train, y_train)\n",
    "                                    , BATCH_SIZE\n",
    "                                    , TRAIN_BUFFER_SIZE)\n",
    "test_dataset = get_prefetched_data((X_test, y_test)\n",
    "                                   , BATCH_SIZE\n",
    "                                   , TEST_BUFFER_SIZE)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e1e9a253",
   "metadata": {},
   "outputs": [],
   "source": [
    "def roc_auc_score_(y_true, y_pred):\n",
    "    \"\"\"\n",
    "    Calculate ROC AUC score using sklearn built-in function.\n",
    "    Used in a model.compile as a custom metric.\n",
    "    Args:\n",
    "        y_true: true labels\n",
    "        y_pred: predicted labels\n",
    "    Returns:\n",
    "        ROC AUC score (float)\n",
    "    \"\"\"\n",
    "    return tf.py_function(roc_auc_score, (y_true, y_pred), tf.float64)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "404cfbe1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define base CNN\n",
    "model_base = models.Sequential([\n",
    "    layers.Conv2D(32, (3, 3), activation='relu', input_shape=(32, 32, 4))\n",
    "    , layers.MaxPooling2D((2, 2))\n",
    "    \n",
    "    , layers.Conv2D(64, (3, 3), activation='relu')\n",
    "    , layers.MaxPooling2D((2, 2))\n",
    "    \n",
    "    , layers.Flatten()\n",
    "    \n",
    "    , layers.Dense(64, activation='relu')\n",
    "    , layers.Dense(128, activation='relu')\n",
    "    \n",
    "    , layers.Dense(1, activation='sigmoid')\n",
    "])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0b1bb75e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define CNN with dropout and batch normalization layers\n",
    "model_drop_bn = models.Sequential([\n",
    "    layers.Conv2D(32, (3, 3), activation='relu', input_shape=(32, 32, 4))\n",
    "    , layers.BatchNormalization()\n",
    "    , layers.MaxPooling2D((2, 2))\n",
    "    \n",
    "    , layers.Conv2D(64, (3, 3), activation='relu')\n",
    "    , layers.BatchNormalization()\n",
    "    , layers.MaxPooling2D((2, 2))\n",
    "    \n",
    "    , layers.Flatten()\n",
    "    \n",
    "    , layers.Dense(64, activation='relu')\n",
    "    , layers.Dense(128, activation='relu')\n",
    "    \n",
    "    , layers.Dropout(0.25)\n",
    "    \n",
    "    , layers.Dense(1, activation='sigmoid')\n",
    "])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dcc20301",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define CNN with tuned hyperparameters\n",
    "model_tuned = models.Sequential([\n",
    "    layers.Conv2D(64, (3, 3), activation='relu', input_shape=(32, 32, 4))\n",
    "    , layers.BatchNormalization()\n",
    "    , layers.MaxPooling2D((2, 2), strides = (1,1))\n",
    "    \n",
    "    , layers.Conv2D(128, (3, 3), activation='relu')\n",
    "    , layers.BatchNormalization()\n",
    "    , layers.MaxPooling2D((2, 2), strides = (1,1))\n",
    "    \n",
    "    , layers.Flatten()\n",
    "    \n",
    "    , layers.Dense(64, activation='relu')\n",
    "    , layers.Dense(128, activation='relu')\n",
    "    \n",
    "    , layers.Dropout(0.3)\n",
    "    \n",
    "    , layers.Dense(1, activation='sigmoid')\n",
    "])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2d4b65e8",
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_model_scores(scores, model_name):\n",
    "    \"\"\"\n",
    "    Plot train and test ROC AUC scores of a model by epoch\n",
    "    \"\"\"\n",
    "    train_scores, test_scores = scores\n",
    "    epochs = range(1, len(train_scores) + 1)\n",
    "\n",
    "    # Plot train and test scores\n",
    "    plt.figure(figsize=(16, 9))\n",
    "    plt.plot(epochs, train_scores, label='Train score')\n",
    "    plt.plot(epochs, test_scores, label='Test score')\n",
    "    plt.title('Train and test ROC AUC scores of {}'.format(model_name))\n",
    "    plt.xlabel('Epoch')\n",
    "    plt.ylabel('ROC AUC Score')\n",
    "    plt.legend()\n",
    "    plt.grid(True)\n",
    "    plt.show()\n",
    "\n",
    "    \n",
    "def get_model_results(model_name, model):\n",
    "    \"\"\"\n",
    "    Return tuple of runtime, train and test scores.\n",
    "    Compile, fit and save model along the way.\n",
    "    Args:\n",
    "        model_name: model name\n",
    "        model: fitted model\n",
    "    Returns:\n",
    "        (runtime, (train_scores, test_scores) )\n",
    "    \"\"\"\n",
    "    st = time.time()\n",
    "    model.compile(optimizer='adam',\n",
    "              loss='binary_crossentropy',\n",
    "              metrics=[roc_auc_score_])\n",
    "    model.fit(train_dataset, epochs=5, validation_data=test_dataset)\n",
    "    runtime = time.time() - st\n",
    "    model.save('{}.h5'.format(model_name))\n",
    "    train_scores = model.history.history['roc_auc_score_']\n",
    "    test_scores = model.history.history['val_roc_auc_score_']\n",
    "    del model\n",
    "    \n",
    "    return (runtime, (train_scores, test_scores))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "309c8bce",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get train and test scores of every epoch\n",
    "runtime_base, scores_base = get_model_results('base', model_base)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b2a293c2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plot scores\n",
    "plot_model_scores(scores_base)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "be33dc05",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get train and test scores of every epoch\n",
    "runtime_drop_bn, scores_drop_bn = get_model_results('drop_bn', model_drop_bn)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "808baeef",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plot scores\n",
    "plot_model_scores(scores_drop_bn)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e99097b2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get train and test scores of every epoch\n",
    "runtime_tuned, scores_tuned = get_model_results('tuned', model_tuned)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5ff6e2d0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plot scores\n",
    "plot_model_scores(scores_tuned)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4ad77d1b",
   "metadata": {},
   "outputs": [],
   "source": [
    "table = [\n",
    "    {\n",
    "        'model':'Base'\n",
    "        , 'sample_size': SAMPLE_SIZE\n",
    "        , 'runtime': runtime_base\n",
    "        , 'train_roc_auc_score': scores_base[0][-1]\n",
    "        , 'test_roc_auc_score': scores_base[1][-1]\n",
    "    }\n",
    "    ,{\n",
    "        'model':'Drop and BN'\n",
    "        , 'sample_size': SAMPLE_SIZE\n",
    "        , 'runtime': runtime_drop_bn\n",
    "        , 'train_roc_auc_score': scores_drop_bn[0][-1]\n",
    "        , 'test_roc_auc_score': scores_drop_bn[1][-1]\n",
    "    }\n",
    "    ,{\n",
    "        'model':'Tuned'\n",
    "        , 'sample_size': SAMPLE_SIZE\n",
    "        , 'runtime': runtime_tuned\n",
    "        , 'train_roc_auc_score': scores_tuned[0][-1]\n",
    "        , 'test_roc_auc_score': scores_tuned[1][-1]\n",
    "    }\n",
    "]\n",
    "\n",
    "pd.DataFrame(table).sort_values(by = ['test_roc_auc_score','runtime']\n",
    "                                , ascending = [False, True])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3e4053af",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load save tuned model with custom metric parameter\n",
    "model_20 = load_model('drop_bn.h5'\n",
    "                           , custom_objects = {'roc_auc_score_': roc_auc_score_})\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0eebe963",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create prefethed dataset of images to classify\n",
    "submis_data = test_dir + sample_data['id'] + '.tif'\n",
    "submis_data = submis_data.values\n",
    "\n",
    "BATCH_SIZE = 64\n",
    "SUBMIS_BUFFER_SIZE = submis_data.shape[0]\n",
    "\n",
    "submis_dataset = get_prefetched_data((submis_data)\n",
    "                                    , BATCH_SIZE\n",
    "                                    , SUBMIS_BUFFER_SIZE)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ed82e2c6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Set predictions to result_20\n",
    "result_20 = model_20.predict(submis_dataset)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0c75d683",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create table of ids and labels like sample_submission\n",
    "sample_data['label'] = np.ravel(np.round(result_20))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "32856d8a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Print submission table\n",
    "sample_data\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "52f72e2d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Make submission\n",
    "sample_data.to_csv('submission_20.csv', index=False)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e7a97fae",
   "metadata": {},
   "outputs": [],
   "source": [
    " \n"
   ]
  }
 ],
 "metadata": {},
 "nbformat": 4,
 "nbformat_minor": 5
}

{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "93dfaf48",
      "metadata": {},
      "outputs": [],
      "source": [
        "import pandas as pd\n",
        "from pathlib import Path"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "f190037f",
      "metadata": {},
      "outputs": [],
      "source": [
        "# This Python 3 environment comes with many helpful analytics libraries installed\n",
        "# It is defined by the kaggle/python docker image: https://github.com/kaggle/docker-python\n",
        "# For example, here's several helpful packages to load in \n",
        "\n",
        "import os\n",
        "import glob\n",
        "from pathlib import Path\n",
        "from PIL import Image\n",
        "import cv2\n",
        "\n",
        "# Python ≥3.5 is required\n",
        "import sys\n",
        "assert sys.version_info >= (3, 5)\n",
        "\n",
        "# Scikit-Learn ≥0.20 is required\n",
        "import sklearn\n",
        "assert sklearn.__version__ >= \"0.20\"\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.pipeline import make_pipeline\n",
        "from sklearn.preprocessing import MinMaxScaler\n",
        "\n",
        "# TensorFlow ≥2.0 is required\n",
        "import tensorflow as tf\n",
        "from tensorflow import keras\n",
        "assert tf.__version__ >= \"2.0\"\n",
        "from keras.models import Sequential, Model\n",
        "from keras.layers import Dense, Dropout, Flatten, Conv2D,MaxPooling2D, BatchNormalization, UpSampling2D, Input, ZeroPadding2D, Cropping2D\n",
        "from keras.preprocessing.image import load_img, array_to_img, img_to_array\n",
        "\n",
        "import numpy as np # linear algebra\n",
        "import pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\n",
        "\n",
        "# Visualization\n",
        "import matplotlib.pyplot as plt\n",
        "import seaborn as sns\n",
        "%matplotlib inline \n",
        "\n",
        "# to make this notebook's output stable across runs\n",
        "np.random.seed(42)\n",
        "tf.random.set_seed(42)\n",
        "\n",
        "# To plot pretty figures\n",
        "%matplotlib inline\n",
        "import matplotlib as mpl\n",
        "import matplotlib.pyplot as plt\n",
        "mpl.rc('axes', labelsize=14)\n",
        "mpl.rc('xtick', labelsize=12)\n",
        "mpl.rc('ytick', labelsize=12)\n",
        "\n",
        "# Input data files are available in the \"../input/\" directory.\n",
        "# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n",
        "\n",
        "for dirname, _, filenames in os.walk('/kaggle/input'):\n",
        "    for filename in filenames:\n",
        "        print(os.path.join(dirname, filename))\n",
        "\n",
        "# Any results you write to the current directory are saved as output.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "1d10b239",
      "metadata": {},
      "outputs": [],
      "source": [
        "# Define paths in the fancy way, after all we have pathlib now. No more os.path.join...whatever!!\n",
        "input_dir  = Path('/kaggle/input/denoising-dirty-documents')\n",
        "train = input_dir / 'train.zip'\n",
        "train_cleaned = input_dir / 'train_cleaned.zip'\n",
        "test = input_dir / 'test.zip'\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "e879aae0",
      "metadata": {},
      "outputs": [],
      "source": [
        "# importing required modules \n",
        "from zipfile import ZipFile \n",
        "\n",
        "def extract_zip_file(file_names):\n",
        "    # opening the zip file in READ mode \n",
        "    for file in file_names:\n",
        "        with ZipFile(file, 'r') as zip: \n",
        "            # printing all the contents of the zip file \n",
        "            # zip.printdir() \n",
        "\n",
        "            # extracting all the files \n",
        "            # print('Extracting all the files now...') \n",
        "            zip.extractall() \n",
        "            # print('Done!')\n",
        "\n",
        "# The train directory comtaims png files. Let's get all the files and check a few samples\n",
        "extract_zip_file([train, train_cleaned, test])\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "6bc54525",
      "metadata": {},
      "outputs": [],
      "source": [
        "train_images = sorted(glob.glob('train/*.png'))\n",
        "train_cleaned_images = sorted(glob.glob('train_cleaned/*.png'))\n",
        "test_images = sorted(glob.glob('test/*.png'))\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "196e3ad8",
      "metadata": {},
      "outputs": [],
      "source": [
        "def convert_imgs_to_array(images_folder, test=False):\n",
        "    images = []\n",
        "    \n",
        "    for img_dir in images_folder:\n",
        "        image = load_img(img_dir, color_mode='grayscale', target_size=(258,540,1))\n",
        "        image = img_to_array(image).astype('float32') / 255.0\n",
        "        images.append(image)\n",
        "        \n",
        "    return np.asarray(images)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "b8b69ae0",
      "metadata": {},
      "outputs": [],
      "source": [
        "X_train_full = convert_imgs_to_array(train_images)\n",
        "Y_train_full = convert_imgs_to_array(train_cleaned_images)\n",
        "X_test = convert_imgs_to_array(test_images)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "0fc2a3a8",
      "metadata": {},
      "outputs": [],
      "source": [
        "print(X_train_full.shape)\n",
        "print(Y_train_full.shape)\n",
        "print(X_test.shape)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "db462189",
      "metadata": {},
      "outputs": [],
      "source": [
        "X_train, x_val, Y_train, y_val = train_test_split(X_train_full, Y_train_full,\n",
        "                                                  test_size=0.3, random_state=42)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "26038356",
      "metadata": {},
      "outputs": [],
      "source": [
        "print(X_train.shape)\n",
        "print(x_val.shape)\n",
        "print(Y_train.shape)\n",
        "print(y_val.shape)\n",
        "print(X_test.shape)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "4b5feed2",
      "metadata": {},
      "outputs": [],
      "source": [
        "# plot random samples with keypoints from training\n",
        "def plot_documents(nrows=3, ncols=2):\n",
        "    selection = np.random.choice(len(X_train), size=(nrows*ncols), replace=False)\n",
        "    images = np.asarray(train_images)[selection]\n",
        "    cleaned_images = np.asarray(train_cleaned_images)[selection]\n",
        "    #images = X_train[selection]\n",
        "    #cleaned_images = Y_train[selection]\n",
        "    fig, axes = plt.subplots(figsize=(nrows*20, ncols*30), nrows=nrows, ncols=ncols)\n",
        "    fig.subplots_adjust(hspace = .05, wspace=.05)\n",
        "    axes = axes.ravel()\n",
        "    for img, img_cleaned, i in zip(images, cleaned_images, range(0, nrows*ncols, 2)):\n",
        "        axes[i].imshow(cv2.imread(img, cv2.IMREAD_GRAYSCALE), cmap='gray')\n",
        "        axes[i+1].imshow(cv2.imread(img_cleaned, cv2.IMREAD_GRAYSCALE), cmap='gray')\n",
        "        axes[i].axis('off')\n",
        "        axes[i+1].axis('off')\n",
        "        \n",
        "plot_documents()\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "daeb5931",
      "metadata": {},
      "outputs": [],
      "source": [
        "'''\n",
        "# CNN model architecture (all these parameters might be tuned to achieve better results)\n",
        "from functools import partial\n",
        "\n",
        "DefaultConv2D = partial(Conv2D, activation='relu', padding='SAME')\n",
        "\n",
        "model = Sequential([\n",
        "    # encoder\n",
        "    DefaultConv2D(filters=32, kernel_size=5, input_shape=[258,540,1]),\n",
        "    BatchNormalization(),\n",
        "    MaxPooling2D((2, 2)),\n",
        "    DefaultConv2D(filters=64, kernel_size=3),\n",
        "    BatchNormalization(),\n",
        "    MaxPooling2D((2, 2)),\n",
        "    # decoder\n",
        "    DefaultConv2D(filters=64, kernel_size=3),\n",
        "    BatchNormalization(),\n",
        "    UpSampling2D((2, 2)),\n",
        "    DefaultConv2D(filters=32, kernel_size=5),\n",
        "    BatchNormalization(),\n",
        "    UpSampling2D((2,2)),\n",
        "    DefaultConv2D(filters=1, kernel_size=5, activation='sigmoid')\n",
        "])\n",
        "\n",
        "# show model architecture\n",
        "model.summary()\n",
        "'''\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "79fd9699",
      "metadata": {},
      "outputs": [],
      "source": [
        "N, H, W = X_train.shape\n",
        "input_img = Input(shape=(H,W,1))  # adapt this if using `channels_first` image data format\n",
        "\n",
        "x = Conv2D(16, (3, 3), activation='relu', padding='same')(input_img)\n",
        "x = MaxPooling2D((2, 2), padding='same')(x)\n",
        "x = Conv2D(8, (3, 3), activation='relu', padding='same')(x)\n",
        "x = MaxPooling2D((2, 2), padding='same')(x)\n",
        "x = Conv2D(8, (3, 3), activation='relu', padding='same')(x)\n",
        "encoded = MaxPooling2D((2, 2), padding='same')(x)\n",
        "\n",
        "# at this point the representation is (4, 4, 8) i.e. 128-dimensional\n",
        "\n",
        "x = Conv2D(8, (3, 3), activation='relu', padding='same')(encoded)\n",
        "x = UpSampling2D((2, 2))(x)\n",
        "x = Conv2D(8, (3, 3), activation='relu', padding='same')(x)\n",
        "x = UpSampling2D((2, 2))(x)\n",
        "x = Conv2D(16, (3, 3), activation='relu')(x)\n",
        "x = UpSampling2D((2, 2))(x)\n",
        "decoded = Conv2D(1, (3, 3), activation='sigmoid', padding='same')(x)\n",
        "\n",
        "autoencoder = Model(input_img, decoded)\n",
        "autoencoder.compile(optimizer='adadelta', loss='binary_crossentropy')\n",
        "\n",
        "autoencoder.summary()\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "6696a762",
      "metadata": {},
      "outputs": [],
      "source": [
        "# Lets' define our autoencoder now\n",
        "def build_autoenocder():\n",
        "    input_img = Input(shape=(258,540,1), name='image_input')\n",
        "    \n",
        "    #enoder \n",
        "    #x = ZeroPadding2D((1,0))(input_img)\n",
        "    x = Conv2D(32, (3,3), activation='relu', padding='same', name='Conv1')(input_img)\n",
        "    x = MaxPooling2D((2,2), padding='same', name='pool1')(x)\n",
        "    #x = Conv2D(64, (3,3), activation='relu', padding='same', name='Conv2')(x)\n",
        "    #x = MaxPooling2D((2,2), padding='same', name='pool2')(x)\n",
        "    \n",
        "    #decoder\n",
        "    #x = Conv2D(64, (3,3), activation='relu', padding='same', name='Conv3')(x)\n",
        "    #x = UpSampling2D((2,2), name='upsample1')(x)\n",
        "    x = Conv2D(32, (3,3), activation='relu', padding='same', name='Conv4')(x)\n",
        "    x = UpSampling2D((2,2), name='upsample2')(x)\n",
        "    x = Conv2D(1, (3,3), activation='sigmoid', padding='same', name='Conv5')(x)\n",
        "    #x = Cropping2D((1,0))(x)\n",
        "    \n",
        "    #model\n",
        "    autoencoder = Model(inputs=input_img, outputs=x)\n",
        "    return autoencoder\n",
        "\n",
        "model = build_autoenocder()\n",
        "model.summary()\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "7ce6d9c6",
      "metadata": {},
      "outputs": [],
      "source": [
        "model.compile(optimizer='adam', loss='mse', metrics=['mae'])\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "09d9fb92",
      "metadata": {},
      "outputs": [],
      "source": [
        "# another method is to use LearningRateScheduler, reduce the learning rate by 10% every epoch\n",
        "# annealer = LearningRateScheduler(lambda x: 1e-3 * 0.9 ** x)\n",
        "K = keras.callbacks\n",
        "reduce_lr = K.ReduceLROnPlateau(monitor='val_mae', patience=7,\n",
        "                                             verbose=1, factor=0.1, min_lr=0.00001)\n",
        "\n",
        "early_stopping = K.EarlyStopping(monitor='val_mae', patience=20, restore_best_weights=True,\n",
        "                                 verbose=1, mode='auto')\n",
        "#checkpointer = K.ModelCheckpoint(filepath = 'best_model.hdf5', monitor='val_mae',\n",
        "                                 #verbose=1, save_weights_only=True)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "bffb9ab3",
      "metadata": {},
      "outputs": [],
      "source": [
        "# it is better to increase the batch size when the dataset is small\n",
        "epochs = 300\n",
        "batch_size = 8\n",
        "history = model.fit(X_train, Y_train, validation_data=(x_val, y_val),\n",
        "                   batch_size=batch_size, epochs=epochs, shuffle=True,\n",
        "                   callbacks=[reduce_lr, early_stopping])\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "563a4dcd",
      "metadata": {},
      "outputs": [],
      "source": [
        "final_loss, final_mae = model.evaluate(x_val, y_val, verbose=1)\n",
        "print(\"Final loss: {0:.4f}, final mae: {1:.4f}\".format(final_loss, final_mae))\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "a6f41f9b",
      "metadata": {},
      "outputs": [],
      "source": [
        "# Plot the loss and accuracy curves for training and validation \n",
        "fig, ax = plt.subplots(2,1)\n",
        "ax[0].plot(history.history['loss'], color='b', label=\"Training loss\")\n",
        "ax[0].plot(history.history['val_loss'], color='r', label=\"validation loss\",axes =ax[0])\n",
        "legend = ax[0].legend(loc='best', shadow=True)\n",
        "\n",
        "ax[1].plot(history.history['mae'], color='b', label=\"Training mae\")\n",
        "ax[1].plot(history.history['val_mae'], color='r',label=\"Validation mae\")\n",
        "legend = ax[1].legend(loc='best', shadow=True)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "30332207",
      "metadata": {},
      "outputs": [],
      "source": [
        "# plot random samples with keypoints from training\n",
        "def plot_documents_after_training(nrows=3, ncols=2):\n",
        "    selection = np.random.choice(len(X_test), size=(nrows*ncols), replace=False)\n",
        "    original_images = np.asarray(test_images)[selection]\n",
        "    tested_images = X_test[selection]\n",
        "    predicted_images = model.predict(tested_images)\n",
        "    fig, axes = plt.subplots(figsize=(nrows*20, ncols*30), nrows=nrows, ncols=ncols)\n",
        "    fig.subplots_adjust(hspace = .05, wspace=.05)\n",
        "    axes = axes.ravel()\n",
        "    for original_img, tested_img, predicted_img, i in zip(original_images, tested_images, predicted_images, range(0, nrows*ncols, 2)):\n",
        "        original_img = cv2.imread(original_img, cv2.IMREAD_GRAYSCALE)\n",
        "        axes[i].imshow(cv2.resize(tested_img, (original_img.shape[1],original_img.shape[0])), cmap='gray')\n",
        "        axes[i+1].imshow(cv2.resize(predicted_img, (original_img.shape[1],original_img.shape[0])), cmap='gray')\n",
        "        axes[i].axis('off')\n",
        "        axes[i+1].axis('off')\n",
        "        \n",
        "plot_documents_after_training()\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "d4269a2b",
      "metadata": {},
      "outputs": [],
      "source": [
        "# save the weights to prevent training every time you open the kernel\n",
        "model.save_weights(\"model.h5\")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "3977c0a9",
      "metadata": {},
      "outputs": [],
      "source": [
        "# after loading, you have to compile the model\n",
        "model.load_weights('/kaggle/input/denoising-dirty-documents2/model.h5')\n",
        "model.compile(optimizer='adam', loss='mse',\n",
        "             metrics=['mae'])\n",
        "\n",
        "final_loss, final_mae = model.evaluate(x_val, y_val, verbose=0)\n",
        "print(\"Final loss: {0:.4f}, final mae: {1:.4f}\".format(final_loss, final_mae))\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "d25ee24a",
      "metadata": {},
      "outputs": [],
      "source": [
        "results = model.predict(X_test)\n",
        "print(results.shape)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "30a8c9c1",
      "metadata": {},
      "outputs": [],
      "source": [
        "def split_numbers(s):\n",
        "    head = s.split('.')[0].split('/')[1]\n",
        "    return head\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "6fbb09be",
      "metadata": {},
      "outputs": [],
      "source": [
        "ids = []\n",
        "values = []\n",
        "\n",
        "for i, pred in enumerate(results):\n",
        "    img_dir = test_images[i]\n",
        "    img_id = split_numbers(img_dir)\n",
        "    img = cv2.imread(img_dir,cv2.IMREAD_GRAYSCALE)\n",
        "    pred = cv2.resize(pred, (img.shape[1], img.shape[0]))\n",
        "    for j in range(pred.shape[1]):\n",
        "        for k in range(pred.shape[0]):\n",
        "            values.append(pred[k][j].item())\n",
        "            ids.append(img_id + '_' + str(k+1) + '_' + str(j+1))\n",
        "    print(\"Processed: {}\".format(img_id))\n",
        "    print(pred.shape)      \n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "eef22d84",
      "metadata": {},
      "outputs": [],
      "source": [
        "len(ids)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "ab256b65",
      "metadata": {},
      "outputs": [],
      "source": [
        "values\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "c6c9f350",
      "metadata": {},
      "outputs": [],
      "source": [
        "pd.DataFrame({'id': ids, 'value': values}).to_csv('submission.csv', index=False)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "65a78948",
      "metadata": {},
      "outputs": [],
      "source": [
        "my_submission = pd.read_csv(\"submission.csv\")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "8b9c5a93",
      "metadata": {},
      "outputs": [],
      "source": [
        "my_submission.head()\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "d05765f2",
      "metadata": {},
      "outputs": [],
      "source": [
        " \n"
      ]
    }
  ],
  "metadata": {},
  "nbformat": 4,
  "nbformat_minor": 5
}
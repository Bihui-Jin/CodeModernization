{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4a90deb1",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from pathlib import Path"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "64abfe75",
   "metadata": {},
   "outputs": [],
   "source": [
    "# This Python 3 environment comes with many helpful analytics libraries installed\n",
    "# It is defined by the kaggle/python Docker image: https://github.com/kaggle/docker-python\n",
    "# For example, here's several helpful packages to load\n",
    "\n",
    "import numpy as np # linear algebra\n",
    "import pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\n",
    "\n",
    "# Input data files are available in the read-only \"../input/\" directory\n",
    "# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n",
    "\n",
    "import os\n",
    "for dirname, _, filenames in os.walk('/kaggle/working/dog-breed-identification'):\n",
    "    for filename in filenames:\n",
    "        print(os.path.join(dirname, filename))\n",
    "\n",
    "# You can write up to 20GB to the current directory (/kaggle/working/) that gets preserved as output when you create a version using \"Save & Run All\" \n",
    "# You can also write temporary files to /kaggle/temp/, but they won't be saved outside of the current session\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5a0934c9",
   "metadata": {},
   "outputs": [],
   "source": [
    "pip install d2lzh\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "00175d82",
   "metadata": {},
   "outputs": [],
   "source": [
    "!cp -r /kaggle/input/dog-breed-identification /kaggle/working/dog-breed-identification\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9606fd39",
   "metadata": {},
   "outputs": [],
   "source": [
    "!pwd\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d9c169f0",
   "metadata": {},
   "outputs": [],
   "source": [
    "import collections\n",
    "import d2lzh as d2l\n",
    "import math\n",
    "from mxnet import autograd, gluon, init, nd\n",
    "from mxnet.gluon import data as gdata, loss as gloss, model_zoo, nn\n",
    "import os\n",
    "import shutil\n",
    "import time\n",
    "import zipfile\n",
    "import tensorflow as tf\n",
    "from tensorflow import keras\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import os\n",
    "import shutil\n",
    "import collections\n",
    "import math\n",
    "import random\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a09e7d5a",
   "metadata": {},
   "outputs": [],
   "source": [
    "def reorg_train_valid(data_dir, train_dir, input_dir, valid_ratio, idx_label):\n",
    "    # 训练集中数量最少一类的狗的样本数\n",
    "    min_n_train_per_label = (\n",
    "        collections.Counter(idx_label.values()).most_common()[:-2:-1][0][1])\n",
    "    # 验证集中每类狗的样本数\n",
    "    n_valid_per_label = math.floor(min_n_train_per_label * valid_ratio)\n",
    "    label_count = {}\n",
    "    for train_file in os.listdir(os.path.join(data_dir, train_dir)):\n",
    "        idx = train_file.split('.')[0]\n",
    "        label = idx_label[idx]\n",
    "        d2l.mkdir_if_not_exist([data_dir, input_dir, 'train_valid', label])\n",
    "        shutil.copy(os.path.join(data_dir, train_dir, train_file),\n",
    "                    os.path.join(data_dir, input_dir, 'train_valid', label))\n",
    "        if label not in label_count or label_count[label] < n_valid_per_label:\n",
    "            d2l.mkdir_if_not_exist([data_dir, input_dir, 'valid', label])\n",
    "            shutil.copy(os.path.join(data_dir, train_dir, train_file),\n",
    "                        os.path.join(data_dir, input_dir, 'valid', label))\n",
    "            label_count[label] = label_count.get(label, 0) + 1\n",
    "        else:\n",
    "            d2l.mkdir_if_not_exist([data_dir, input_dir, 'train', label])\n",
    "            shutil.copy(os.path.join(data_dir, train_dir, train_file),\n",
    "                        os.path.join(data_dir, input_dir, 'train', label))\n",
    "def reorg_dog_data(data_dir, label_file, train_dir, test_dir, input_dir,\n",
    "                   valid_ratio):\n",
    "    # 读取训练数据标签\n",
    "    with open(os.path.join(data_dir, label_file), 'r') as f:\n",
    "        # 跳过文件头行（栏名称）\n",
    "        lines = f.readlines()[1:]\n",
    "        tokens = [l.rstrip().split(',') for l in lines]\n",
    "        idx_label = dict(((idx, label) for idx, label in tokens))\n",
    "    reorg_train_valid(data_dir, train_dir, input_dir, valid_ratio, idx_label)\n",
    "    # 整理测试集\n",
    "    d2l.mkdir_if_not_exist([data_dir, input_dir, 'test', 'unknown'])\n",
    "    for test_file in os.listdir(os.path.join(data_dir, test_dir)):\n",
    "        shutil.copy(os.path.join(data_dir, test_dir, test_file),\n",
    "                    os.path.join(data_dir, input_dir, 'test', 'unknown'))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cb131b99",
   "metadata": {},
   "outputs": [],
   "source": [
    "data_dir = '/kaggle/working/dog-breed-identification'\n",
    "label_file, train_dir, test_dir = 'labels.csv', 'train', 'test'\n",
    "input_dir, batch_size, valid_ratio = 'train_valid_test', 128, 0.1\n",
    "reorg_dog_data(data_dir, label_file, train_dir, test_dir, input_dir,valid_ratio)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4a1017c9",
   "metadata": {},
   "outputs": [],
   "source": [
    "def transform_train(imgpath,label):\n",
    "    # 随机对图像裁剪出面积为原图像面积0.08~1倍、且高和宽之比在3/4~4/3的图像，再放缩为高和\n",
    "    # 宽均为224像素的新图像\n",
    "    feature=tf.io.read_file(imgpath)\n",
    "    feature = tf.image.decode_jpeg(feature,channels=3)\n",
    "    feature = tf.image.resize(feature, size=[400, 400])\n",
    "    seed=random.randint(8,100)/100\n",
    "    feature = tf.image.random_crop(feature, size=[int(seed*feature.shape[0]), int(seed*feature.shape[1]), 3])\n",
    "    feature = tf.image.resize(feature, size=[224, 224])\n",
    "    feature = tf.image.random_flip_left_right(feature)\n",
    "    feature = tf.image.random_flip_up_down(feature)\n",
    "    # 标准化\n",
    "    feature = tf.divide(feature, 255.)\n",
    "    # 正则化\n",
    "    mean = tf.convert_to_tensor([0.485, 0.456, 0.406])\n",
    "    std = tf.convert_to_tensor([0.229, 0.224, 0.225])\n",
    "    feature = tf.divide(tf.subtract(feature, mean), std)\n",
    "    #feature = tf.image.per_image_standardization(feature)\n",
    "    #print(feature,label)\n",
    "    return tf.image.convert_image_dtype(feature, tf.float32),label\n",
    "def transform_test(imgpath,label):\n",
    "    feature=tf.io.read_file(imgpath)\n",
    "    feature = tf.image.decode_jpeg(feature,channels=3)\n",
    "    feature = tf.image.resize(feature, [224, 224])\n",
    "    feature = tf.divide(feature, 255.)\n",
    "    # feature = tf.image.per_image_standardization(feature)\n",
    "    mean = tf.convert_to_tensor([0.485, 0.456, 0.406])\n",
    "    std = tf.convert_to_tensor([0.229, 0.224, 0.225])\n",
    "    feature = tf.divide(tf.subtract(feature, mean), std)\n",
    "    return feature,label\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ec3d829e",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pathlib\n",
    "data_root=\"/kaggle/working/dog-breed-identification/train_valid_test\"\n",
    "train_data_root = pathlib.Path(data_root+\"/train\")\n",
    "valid_data_root = pathlib.Path(data_root+\"/valid\")\n",
    "train_valid_data_root = pathlib.Path(data_root+\"/train_valid\")\n",
    "test_data_root = pathlib.Path(data_root+\"/test\")\n",
    "label_names = sorted(item.name for item in train_data_root.glob('*/') if item.is_dir())\n",
    "label_to_index = dict((name, index) for index, name in enumerate(label_names))\n",
    "\n",
    "train_all_image_paths = [str(path) for path in list(train_data_root.glob('*/*'))]\n",
    "valid_all_image_paths = [str(path) for path in list(valid_data_root.glob('*/*'))]\n",
    "train_valid_all_image_paths = [str(path) for path in list(train_valid_data_root.glob('*/*'))]\n",
    "test_all_image_paths = [str(path) for path in list(test_data_root.glob('*/*'))]\n",
    "\n",
    "\n",
    "train_all_image_labels = [label_to_index[pathlib.Path(path).parent.name] for path in train_all_image_paths]\n",
    "valid_all_image_labels = [label_to_index[pathlib.Path(path).parent.name] for path in valid_all_image_paths]\n",
    "train_valid_all_image_labels = [label_to_index[pathlib.Path(path).parent.name] for path in train_valid_all_image_paths]\n",
    "test_all_image_labels = [-1 for i in range(len(test_all_image_paths))]\n",
    "print(\"First 10 images indices: \", train_valid_all_image_labels[:10])\n",
    "print(\"First 10 labels indices: \", train_valid_all_image_labels[:10])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "62f59cf1",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_ds = tf.data.Dataset.from_tensor_slices((train_all_image_paths, train_all_image_labels)).map(transform_train).shuffle(len(train_all_image_paths)).batch(batch_size)\n",
    "valid_ds = tf.data.Dataset.from_tensor_slices((valid_all_image_paths, valid_all_image_labels)).map(transform_train).shuffle(len(valid_all_image_paths)).batch(batch_size)\n",
    "train_valid_ds = tf.data.Dataset.from_tensor_slices((train_valid_all_image_paths, train_valid_all_image_labels)).map(transform_train).shuffle(len(train_valid_all_image_paths)).batch(batch_size)\n",
    "test_ds = tf.data.Dataset.from_tensor_slices((test_all_image_paths, test_all_image_labels)).map(transform_test).shuffle(len(test_all_image_paths)).batch(batch_size)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "97a698ba",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_ds\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7f7ce2ec",
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras.applications import ResNet50\n",
    "net=ResNet50(\n",
    "    input_shape=(224, 224, 3),\n",
    "    weights='imagenet',\n",
    "    include_top=False\n",
    ")\n",
    "model = tf.keras.Sequential([\n",
    "    net,\n",
    "    tf.keras.layers.GlobalAveragePooling2D(),\n",
    "    tf.keras.layers.Dense(256, activation='relu',dtype=tf.float32),\n",
    "    tf.keras.layers.Dropout(.5),\n",
    "    tf.keras.layers.Dense(len(label_names), activation='softmax',dtype=tf.float32)\n",
    "])\n",
    "model.summary()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3d8a4cf5",
   "metadata": {},
   "outputs": [],
   "source": [
    "lr = 0.1\n",
    "lr_decay = 0.01\n",
    "\n",
    "def scheduler(epoch):\n",
    "    if epoch < 10:\n",
    "        return lr\n",
    "    else:\n",
    "        return lr * tf.math.exp(lr_decay * (10 - epoch))\n",
    "\n",
    "callback = tf.keras.callbacks.LearningRateScheduler(scheduler)\n",
    "\n",
    "model.compile(optimizer=keras.optimizers.SGD(learning_rate=lr, momentum=0.9),\n",
    "        loss='sparse_categorical_crossentropy')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dd9e01df",
   "metadata": {},
   "outputs": [],
   "source": [
    "model.fit(train_ds, epochs=1 , validation_data=valid_ds,  callbacks=[callback])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7ebbf10f",
   "metadata": {},
   "outputs": [],
   "source": [
    "model.compile(optimizer=keras.optimizers.SGD(learning_rate=lr, momentum=0.9),\n",
    "        loss='sparse_categorical_crossentropy')\n",
    "model.fit(train_valid_ds, epochs=1 , callbacks=[callback])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "193073c2",
   "metadata": {},
   "outputs": [],
   "source": [
    "probabilities=model.predict(test_ds)\n",
    "predictions=np.argmax(probabilities, axis=-1)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "556f964e",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(probabilities)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2b293b9f",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv('/kaggle/working/dog-breed-identification/sample_submission.csv')\n",
    "\n",
    "for i, c in enumerate(df.columns[1:]):\n",
    "    df[c] = probabilities[:,i]\n",
    "\n",
    "df.to_csv('submission.csv', index=None)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e56217ee",
   "metadata": {},
   "outputs": [],
   "source": [
    "!rm -rf /kaggle/working/dog-breed-identification\n"
   ]
  }
 ],
 "metadata": {},
 "nbformat": 4,
 "nbformat_minor": 5
}

{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "32079900",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from pathlib import Path"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cbdf7e9f",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd \n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib\n",
    "\n",
    "\n",
    "import os\n",
    "#for dirname, _, filenames in os.walk('/kaggle/input'):\n",
    "#    for filename in filenames:\n",
    "#        print(os.path.join(dirname, filename))\n",
    "\n",
    "train_df = pd.read_csv('/kaggle/input/tabular-playground-series-may-2022/train.csv')\n",
    "test_df = pd.read_csv('/kaggle/input/tabular-playground-series-may-2022/test.csv')\n",
    "subm = pd.read_csv('/kaggle/input/tabular-playground-series-may-2022/sample_submission.csv')\n",
    "\n",
    "print(\"The Training dataset is made of {} rows and {} columns.\".format(len(train_df), len(train_df.columns)))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "185cb7dc",
   "metadata": {},
   "outputs": [],
   "source": [
    "pd.options.display.max_columns = train_df.shape[1]\n",
    "train_df.head()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e72755f9",
   "metadata": {},
   "outputs": [],
   "source": [
    "columns = train_df.dtypes\n",
    "\n",
    "for elem in range(len(columns.index)):\n",
    "    print(\"- {}: type {} \\n\".format(columns.index[elem], columns.values[elem]))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "71cbdd20",
   "metadata": {},
   "outputs": [],
   "source": [
    "counting = train_df['target'].value_counts()\n",
    "lbl = []\n",
    "for elem in counting.index:\n",
    "    lbl.append('Target {}'.format(counting.index.values[elem]))\n",
    "\n",
    "plt.figure(figsize=(15,8))\n",
    "font = {'family' : 'serif',\n",
    "        'weight' : 'bold',\n",
    "        'size'   : 12}\n",
    "\n",
    "matplotlib.rc('font', **font)\n",
    "\n",
    "colors = sns.color_palette(\"husl\", 2)\n",
    "plt.pie(counting, labels = lbl, colors = colors, autopct='%.0f%%', explode=(0, 0.1),\n",
    "        shadow=True, startangle=90\n",
    "       )\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "44300bdb",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"The number of missing values in the training set is equal to: {}.\".format(train_df.isnull().sum().sum()))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d329f1bf",
   "metadata": {},
   "outputs": [],
   "source": [
    "features = train_df.drop(columns = ['id', 'target'])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e9b55c62",
   "metadata": {},
   "outputs": [],
   "source": [
    "x_float = train_df.select_dtypes('float64')\n",
    "x_float.describe()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6adf0e2b",
   "metadata": {},
   "outputs": [],
   "source": [
    "sns.color_palette(\"husl\", 8)\n",
    "plt.figure(figsize=(15,8))\n",
    "ax = sns.boxplot(data=x_float, orient=\"h\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7c9c5870",
   "metadata": {},
   "outputs": [],
   "source": [
    "float_and_tgt=pd.concat([x_float,train_df['target']], axis=1)\n",
    "titles=['Feature {}'.format(i.split('_')[-1]) for i in x_float]\n",
    "fig, ax = plt.subplots(4,4, figsize=(14,24))\n",
    "row=0\n",
    "col=[0,1,2,3]*4\n",
    "for i, column in enumerate(float_and_tgt.columns[:-1]):\n",
    "    if (i!=0) & (i%4==0):\n",
    "        row+=1\n",
    "    color='#2CB4CF'\n",
    "    rgb=matplotlib.colors.to_rgba(color,0.2)\n",
    "    ax[row,col[i]].boxplot(float_and_tgt[float_and_tgt['target']==0][column], positions=[0],\n",
    "                           widths=0.7, patch_artist=True,\n",
    "                           boxprops=dict(color=color, facecolor=rgb, linewidth=1.5))\n",
    "    color='#EAB4DE'\n",
    "    rgb=matplotlib.colors.to_rgba(color,0.2)\n",
    "    ax[row,col[i]].boxplot(float_and_tgt[float_and_tgt['target']==1][column], positions=[1],\n",
    "                           widths=0.7, patch_artist=True,\n",
    "                           boxprops=dict(color=color, facecolor=rgb, linewidth=1.5))\n",
    "    ax[row,col[i]].grid(visible=True, which='major', axis='y', color='#F2F2F2')\n",
    "    ax[row,col[i]].tick_params(left=False,bottom=False)\n",
    "    ax[row,col[i]].set_title('\\n\\n{}'.format(titles[i]))\n",
    "sns.despine(bottom=True, trim=True)\n",
    "plt.suptitle('Distributions of Numerical Variables',fontsize=16)\n",
    "plt.tight_layout(rect=[0, 0.2, 1, 0.99])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0dc275e4",
   "metadata": {},
   "outputs": [],
   "source": [
    "float_and_tgt=pd.concat([x_float,train_df['target']], axis=1)\n",
    "titles=['Feature {}'.format(i.split('_')[-1]) for i in x_float]\n",
    "fig, ax = plt.subplots(4,4, figsize=(14,24))\n",
    "row=0\n",
    "col=[0,1,2,3]*4\n",
    "for i, column in enumerate(float_and_tgt.columns[:-1]):\n",
    "    if (i!=0) & (i%4==0):\n",
    "        row+=1\n",
    "    color='#2CB4CF'\n",
    "    rgb=matplotlib.colors.to_rgba(color,0.3)\n",
    "    ax[row,col[i]].hist(float_and_tgt[float_and_tgt['target']==0][column],\n",
    "                        color=rgb, density=True, bins=40)\n",
    "    color='#EAB4DE'\n",
    "    rgb=matplotlib.colors.to_rgba(color,0.3)\n",
    "    ax[row,col[i]].hist(float_and_tgt[float_and_tgt['target']==1][column],\n",
    "                       color=rgb, density=True, bins=40)\n",
    "    #ax[row,col[i]].grid(visible=True, which='major', axis='y', color='#F2F2F2')\n",
    "    ax[row,col[i]].tick_params(left=False,bottom=False)\n",
    "    ax[row,col[i]].set_title('\\n\\n{}'.format(titles[i]))\n",
    "sns.despine(bottom=True, trim=True)\n",
    "plt.suptitle('Distributions of Numerical Variables',fontsize=16)\n",
    "plt.tight_layout(rect=[0, 0.2, 1, 0.99])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1134dfb3",
   "metadata": {},
   "outputs": [],
   "source": [
    "corr = x_float.corr()\n",
    "\n",
    "# Generate a mask for the upper triangle\n",
    "mask = np.triu(np.ones_like(corr, dtype=bool))\n",
    "f, ax = plt.subplots(figsize=(14, 24))\n",
    "\n",
    "# Generate a custom diverging colormap\n",
    "cmap = sns.diverging_palette(145, 300, s=60, as_cmap=True)\n",
    "\n",
    "# Draw the heatmap with the mask and correct aspect ratio\n",
    "sns.heatmap(corr, mask=mask, cmap=cmap, vmax=.3, center=0,\n",
    "            square=True, linewidths=.5, cbar_kws={\"shrink\": .5})\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d2d7eecc",
   "metadata": {},
   "outputs": [],
   "source": [
    "x_int = train_df.select_dtypes('int64')\n",
    "x_int = x_int.drop('id', axis=1)\n",
    "#x_int_tgt = pd.concat([x_int,train_df['target']], axis=1)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "689fc857",
   "metadata": {},
   "outputs": [],
   "source": [
    "sub_titles=['Feature {}'.format(i.split('_')[-1]) for i in x_int.columns[:-1]]\n",
    "\n",
    "fig, ax = plt.subplots(4,4, figsize=(14,24))\n",
    "\n",
    "for i, f in enumerate(x_int.columns[:-1]):\n",
    "    plt.subplot(4, 4, i+1)\n",
    "    ax = plt.gca()\n",
    "    color='#2CB4CF'\n",
    "    rgb=matplotlib.colors.to_rgba(color,0.3)\n",
    "    \n",
    "    vc_0 = x_int[x_int['target']==0][f].value_counts()\n",
    "    ax.bar(vc_0.index, vc_0, color=rgb)\n",
    "    \n",
    "    color='#EAB4DE'\n",
    "    rgb=matplotlib.colors.to_rgba(color,0.3)\n",
    "    vc_1 = x_int[x_int['target']==1][f].value_counts()\n",
    "    ax.bar(vc_1.index, vc_1, color=rgb)\n",
    "    #ax.hist(train[f], density=False, bins=(train[f].max()-train[f].min()+1))\n",
    "    #ax.set_xlabel(f'Feature {f}')\n",
    "    ax.set_title('\\n\\n{}'.format(sub_titles[i]))\n",
    "    #ax.xaxis.set_major_locator(MaxNLocator(integer=True)) # only integer labels\n",
    "sns.despine(bottom=True, trim=True)\n",
    "plt.suptitle('Distributions of Categorical Variables',fontsize=16)\n",
    "plt.tight_layout(rect=[0, 0.2, 1, 0.99])\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dc56a0b1",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection  import train_test_split\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.metrics import accuracy_score\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e71a1dce",
   "metadata": {},
   "outputs": [],
   "source": [
    "x_features = pd.concat([x_float,x_int], axis=1)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ba1bae95",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_x, cv_x, y_train, y_cv  = train_test_split(x_features,train_df['target'],\n",
    "                                                 stratify=train_df['target'])\n",
    "\n",
    "train_x.drop(['target'],axis=1,inplace=True)\n",
    "cv_x.drop([\"target\"],axis=1,inplace=True)\n",
    "\n",
    "lr = LogisticRegression(max_iter=500)\n",
    "lr.fit(train_x.values, y_train.values)\n",
    "pred = lr.predict(train_x.values)\n",
    "print(\"The train accuracy of the Logistic Regression is \",accuracy_score(y_train.values,pred))\n",
    "pred  = lr.predict(cv_x.values)\n",
    "print(\"The cv accuracy of the Logistic Regression is \",accuracy_score(y_cv.values, pred))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3ba147d1",
   "metadata": {},
   "outputs": [],
   "source": [
    "from scipy import stats\n",
    "x_float_no = x_float[(np.abs(stats.zscore(x_float)) < 3).all(axis=1)]\n",
    "index_list_no = x_float_no.index.to_list()\n",
    "x_int_no = x_int.iloc[index_list_no]\n",
    "target_no = x_int_no['target']\n",
    "x_int_no.drop('target', axis=1, inplace=True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "01442bda",
   "metadata": {},
   "outputs": [],
   "source": [
    "x_features_no = pd.concat([x_float_no,x_int_no], axis=1)\n",
    "\n",
    "train_x, cv_x, y_train, y_cv  = train_test_split(x_features_no,target_no,\n",
    "                                                 stratify=target_no)\n",
    "\n",
    "#train_x.drop(['target'],axis=1,inplace=True)\n",
    "#cv_x.drop([\"target\"],axis=1,inplace=True)\n",
    "\n",
    "lr = LogisticRegression(max_iter=500)\n",
    "lr.fit(train_x.values, y_train.values)\n",
    "pred = lr.predict(train_x.values)\n",
    "print(\"The train accuracy of the Logistic Regression without outliers is \",accuracy_score(y_train.values,pred))\n",
    "pred  = lr.predict(cv_x.values)\n",
    "print(\"The cv accuracy of the Logistic Regression without outliers is \",accuracy_score(y_cv.values, pred))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "03b69a16",
   "metadata": {},
   "outputs": [],
   "source": [
    "test_x = test_df.select_dtypes([\"int\",\"float\"])\n",
    "test_id = test_x['id'].values\n",
    "test_x.drop(\"id\",axis=1,inplace=True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6387d75c",
   "metadata": {},
   "outputs": [],
   "source": [
    "pred = lr.predict(test_x.values)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5ab23f14",
   "metadata": {},
   "outputs": [],
   "source": [
    "subm.head()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "729443c4",
   "metadata": {},
   "outputs": [],
   "source": [
    "#x_features_no.drop('target', axis=1, inplace=True)\n",
    "from sklearn.ensemble import RandomForestRegressor, RandomForestClassifier\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d897be33",
   "metadata": {},
   "outputs": [],
   "source": [
    "x_train, x_test, y_train, y_test = train_test_split(x_features_no, target_no)\n",
    "\n",
    "\n",
    "model = RandomForestClassifier(n_jobs=-1)\n",
    "model.fit(x_train, y_train)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0d0749c5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Use the forest's predict method on the test data\n",
    "predictions = model.predict(x_test)\n",
    "# Calculate the absolute errors\n",
    "errors = abs(predictions - y_test)\n",
    "# Print out the mean absolute error (mae)\n",
    "print('Mean Absolute Error:', round(np.mean(errors), 2), 'degrees.')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1ff80161",
   "metadata": {},
   "outputs": [],
   "source": [
    "pred = model.predict(test_df.drop([\"id\",\"f_27\"],axis=1))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "51b4b61f",
   "metadata": {},
   "outputs": [],
   "source": [
    "submission_df = pd.DataFrame({\n",
    "    \"id\" : test_id,\n",
    "    \"target\": pred\n",
    "})\n",
    "submission_df.to_csv(\"submission.csv\",index=False)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "534717fd",
   "metadata": {},
   "outputs": [],
   "source": [
    " \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "04672ac7",
   "metadata": {},
   "outputs": [],
   "source": [
    " \n"
   ]
  }
 ],
 "metadata": {},
 "nbformat": 4,
 "nbformat_minor": 5
}

{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "de575238",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from pathlib import Path"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f3281eb0",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np # linear algebra\n",
    "import pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import cv2 \n",
    "import os\n",
    "\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Conv2D, Dense, Flatten, BatchNormalization, Dropout, LeakyReLU, Flatten,  MaxPool2D\n",
    "from keras.layers.pooling import GlobalAveragePooling2D\n",
    "from keras.optimizers import Adam\n",
    "from keras.preprocessing.image import ImageDataGenerator\n",
    "from keras.callbacks import ReduceLROnPlateau, ModelCheckpoint, EarlyStopping\n",
    "from sklearn.metrics import confusion_matrix, roc_auc_score, classification_report\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "from tqdm import tqdm, tqdm_notebook\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b2fe25d6",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_dir = '../input/train/train/'\n",
    "test_dir = '../input/test/test/'\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2e04d8b5",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_data = pd.read_csv('../input/train.csv')\n",
    "train_data.head()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9a47b6d8",
   "metadata": {},
   "outputs": [],
   "source": [
    "features = []\n",
    "labels = []\n",
    "\n",
    "images = train_data['id'].values\n",
    "\n",
    "for img_id in tqdm_notebook(images):\n",
    "    features.append(cv2.imread(train_dir+img_id))\n",
    "    labels.append(train_data[train_data['id'] == img_id]\n",
    "                  ['has_cactus'].values[0])\n",
    "    \n",
    "features = np.asarray(features)\n",
    "features = features.astype('float32')\n",
    "features /= 255\n",
    "labels = np.asarray(labels)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c65cd05b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Data augmentation\n",
    "datagen = ImageDataGenerator(\n",
    "            featurewise_center=False, \n",
    "            samplewise_center= False,\n",
    "            featurewise_std_normalization=False,\n",
    "            samplewise_std_normalization=False,\n",
    "            zca_whitening=False,\n",
    "            rotation_range=10,  #randomly rotate image in 0 to 180 degree\n",
    "            zoom_range=0.1, #randomly zoom image\n",
    "            width_shift_range=0.1, #randomly shift images horizontally\n",
    "            height_shift_range=0.1, #randomly shift images vertically\n",
    "            horizontal_flip = False, #randomly flip images\n",
    "            vertical_flip = False #randomly flip images\n",
    ")\n",
    "datagen.fit(features)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bd95b936",
   "metadata": {},
   "outputs": [],
   "source": [
    "# split dataset\n",
    "X_train, X_val, y_train, y_val = train_test_split(features, labels, test_size =0.1, random_state=2)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "32c3c1e5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# define model\n",
    "model = Sequential()\n",
    "model.add(Conv2D(15, kernel_size=3, activation='relu',\n",
    "                 input_shape=(32,32,3), padding='same'))\n",
    "model.add(Conv2D(15, kernel_size=3, activation='relu',\n",
    "                 padding='same'))\n",
    "model.add(Conv2D(15, kernel_size=3, activation='relu',\n",
    "                 padding='same'))\n",
    "model.add(Flatten())\n",
    "model.add(Dense(1, activation='sigmoid'))\n",
    "\n",
    "model.summary()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "67e96e7f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Compiling the model\n",
    "model.compile(optimizer='adam', loss='binary_crossentropy', metrics=['accuracy'])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ec000d4b",
   "metadata": {},
   "outputs": [],
   "source": [
    "#set a learning rate annealer\n",
    "learning_rate_reduction = ReduceLROnPlateau(monitor='val_acc', \n",
    "                                            patience=3, verbose=1, \n",
    "                                            factor=0.5, \n",
    "                                            min_lr=0.00001)\n",
    "epochs = 15\n",
    "batch_size = 86\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d8f86549",
   "metadata": {},
   "outputs": [],
   "source": [
    "clf = model.fit_generator(datagen.flow(X_train, y_train,batch_size=batch_size), \n",
    "                          epochs=epochs, validation_data=(X_val, y_val), verbose=2,\n",
    "                          steps_per_epoch=X_train.shape[0] // batch_size, \n",
    "                          callbacks=[learning_rate_reduction])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "30d5af1b",
   "metadata": {},
   "outputs": [],
   "source": [
    "test_features = []\n",
    "test_images = []\n",
    "\n",
    "for img_id in tqdm_notebook(os.listdir(test_dir)):\n",
    "    test_features.append(cv2.imread(test_dir+img_id))\n",
    "    test_images.append(img_id)\n",
    "    \n",
    "test_features = np.asarray(test_features)\n",
    "test_features = test_features.astype('float32')\n",
    "test_features /= 255\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "eb914782",
   "metadata": {},
   "outputs": [],
   "source": [
    "model.save('cactus_model.h5')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9dbe68a1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Running the model over the test images\n",
    "\n",
    "test_predictions = model.predict(test_features)\n",
    "submissions = pd.DataFrame(test_predictions, columns=['has_cactus'])\n",
    "submissions['has_cactus'] = submissions['has_cactus'].apply(lambda x: 1 if x > 0.75 else 0)\n",
    "submissions['id'] = ''\n",
    "cols = submissions.columns.tolist()\n",
    "cols = cols[-1:] + cols[:-1]\n",
    "submissions=submissions[cols]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5328acc1",
   "metadata": {},
   "outputs": [],
   "source": [
    "for i, img in enumerate(test_images):\n",
    "    submissions.set_value(i,'id',img)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9c79394c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Saving the output file\n",
    "\n",
    "submissions.to_csv('submission.csv',index=False)\n"
   ]
  }
 ],
 "metadata": {},
 "nbformat": 4,
 "nbformat_minor": 5
}

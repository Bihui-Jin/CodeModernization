{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0ae98e8e",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from pathlib import Path"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9e5635c4",
   "metadata": {},
   "outputs": [],
   "source": [
    "#import necessary packages and training labels\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "train_labels = pd.read_csv('../input/histopathologic-cancer-detection/train_labels.csv', dtype=str)\n",
    "print(train_labels.shape)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "28d77d6a",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_labels.head()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2649bd18",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_labels.dtypes\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b781ed07",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_labels['label'] = train_labels['label'].astype(float)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f7690c6b",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "print(len(os.listdir('../input/histopathologic-cancer-detection/train/')))\n",
    "print(len(os.listdir('../input/histopathologic-cancer-detection/test/')))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "431d4d6b",
   "metadata": {},
   "outputs": [],
   "source": [
    "len(train_labels)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7b2d6c93",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_labels['label'].value_counts()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "959d0b70",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_labels['label'].value_counts().plot(kind='pie')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "20669008",
   "metadata": {},
   "outputs": [],
   "source": [
    "#split into two sets based on labels\n",
    "train_labels_pos = train_labels[train_labels['label']==1]\n",
    "train_labels_neg = train_labels[train_labels['label']==0]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0c52e5d7",
   "metadata": {},
   "outputs": [],
   "source": [
    "#take a random sample of the neg labels of the same size as the set of pos labels\n",
    "train_labels_neg = train_labels_neg.sample(n = train_labels_pos.shape[0])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e7f14685",
   "metadata": {},
   "outputs": [],
   "source": [
    "#confirm both sets are of the same size\n",
    "print(train_labels_neg.shape[0])\n",
    "print(train_labels_pos.shape[0])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6e43cd1c",
   "metadata": {},
   "outputs": [],
   "source": [
    "#combine and randomize the two sets\n",
    "train_labels_balanced = pd.concat([train_labels_neg,train_labels_pos]).sample(frac=1, random_state=12345).reset_index(drop=True)\n",
    "train_labels_balanced.head()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5eba6806",
   "metadata": {},
   "outputs": [],
   "source": [
    "#confirm final set has the expected amount and shape\n",
    "train_labels_balanced.shape\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "63009b77",
   "metadata": {},
   "outputs": [],
   "source": [
    "#confirm final set has the expected value counts\n",
    "train_labels_balanced['label'].value_counts()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "017b879d",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_labels_balanced['label'].value_counts().plot(kind='pie')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "12551262",
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import matplotlib.image as mpimg\n",
    "\n",
    "img = mpimg.imread(f'../input/histopathologic-cancer-detection/train/{train_labels_balanced.iloc[47,0]}.tif')\n",
    "imgplot = plt.imshow(img)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4923fec5",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(img.shape)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "744c18ef",
   "metadata": {},
   "outputs": [],
   "source": [
    "sample_imgs = np.random.choice(train_labels_balanced.index,15)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4713a72c",
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, ax = plt.subplots(5, 3,figsize=(20,20))\n",
    "\n",
    "for i in range(0, sample_imgs.shape[0]):\n",
    "    ax = plt.subplot(5, 3, i+1)\n",
    "    img = mpimg.imread(f'../input/histopathologic-cancer-detection/train/{train_labels_balanced.iloc[sample_imgs[i],0]}.tif')\n",
    "    ax.imshow(img)\n",
    "    lab = train_labels_balanced.iloc[sample_imgs[i],1]\n",
    "    ax.set_title('Label: %s'%lab)\n",
    "    \n",
    "plt.tight_layout()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "26df8fdd",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9a6a695e",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_df, valid_df = train_test_split(train_labels_balanced, test_size=0.25, random_state=1234, stratify=train_labels_balanced.label)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b4a67bc3",
   "metadata": {},
   "outputs": [],
   "source": [
    "#import tensorflow and keras as well as any necessary packages\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow import keras\n",
    "from keras.layers import Dense, Activation, Flatten, Dropout, BatchNormalization\n",
    "from keras.layers import Conv2D, MaxPooling2D\n",
    "from keras import regularizers, optimizers\n",
    "from keras.layers import PReLU\n",
    "from keras.initializers import Constant\n",
    "\n",
    "from tensorflow.keras.preprocessing.image import ImageDataGenerator\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fe7a5464",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_df['id'] = train_df['id']+'.tif'\n",
    "valid_df['id'] = valid_df['id']+'.tif'\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c07983d5",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_df['label'] = train_df['label'].astype(str)\n",
    "valid_df['label'] = valid_df['label'].astype(str)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e1c05757",
   "metadata": {},
   "outputs": [],
   "source": [
    "#create the training and validation subsets\n",
    "train_datagen=ImageDataGenerator(rescale=1/255)\n",
    "\n",
    "train_generator=train_datagen.flow_from_dataframe(dataframe=train_df,directory=\"../input/histopathologic-cancer-detection/train/\",\n",
    "                x_col=\"id\",y_col=\"label\",batch_size=64,seed=1234,shuffle=True,\n",
    "                class_mode=\"binary\",target_size=(96,96))\n",
    "\n",
    "valid_generator=train_datagen.flow_from_dataframe(dataframe=valid_df,directory=\"../input/histopathologic-cancer-detection/train/\",\n",
    "                x_col=\"id\",y_col=\"label\",batch_size=64,seed=1234,shuffle=True,\n",
    "                class_mode=\"binary\",target_size=(96,96))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4fde4a57",
   "metadata": {},
   "outputs": [],
   "source": [
    "#initial model with 4 sets of 2 convolutional layers\n",
    "model = Sequential()\n",
    "model.add(Conv2D(32, (3, 3), padding='same',input_shape=(96,96,3)))\n",
    "model.add(Activation('relu'))\n",
    "model.add(Conv2D(32, (3, 3)))\n",
    "model.add(Activation('relu'))\n",
    "model.add(MaxPooling2D(pool_size=(2, 2)))\n",
    "model.add(BatchNormalization())\n",
    "\n",
    "model.add(Conv2D(64, (3, 3)))\n",
    "model.add(Activation('relu'))\n",
    "model.add(Conv2D(64, (3, 3)))\n",
    "model.add(Activation('relu'))\n",
    "model.add(MaxPooling2D(pool_size=(2, 2)))\n",
    "model.add(BatchNormalization())\n",
    "\n",
    "model.add(Conv2D(128, (3, 3)))\n",
    "model.add(Activation('relu'))\n",
    "model.add(Conv2D(128, (3, 3)))\n",
    "model.add(Activation('relu'))\n",
    "model.add(MaxPooling2D(pool_size=(2, 2)))\n",
    "model.add(BatchNormalization())\n",
    "\n",
    "model.add(Conv2D(256, (3, 3)))\n",
    "model.add(Activation('relu'))\n",
    "model.add(Conv2D(256, (3, 3)))\n",
    "model.add(Activation('relu'))\n",
    "model.add(MaxPooling2D(pool_size=(2, 2)))\n",
    "model.add(BatchNormalization())\n",
    "          \n",
    "model.add(Flatten())\n",
    "model.add(Dropout(0.25))\n",
    "model.add(Dense(512))\n",
    "model.add(Activation('relu'))\n",
    "\n",
    "model.add(Dropout(0.25))\n",
    "model.add(Dense(256))\n",
    "model.add(Activation('relu'))\n",
    "\n",
    "model.add(Dropout(0.25))\n",
    "model.add(Dense(64))\n",
    "model.add(Activation('relu')) \n",
    "\n",
    "model.add(Dropout(0.25))\n",
    "model.add(Dense(1, activation='sigmoid'))\n",
    "opt = tf.keras.optimizers.Adam(0.001)\n",
    "model.compile(loss='binary_crossentropy', optimizer=opt, metrics=['accuracy'])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4ee70882",
   "metadata": {},
   "outputs": [],
   "source": [
    "model.summary()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "55cb6e70",
   "metadata": {},
   "outputs": [],
   "source": [
    "STEP_SIZE_TRAIN=train_generator.n//train_generator.batch_size\n",
    "STEP_SIZE_VALID=valid_generator.n//valid_generator.batch_size\n",
    "\n",
    "history = model.fit_generator(generator=train_generator,\n",
    "                    steps_per_epoch=STEP_SIZE_TRAIN,\n",
    "                    validation_data=valid_generator,\n",
    "                    validation_steps=STEP_SIZE_VALID,\n",
    "                    epochs=30, verbose=1\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1ac44fdb",
   "metadata": {},
   "outputs": [],
   "source": [
    "#next model with 3 sets of 5 convolutional layers\n",
    "model2 = Sequential()\n",
    "model2.add(Conv2D(32, (3, 3), padding='same',input_shape=(96,96,3)))\n",
    "model2.add(Activation('relu'))\n",
    "model2.add(Conv2D(32, (3, 3)))\n",
    "model2.add(Activation('relu'))\n",
    "model2.add(Conv2D(32, (3, 3)))\n",
    "model2.add(Activation('relu'))\n",
    "model2.add(Conv2D(32, (3, 3)))\n",
    "model2.add(Activation('relu'))\n",
    "model2.add(Conv2D(32, (3, 3)))\n",
    "model2.add(Activation('relu'))\n",
    "model2.add(MaxPooling2D(pool_size=(2, 2)))\n",
    "model2.add(BatchNormalization())\n",
    "\n",
    "model2.add(Conv2D(64, (3, 3)))\n",
    "model2.add(Activation('relu'))\n",
    "model2.add(Conv2D(64, (3, 3)))\n",
    "model2.add(Activation('relu'))\n",
    "model2.add(Conv2D(64, (3, 3)))\n",
    "model2.add(Activation('relu'))\n",
    "model2.add(Conv2D(64, (3, 3)))\n",
    "model2.add(Activation('relu'))\n",
    "model2.add(Conv2D(64, (3, 3)))\n",
    "model2.add(Activation('relu'))\n",
    "model2.add(MaxPooling2D(pool_size=(2, 2)))\n",
    "model2.add(BatchNormalization())\n",
    "\n",
    "model2.add(Conv2D(128, (3, 3)))\n",
    "model2.add(Activation('relu'))\n",
    "model2.add(Conv2D(128, (3, 3)))\n",
    "model2.add(Activation('relu'))\n",
    "model2.add(Conv2D(128, (3, 3)))\n",
    "model2.add(Activation('relu'))\n",
    "model2.add(Conv2D(128, (3, 3)))\n",
    "model2.add(Activation('relu'))\n",
    "model2.add(Conv2D(128, (3, 3)))\n",
    "model2.add(Activation('relu'))\n",
    "model2.add(MaxPooling2D(pool_size=(2, 2)))\n",
    "model2.add(BatchNormalization())\n",
    "          \n",
    "model2.add(Flatten())\n",
    "model2.add(Dropout(0.25))\n",
    "model2.add(Dense(512))\n",
    "model2.add(Activation('relu'))\n",
    "\n",
    "model2.add(Dropout(0.25))\n",
    "model2.add(Dense(256))\n",
    "model2.add(Activation('relu'))\n",
    "\n",
    "model2.add(Dropout(0.25))\n",
    "model2.add(Dense(64))\n",
    "model2.add(Activation('relu')) \n",
    "\n",
    "model2.add(Dropout(0.25))\n",
    "model2.add(Dense(1, activation='sigmoid'))\n",
    "opt = tf.keras.optimizers.Adam(0.001)\n",
    "model2.compile(loss='binary_crossentropy', optimizer=opt, metrics=['accuracy'])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fe623826",
   "metadata": {},
   "outputs": [],
   "source": [
    "model2.summary()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2e2e4057",
   "metadata": {},
   "outputs": [],
   "source": [
    "STEP_SIZE_TRAIN=train_generator.n//train_generator.batch_size\n",
    "STEP_SIZE_VALID=valid_generator.n//valid_generator.batch_size\n",
    "\n",
    "history2 = model2.fit_generator(generator=train_generator,\n",
    "                    steps_per_epoch=STEP_SIZE_TRAIN,\n",
    "                    validation_data=valid_generator,\n",
    "                    validation_steps=STEP_SIZE_VALID,\n",
    "                    epochs=30, verbose=1\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2bdb4ee3",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.plot(history.history['accuracy'])\n",
    "plt.plot(history.history['val_accuracy'])\n",
    "plt.title('model loss')\n",
    "plt.ylabel('loss')\n",
    "plt.xlabel('epoch')\n",
    "plt.legend(['train', 'val'], loc='upper left')\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "55e9152a",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.plot(history2.history['accuracy'])\n",
    "plt.plot(history2.history['val_accuracy'])\n",
    "plt.title('model2 accuracy')\n",
    "plt.ylabel('accuracy')\n",
    "plt.xlabel('epoch')\n",
    "plt.legend(['train', 'val'], loc='upper left')\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "58e9fe4e",
   "metadata": {},
   "outputs": [],
   "source": [
    "#next model with 3 sets of 5 convolutional layers\n",
    "model3 = Sequential()\n",
    "model3.add(Conv2D(32, (3, 3), padding='same',input_shape=(96,96,3)))\n",
    "model3.add(Activation('relu'))\n",
    "model3.add(Conv2D(32, (3, 3)))\n",
    "model3.add(Activation('relu'))\n",
    "model3.add(Conv2D(32, (3, 3)))\n",
    "model3.add(Activation('relu'))\n",
    "model3.add(Conv2D(32, (3, 3)))\n",
    "model3.add(Activation('relu'))\n",
    "model3.add(Conv2D(32, (3, 3)))\n",
    "model3.add(Activation('relu'))\n",
    "model3.add(MaxPooling2D(pool_size=(2, 2)))\n",
    "model3.add(BatchNormalization())\n",
    "\n",
    "model3.add(Conv2D(64, (3, 3)))\n",
    "model3.add(Activation('relu'))\n",
    "model3.add(Conv2D(64, (3, 3)))\n",
    "model3.add(Activation('relu'))\n",
    "model3.add(Conv2D(64, (3, 3)))\n",
    "model3.add(Activation('relu'))\n",
    "model3.add(Conv2D(64, (3, 3)))\n",
    "model3.add(Activation('relu'))\n",
    "model3.add(Conv2D(64, (3, 3)))\n",
    "model3.add(Activation('relu'))\n",
    "model3.add(MaxPooling2D(pool_size=(2, 2)))\n",
    "model3.add(BatchNormalization())\n",
    "\n",
    "model3.add(Conv2D(128, (3, 3)))\n",
    "model3.add(Activation('relu'))\n",
    "model3.add(Conv2D(128, (3, 3)))\n",
    "model3.add(Activation('relu'))\n",
    "model3.add(Conv2D(128, (3, 3)))\n",
    "model3.add(Activation('relu'))\n",
    "model3.add(Conv2D(128, (3, 3)))\n",
    "model3.add(Activation('relu'))\n",
    "model3.add(Conv2D(128, (3, 3)))\n",
    "model3.add(Activation('relu'))\n",
    "model3.add(MaxPooling2D(pool_size=(2, 2)))\n",
    "model3.add(BatchNormalization())\n",
    "          \n",
    "model3.add(Flatten())\n",
    "model3.add(Dropout(0.25))\n",
    "model3.add(Dense(512))\n",
    "model3.add(Activation('relu'))\n",
    "\n",
    "model3.add(Dropout(0.25))\n",
    "model3.add(Dense(256))\n",
    "model3.add(Activation('relu'))\n",
    "\n",
    "model3.add(Dropout(0.25))\n",
    "model3.add(Dense(64))\n",
    "model3.add(Activation('relu')) \n",
    "\n",
    "model3.add(Dropout(0.25))\n",
    "model3.add(Dense(1, activation='sigmoid'))\n",
    "opt = tf.keras.optimizers.RMSprop(0.001)\n",
    "model3.compile(loss='binary_crossentropy', optimizer=opt, metrics=['accuracy'])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "75f8b4ec",
   "metadata": {},
   "outputs": [],
   "source": [
    "model3.summary()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "970714e0",
   "metadata": {},
   "outputs": [],
   "source": [
    "STEP_SIZE_TRAIN=train_generator.n//train_generator.batch_size\n",
    "STEP_SIZE_VALID=valid_generator.n//valid_generator.batch_size\n",
    "\n",
    "history3 = model3.fit_generator(generator=train_generator,\n",
    "                    steps_per_epoch=STEP_SIZE_TRAIN,\n",
    "                    validation_data=valid_generator,\n",
    "                    validation_steps=STEP_SIZE_VALID,\n",
    "                    epochs=30, verbose=1\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "acd1c2e3",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.plot(history3.history['accuracy'])\n",
    "plt.plot(history3.history['val_accuracy'])\n",
    "plt.title('model3 accuracy')\n",
    "plt.ylabel('accuracy')\n",
    "plt.xlabel('epoch')\n",
    "plt.legend(['train', 'val'], loc='upper left')\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "025ddfb5",
   "metadata": {},
   "outputs": [],
   "source": [
    "#next model with 3 sets of 5 convolutional layers, using prelu activations\n",
    "model4 = Sequential()\n",
    "model4.add(Conv2D(32, (3, 3), padding='same',input_shape=(96,96,3)))\n",
    "model4.add(PReLU(alpha_initializer=Constant(value=0.25)))\n",
    "model4.add(Conv2D(32, (3, 3)))\n",
    "model4.add(PReLU(alpha_initializer=Constant(value=0.25)))\n",
    "model4.add(Conv2D(32, (3, 3)))\n",
    "model4.add(PReLU(alpha_initializer=Constant(value=0.25)))\n",
    "model4.add(Conv2D(32, (3, 3)))\n",
    "model4.add(PReLU(alpha_initializer=Constant(value=0.25)))\n",
    "model4.add(Conv2D(32, (3, 3)))\n",
    "model4.add(PReLU(alpha_initializer=Constant(value=0.25)))\n",
    "model4.add(MaxPooling2D(pool_size=(2, 2)))\n",
    "model4.add(BatchNormalization())\n",
    "\n",
    "model4.add(Conv2D(64, (3, 3)))\n",
    "model4.add(PReLU(alpha_initializer=Constant(value=0.25)))\n",
    "model4.add(Conv2D(64, (3, 3)))\n",
    "model4.add(PReLU(alpha_initializer=Constant(value=0.25)))\n",
    "model4.add(Conv2D(64, (3, 3)))\n",
    "model4.add(PReLU(alpha_initializer=Constant(value=0.25)))\n",
    "model4.add(Conv2D(64, (3, 3)))\n",
    "model4.add(PReLU(alpha_initializer=Constant(value=0.25)))\n",
    "model4.add(Conv2D(64, (3, 3)))\n",
    "model4.add(PReLU(alpha_initializer=Constant(value=0.25)))\n",
    "model4.add(MaxPooling2D(pool_size=(2, 2)))\n",
    "model4.add(BatchNormalization())\n",
    "\n",
    "model4.add(Conv2D(128, (3, 3)))\n",
    "model4.add(PReLU(alpha_initializer=Constant(value=0.25)))\n",
    "model4.add(Conv2D(128, (3, 3)))\n",
    "model4.add(PReLU(alpha_initializer=Constant(value=0.25)))\n",
    "model4.add(Conv2D(128, (3, 3)))\n",
    "model4.add(PReLU(alpha_initializer=Constant(value=0.25)))\n",
    "model4.add(Conv2D(128, (3, 3)))\n",
    "model4.add(PReLU(alpha_initializer=Constant(value=0.25)))\n",
    "model4.add(Conv2D(128, (3, 3)))\n",
    "model4.add(PReLU(alpha_initializer=Constant(value=0.25)))\n",
    "model4.add(MaxPooling2D(pool_size=(2, 2)))\n",
    "model4.add(BatchNormalization())\n",
    "          \n",
    "model4.add(Flatten())\n",
    "model4.add(Dropout(0.25))\n",
    "model4.add(Dense(512))\n",
    "model4.add(PReLU(alpha_initializer=Constant(value=0.25)))\n",
    "\n",
    "model4.add(Dropout(0.25))\n",
    "model4.add(Dense(256))\n",
    "model4.add(PReLU(alpha_initializer=Constant(value=0.25)))\n",
    "\n",
    "model4.add(Dropout(0.25))\n",
    "model4.add(Dense(64))\n",
    "model4.add(PReLU(alpha_initializer=Constant(value=0.25)))\n",
    "\n",
    "model4.add(Dropout(0.25))\n",
    "model4.add(Dense(1, activation='sigmoid'))\n",
    "opt = tf.keras.optimizers.RMSprop(0.001)\n",
    "model4.compile(loss='binary_crossentropy', optimizer=opt, metrics=['accuracy'])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f4102caa",
   "metadata": {},
   "outputs": [],
   "source": [
    "model4.summary()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "08420e0b",
   "metadata": {},
   "outputs": [],
   "source": [
    "STEP_SIZE_TRAIN=train_generator.n//train_generator.batch_size\n",
    "STEP_SIZE_VALID=valid_generator.n//valid_generator.batch_size\n",
    "\n",
    "history4 = model4.fit_generator(generator=train_generator,\n",
    "                    steps_per_epoch=STEP_SIZE_TRAIN,\n",
    "                    validation_data=valid_generator,\n",
    "                    validation_steps=STEP_SIZE_VALID,\n",
    "                    epochs=30, verbose=1\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1e88bf68",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.plot(history4.history['accuracy'])\n",
    "plt.plot(history4.history['val_accuracy'])\n",
    "plt.title('model3 accuracy')\n",
    "plt.ylabel('accuracy')\n",
    "plt.xlabel('epoch')\n",
    "plt.legend(['train', 'val'], loc='upper left')\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0a1ac194",
   "metadata": {},
   "outputs": [],
   "source": [
    "test_set = os.listdir('../input/histopathologic-cancer-detection/test/')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d8715514",
   "metadata": {},
   "outputs": [],
   "source": [
    "test_df = pd.DataFrame(test_set)\n",
    "test_df.columns = ['id']\n",
    "test_df.head()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d51c8665",
   "metadata": {},
   "outputs": [],
   "source": [
    "test_datagen=ImageDataGenerator(rescale=1/255)\n",
    "\n",
    "test_generator=test_datagen.flow_from_dataframe(dataframe=test_df,directory=\"../input/histopathologic-cancer-detection/test/\",\n",
    "                x_col=\"id\",batch_size=64,seed=1234,shuffle=False,\n",
    "                class_mode=None,target_size=(96,96))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f3d83aff",
   "metadata": {},
   "outputs": [],
   "source": [
    "STEP_SIZE_TEST=test_generator.n/2\n",
    "\n",
    "preds = model4.predict_generator(generator=test_generator,steps=STEP_SIZE_TEST, verbose = 1)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6c7dc8d3",
   "metadata": {},
   "outputs": [],
   "source": [
    "predictions = []\n",
    "\n",
    "for pred in preds:\n",
    "    if pred >= 0.5:\n",
    "        predictions.append(1)\n",
    "    else:\n",
    "        predictions.append(0)\n",
    "        \n",
    "predictions[:10]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0588c20c",
   "metadata": {},
   "outputs": [],
   "source": [
    "submission = test_df.copy()\n",
    "submission['id']=submission['id'].str[:-4]\n",
    "submission['label']=predictions\n",
    "submission.head()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7ce13fb4",
   "metadata": {},
   "outputs": [],
   "source": [
    "submission.to_csv('submission.csv',index=False)\n"
   ]
  }
 ],
 "metadata": {},
 "nbformat": 4,
 "nbformat_minor": 5
}

{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "da59ddf9",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from pathlib import Path"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0ab4be33",
   "metadata": {},
   "outputs": [],
   "source": [
    "from typing import List\n",
    "import logging\n",
    "from typing import Optional\n",
    "from functools import partial\n",
    "from typing import Tuple\n",
    "from typing import Union\n",
    "\n",
    "\n",
    "import torch.nn as nn\n",
    "import numpy as np\n",
    "import os\n",
    "import pandas as pd\n",
    "import torch\n",
    "from torch.optim import Adam\n",
    "from torchvision.models.resnet import BasicBlock\n",
    "from torch.utils.data import DataLoader\n",
    "from torch.utils.data import Dataset\n",
    "from PIL import Image\n",
    "from matplotlib import pyplot as plt\n",
    "from torchvision.models.resnet import ResNet\n",
    "from sklearn.metrics import roc_auc_score\n",
    "from torch import Tensor\n",
    "from torchvision import transforms\n",
    "from torch.autograd import Variable\n",
    "import albumentations as A\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e885476b",
   "metadata": {},
   "outputs": [],
   "source": [
    "DATA_FOLDER = '../input/histopathologic-cancer-detection'\n",
    "LABELS = f'{DATA_FOLDER}/train_labels.csv'\n",
    "TRAIN_IMAGES_FOLDER = f'{DATA_FOLDER}/train'\n",
    "SAMPLE_SUBMISSION = f'{DATA_FOLDER}/sample_submission.csv'\n",
    "USE_GPU = torch.cuda.is_available()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "259cd222",
   "metadata": {},
   "outputs": [],
   "source": [
    "USE_GPU\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ca06afec",
   "metadata": {},
   "outputs": [],
   "source": [
    "logging.basicConfig(level='INFO')\n",
    "logger = logging.getLogger()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "715272a6",
   "metadata": {},
   "outputs": [],
   "source": [
    "labels = pd.read_csv(LABELS)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4b3d2f2c",
   "metadata": {},
   "outputs": [],
   "source": [
    "labels\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ac30a011",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Метод для конвертации дата фрейма ответов в нумпай массив \n",
    "def format_labels_for_data_set(labels):\n",
    "    return (labels['label'].values.reshape(-1,1))\n",
    "\n",
    "# Сплит train на тренировочную и валидационную выборки\n",
    "def train_valid_split(df, split_percent, limit_df= 10000 ):\n",
    "#     limit_d -  count of images\n",
    "    df = df.sample(n = df.shape[0])\n",
    "    df = df.iloc[:limit_df]\n",
    "    split = round(limit_df * split_percent / 100)\n",
    "    train = df.iloc[:split]\n",
    "    valid = df.iloc[split:]\n",
    "    return (train, valid)\n",
    "\n",
    "# возвращает полный путь к картинкам из labels sample\n",
    "def format_path_to_images_for_dataset(labels, path):\n",
    "    return [os.path.join(path, f'{f}.tif') for f in labels['id'].values]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "42b04655",
   "metadata": {},
   "outputs": [],
   "source": [
    "# класс, в котором определяется исходный DataSet и делается масштабирование исходных данных\n",
    "class MainDataset(Dataset):\n",
    "    def __init__(self, x_dataset, y_dataset, x_tfms):\n",
    "        self.x_dataset = x_dataset\n",
    "        self.y_dataset = y_dataset\n",
    "        self.x_tfms = x_tfms\n",
    "        \n",
    "    def __len__(self):\n",
    "        return self.x_dataset.__len__() \n",
    "        \n",
    "    def __getitem__(self, index):\n",
    "        x = self.x_dataset[index]\n",
    "        y = self.y_dataset[index]\n",
    "        if x_tfms is not None:\n",
    "            x = self.x_tfms(x)\n",
    "        return x, y\n",
    "\n",
    "# возвращает картинку (с учетом ее полного пути) по индексу\n",
    "class ImageDataset(Dataset):\n",
    "    def __init__(self, path_to_image):\n",
    "        self.path_to_image = path_to_image\n",
    "    \n",
    "    def __len__(self):\n",
    "        return len(self.path_to_image)\n",
    "    \n",
    "    def __getitem__(self, index):\n",
    "        img = Image.open(self.path_to_image[index])\n",
    "        \n",
    "        # Compose a complex augmentation pipeline\n",
    "        augmentation_pipeline = A.Compose([\n",
    "            A.HorizontalFlip(p = 0.5), # apply horizontal flip to 50% of images\n",
    "            A.OneOf(\n",
    "                [\n",
    "                    # apply one of transforms to 50% of images\n",
    "                    A.RandomContrast(), # apply random contrast\n",
    "                    A.RandomGamma(), # apply random gamma\n",
    "                    A.RandomBrightness(limit = -0.1), # apply random brightness\n",
    "                ],\n",
    "                p = 1\n",
    "            ),\n",
    "            A.ShiftScaleRotate(p = 0.5)\n",
    "        ],\n",
    "        p = 1)\n",
    "        \n",
    "        image_aug = augmentation_pipeline(image = np.array(img))['image']\n",
    "        image = Image.fromarray(image_aug, 'RGB')\n",
    "        return image\n",
    "\n",
    "\n",
    "# возвращает label по индексу\n",
    "class LabelDataset(Dataset):\n",
    "    def __init__(self, labels):\n",
    "        self.labels = labels\n",
    "    \n",
    "    def __len__(self):\n",
    "        return len(labels)\n",
    "    \n",
    "    def __getitem__(self, index):\n",
    "        return self.labels[index]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "31f3a125",
   "metadata": {},
   "outputs": [],
   "source": [
    "labels = pd.read_csv(LABELS)\n",
    "sample_submission = pd.read_csv(SAMPLE_SUBMISSION)\n",
    "\n",
    "train, valid = train_valid_split(labels, 70)\n",
    "\n",
    "train_labels = format_labels_for_data_set(train)\n",
    "valid_labels = format_labels_for_data_set(valid)\n",
    "\n",
    "train_images = format_path_to_images_for_dataset(train, TRAIN_IMAGES_FOLDER)\n",
    "valid_images = format_path_to_images_for_dataset(valid, TRAIN_IMAGES_FOLDER)\n",
    "\n",
    "train_images_dataset = ImageDataset(train_images)\n",
    "valid_images_dataset = ImageDataset(valid_images)\n",
    "train_labels_dataset = LabelDataset(train_labels)\n",
    "valid_labels_dataset = LabelDataset(valid_labels)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6cb36ae0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Посмотрим на картинки с аугментацией\n",
    "def implot(dataset, w=2, h=2, cols=12, max_charts = 24 ):\n",
    "    rows = (max_charts) / cols + 1\n",
    "    images = [dataset[3] for i in range(max_charts)]\n",
    "    plt.figure(figsize = (cols * w, rows * h))\n",
    "    plt.tight_layout()\n",
    "    for chart, img in enumerate(images, 1):\n",
    "        ax = plt.subplot(rows, cols, chart)\n",
    "        ax.imshow(np.array(img))\n",
    "        ax.axis('off')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8b8a0cd3",
   "metadata": {},
   "outputs": [],
   "source": [
    "implot(train_images_dataset)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f5cdd6fb",
   "metadata": {},
   "outputs": [],
   "source": [
    "# зададим форматирование и перевод в тензорный вид наших тренировочных данных \n",
    "x_tfms = transforms.Compose([transforms.ToTensor(), \n",
    "                             transforms.Normalize(\n",
    "                                 mean=[0.485, 0.456, 0.406],\n",
    "                                 std=[0.229, 0.224, 0.225]\n",
    "                             )\n",
    "                            ])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "78832b6f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# определим объеккты из данных и ответов для загрузки в data loader\n",
    "train_dataset = MainDataset(train_images_dataset, train_labels_dataset, x_tfms)\n",
    "valid_dataset = MainDataset(valid_images_dataset, valid_labels_dataset, x_tfms)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ec7ff532",
   "metadata": {},
   "outputs": [],
   "source": [
    " \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3fa5d5c3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# загружаем данные в data loader, определяем число батчей\n",
    "shuffle = True\n",
    "batch_size = 512\n",
    "num_workers = 0\n",
    "\n",
    "train_dataloader = DataLoader(train_dataset, batch_size = batch_size, shuffle = shuffle, num_workers = num_workers)\n",
    "valid_dataloader = DataLoader(valid_dataset, batch_size = batch_size, shuffle = shuffle, num_workers = num_workers)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "220072a3",
   "metadata": {},
   "outputs": [],
   "source": [
    " \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "01b9af7a",
   "metadata": {},
   "outputs": [],
   "source": [
    "def to_gpu(tensor):\n",
    "    return tensor.cuda() if USE_GPU else tensor\n",
    "\n",
    "def create_resnet9_model(output_dim: int = 1) -> nn.Module:\n",
    "    model = ResNet(BasicBlock, [1, 1, 1, 1])\n",
    "    # размер входящей картинки\n",
    "    in_features = model.fc.in_features\n",
    "    # output size = 1X1\n",
    "    model.avgpool = nn.AdaptiveAvgPool2d(1)\n",
    "    model.fc = nn.Linear(in_features, output_dim)\n",
    "    model = to_gpu(model)\n",
    "    return model\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "81fe1127",
   "metadata": {},
   "outputs": [],
   "source": [
    "resnet9 = create_resnet9_model()\n",
    "resnet9\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2342adb3",
   "metadata": {},
   "outputs": [],
   "source": [
    "lr = 1e-3\n",
    "optimizer = Adam(resnet9.parameters(), lr)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0547a90d",
   "metadata": {},
   "outputs": [],
   "source": [
    "loss = nn.BCEWithLogitsLoss()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1d8a014f",
   "metadata": {},
   "outputs": [],
   "source": [
    "def auc_writer(y_true, y_predicted, iteration):\n",
    "    try:\n",
    "        score = roc_auc_score(np.vstack(y_true), np.vstack(y_predicted))\n",
    "    except:\n",
    "        score = -1\n",
    "    print(f'iteration: {iteration}, roc_auc: {score}')\n",
    "    logger.info(f'iteration: {iteration}, roc_auc: {score}')    \n",
    "    \n",
    "loss_writer_train = auc_writer\n",
    "loss_writer_valid = auc_writer\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c9c4a259",
   "metadata": {},
   "outputs": [],
   "source": [
    " \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "303305f6",
   "metadata": {},
   "outputs": [],
   "source": [
    "def predict(model, dataloader):\n",
    "    model.eval()\n",
    "    y_true, y_hat = [], []\n",
    "    \n",
    "    for x, y in dataloader:\n",
    "        x = Variable(T(x))\n",
    "        y = Variable(T(y))\n",
    "        output = model(x)\n",
    "        \n",
    "        y_true.append(to_numpy(y))\n",
    "        y_hat.append(to_numpy(output))\n",
    "    \n",
    "    return y_true, y_hat\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8c0b3a4c",
   "metadata": {},
   "outputs": [],
   "source": [
    "def T(tensor):\n",
    "    if not torch.is_tensor(tensor):\n",
    "        tensor = torch.FloatTensor(tensor)\n",
    "    else:\n",
    "        tensor = tensor.type(torch.FloatTensor)\n",
    "    if USE_GPU:\n",
    "        tensor = to_gpu(tensor)\n",
    "    return tensor\n",
    "\n",
    "\n",
    "def to_numpy(tensor):\n",
    "    if type(tensor) == np.array or type(tensor) == np.ndarray:\n",
    "        return np.array(tensor)\n",
    "    elif type(tensor) == Image.Image:\n",
    "        return np.array(tensor)\n",
    "    elif type(tensor) == Tensor:\n",
    "        return tensor.cpu().detach().numpy()\n",
    "    else:\n",
    "        raise ValueError(msg)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9cf4dd3a",
   "metadata": {},
   "outputs": [],
   "source": [
    "def iteration_trigger(iteration, every_x_iteration):\n",
    "    if every_x_iteration == 1:\n",
    "        return True\n",
    "    elif iteration > 0 and iteration % every_x_iteration == 0:\n",
    "        return True\n",
    "    else:\n",
    "        return False\n",
    "    \n",
    "\n",
    "\n",
    "def init_triggers(step = 1, train = 10, valid = 10):\n",
    "    do_step_trigger = partial(iteration_trigger, every_x_iteration = step)\n",
    "    train_loss_trigger = partial(iteration_trigger, every_x_iteration = train)\n",
    "    valid_loss_trigger = partial(iteration_trigger, every_x_iteration = valid)\n",
    "    \n",
    "    return do_step_trigger, train_loss_trigger, valid_loss_trigger\n",
    "\n",
    "\n",
    "do_step_trigger, train_loss_trigger, valid_loss_trigger = init_triggers(1, 10, 20)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "49870022",
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_one_epoch(model, \n",
    "                    train_data_loader, \n",
    "                    valid_data_loader, \n",
    "                    loss, \n",
    "                    optimizer, \n",
    "                    loss_writer_train, \n",
    "                    loss_writer_valid,\n",
    "                    do_step_trigger,\n",
    "                    train_loss_trigger,\n",
    "                    valid_loss_trigger):\n",
    "    \n",
    "    y_true_train, y_hat_train = [], []\n",
    "    for iteration, (x, y) in enumerate(train_data_loader):\n",
    "        x_train = Variable(T(x), requires_grad = True)\n",
    "        y_train = Variable(T(y), requires_grad = True)\n",
    "        \n",
    "        output = model(x_train)\n",
    "        y_true_train.append(to_numpy(y_train))\n",
    "        y_hat_train.append(to_numpy(output))\n",
    "        loss_values = loss(output, y_train)\n",
    "        loss_values.backward()\n",
    "        \n",
    "        #делаем шаг на каждой итерации и сбрасываем градиент\n",
    "        if do_step_trigger(iteration):\n",
    "            optimizer.step()\n",
    "            optimizer.zero_grad()\n",
    "        \n",
    "        # проверяем, если итерация кратна train_step = 10, то тогда записываем в лог значение roc_auc\n",
    "        if train_loss_trigger(iteration):\n",
    "            print('train_loss_trigger: ')\n",
    "            loss_writer_train(y_true_train, y_hat_train, iteration)\n",
    "            y_true_train, y_hat_train = [], []\n",
    "        \n",
    "        # проверяем, если итерация кратна valid_step = 20, то тогда записываем в лог значение roc_auc\n",
    "        if valid_loss_trigger(iteration):\n",
    "            print('valid_loss_trigger:')\n",
    "            y_true_valid, y_hat_valid = predict(model, valid_data_loader)\n",
    "            loss_writer_valid(y_true_valid, y_hat_valid, iteration)\n",
    "        \n",
    "    return model\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e36e55a0",
   "metadata": {},
   "outputs": [],
   "source": [
    "resnet9 = train_one_epoch(resnet9, \n",
    "                    train_dataloader, \n",
    "                    valid_dataloader, \n",
    "                    loss, \n",
    "                    optimizer, \n",
    "                    loss_writer_train, \n",
    "                    loss_writer_valid,\n",
    "                    do_step_trigger,\n",
    "                    train_loss_trigger,\n",
    "                    valid_loss_trigger)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2da80b82",
   "metadata": {},
   "outputs": [],
   "source": [
    "TEST_IMAGES_FOLDER = f'{DATA_FOLDER}/test/'\n",
    "\n",
    "# преобразуем исходные данные сначала в Image, затем в Tensor\n",
    "\n",
    "#сделаем функцию, которая возвращает список названий картинок в папке test\n",
    "def test_image_collection(directory: str) -> List:\n",
    "    images_name = []\n",
    "    for filename in os.listdir(directory):\n",
    "        images_name.append(TEST_IMAGES_FOLDER + filename)\n",
    "    return(images_name)\n",
    "\n",
    "test_image = test_image_collection(TEST_IMAGES_FOLDER)\n",
    "test_images_dataset = ImageDataset(test_image)    \n",
    "\n",
    "# зададим форматирование и перевод в тензорный вид наших тестовых данных \n",
    "class TestDataset(Dataset):\n",
    "    def __init__(self, x_dataset: Dataset, x_tfms: Optional = None):\n",
    "        self.x_dataset = x_dataset\n",
    "        self.x_tfms = x_tfms\n",
    "        \n",
    "    def __len__(self) -> int:\n",
    "        return self.x_dataset.__len__() \n",
    "        \n",
    "    def __getitem__(self, index: int) -> Tuple:\n",
    "        x = self.x_dataset[index]\n",
    "        if x_tfms is not None:\n",
    "            x = self.x_tfms(x)\n",
    "        return x\n",
    "    \n",
    "test_dataset = TestDataset(test_images_dataset, x_tfms)    \n",
    "\n",
    "# загружаем данные в data loader, определяем число батчей\n",
    "batch_size = 512\n",
    "num_workers = 0\n",
    "shuffle = False\n",
    "\n",
    "test_dataloader = DataLoader(test_dataset, batch_size = batch_size, shuffle = shuffle, num_workers = num_workers)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3587c70f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# определим функцию предсказания для тестовой выборки\n",
    "def predict_test(model, dataloader):\n",
    "    model.eval()\n",
    "    y_hat = []\n",
    "    \n",
    "    for x in dataloader:\n",
    "        x = Variable(T(x))\n",
    "        output = model(x)\n",
    "        \n",
    "        y_hat.append(to_numpy(output))\n",
    "    return y_hat\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c0731876",
   "metadata": {},
   "outputs": [],
   "source": [
    "# сделаем предсказания для тестовой выборки\n",
    "y_hat_test = predict_test(resnet9, test_dataloader)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1ae32e95",
   "metadata": {},
   "outputs": [],
   "source": [
    "# запишем ответы в DataFrame\n",
    "predictions = pd.DataFrame(\n",
    "    list(\n",
    "        zip(\n",
    "            test_image,\n",
    "            np.vstack(y_hat_test).reshape(-1)\n",
    "        )\n",
    "    ), \n",
    "     columns=['id', 'label'])\n",
    "predictions['id'] = predictions['id'].apply(lambda x: x.split('/')[-1].split('.')[0]) \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "287e7a18",
   "metadata": {},
   "outputs": [],
   "source": [
    "predictions.to_csv('submission.csv', index=False)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0d348120",
   "metadata": {},
   "outputs": [],
   "source": [
    "predictions\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "18a78856",
   "metadata": {},
   "outputs": [],
   "source": [
    "#определим метод для отображения картинок\n",
    "max_charts = 60\n",
    "def implot_errors(files, w=2, h=2, cols=12):\n",
    "    rows = len(files) / cols + 1\n",
    "    images = [Image.open(f) for f in files]\n",
    "    plt.figure(figsize = (cols * w, rows * h))\n",
    "    plt.tight_layout()\n",
    "    for chart, img in enumerate(images, 1):\n",
    "        ax = plt.subplot(rows, cols, chart)\n",
    "        ax.imshow(np.array(img))\n",
    "        ax.axis('off')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2ac58fd8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# сделаем таблицу с предсказаниями и реальными значениями на валидационной выборке\n",
    "y_true, y_hat = predict(resnet9, valid_dataloader)\n",
    "\n",
    "predictions_comparison = pd.DataFrame(\n",
    "    list(\n",
    "        zip(\n",
    "            valid_labels.reshape(-1), \n",
    "            np.vstack(y_hat).reshape(-1),\n",
    "            valid_images\n",
    "        )\n",
    "    ), \n",
    "     columns=['true', 'pred', 'files'])\n",
    "\n",
    "predictions_comparison.head(3)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6a941533",
   "metadata": {},
   "outputs": [],
   "source": [
    "files = predictions_comparison[predictions_comparison['true']==1].sort_values('pred')['files'].values[:max_charts]\n",
    "implot_errors(files)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ddef87a1",
   "metadata": {},
   "outputs": [],
   "source": [
    "files = predictions_comparison[predictions_comparison['true']==0].sort_values('pred', ascending=False)['files'].values[:max_charts]\n",
    "implot_errors(files)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0de3f15d",
   "metadata": {},
   "outputs": [],
   "source": [
    "files = predictions_comparison[predictions_comparison['true']==1].sort_values('pred', ascending=False)['files'].values[:max_charts]\n",
    "implot_errors(files)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6f7620e1",
   "metadata": {},
   "outputs": [],
   "source": [
    "files = predictions_comparison[predictions_comparison['true']==0].sort_values('pred', ascending=True)['files'].values[:max_charts]\n",
    "implot_errors(files)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e16a0b6e",
   "metadata": {},
   "outputs": [],
   "source": [
    " \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7685782d",
   "metadata": {},
   "outputs": [],
   "source": [
    " \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "076d7a03",
   "metadata": {},
   "outputs": [],
   "source": [
    " \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "40f69acb",
   "metadata": {},
   "outputs": [],
   "source": [
    " \n"
   ]
  }
 ],
 "metadata": {},
 "nbformat": 4,
 "nbformat_minor": 5
}

{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "4ffebd70",
      "metadata": {},
      "outputs": [],
      "source": [
        "import pandas as pd\n",
        "from pathlib import Path"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "48fc40fc",
      "metadata": {},
      "outputs": [],
      "source": [
        "import os\n",
        "import cv2\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "import tensorflow as tf\n",
        "from tensorflow.keras import backend as K\n",
        "import keras_tuner as kt\n",
        "import matplotlib.pyplot as plt\n",
        "import matplotlib.image as mpimg\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "66d89fdb",
      "metadata": {},
      "outputs": [],
      "source": [
        "strategy = tf.distribute.MirroredStrategy()\n",
        "print(f\"Number of devices: {strategy.num_replicas_in_sync}\")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "05042bb6",
      "metadata": {},
      "outputs": [],
      "source": [
        "PATH = '/kaggle/input/dog-breed-identification'\n",
        "NUM_CHANNEL = 3\n",
        "INPUT_SHAPE = 256\n",
        "BATCH_SIZE = 32 * strategy.num_replicas_in_sync\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "b8318be3",
      "metadata": {},
      "outputs": [],
      "source": [
        "class ImageDatastore:\n",
        "    \n",
        "    def __init__(self, path, csv, output_shape, train_val_test):\n",
        "        self.path = path\n",
        "        self.csv = csv\n",
        "        self.output_shape = output_shape\n",
        "        self.train_val_test = train_val_test\n",
        "        self.image_paths, self.labels = self.get_files_and_labels()\n",
        "        \n",
        "    def get_files_and_labels(self):\n",
        "        image_paths = [os.path.join(self.path, path) + '.jpg' for path in self.csv.index]\n",
        "        if self.train_val_test == 'test':\n",
        "            labels = ['' for i in range(len(image_paths))]\n",
        "        else:\n",
        "            labels = pd.get_dummies(self.csv.breed).astype('uint8').to_numpy()\n",
        "        return image_paths, labels\n",
        "    \n",
        "    def __call__(self):\n",
        "        pairs = list(zip(self.image_paths, self.labels))\n",
        "        for image_path, label in pairs:\n",
        "            image = cv2.imread(image_path)\n",
        "            image = cv2.resize(image, self.output_shape)\n",
        "            image = cv2.cvtColor(image, cv2.COLOR_BGR2RGB)\n",
        "            if self.train_val_test == 'test':\n",
        "                yield image\n",
        "            else:\n",
        "                yield image, label\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "95176f1f",
      "metadata": {},
      "outputs": [],
      "source": [
        "class CustomCallback(tf.keras.callbacks.Callback):\n",
        "    def __init__(self, monitor=\"loss\", factor=0.5, patience=0, min_lr=0.01):\n",
        "        super(CustomCallback, self).__init__()\n",
        "        self.monitor = monitor\n",
        "        self.factor = factor\n",
        "        self.patience = patience\n",
        "        self.min_lr = min_lr\n",
        "        self.job = 0\n",
        "\n",
        "    def on_train_begin(self, logs=None):\n",
        "        self.wait = 0\n",
        "        self.stopped_epoch = 0\n",
        "        if 'loss' in self.monitor:\n",
        "            self.best = np.inf\n",
        "        else:\n",
        "            self.best = -1\n",
        "\n",
        "    def on_epoch_end(self, epoch, logs=None):\n",
        "        current = logs.get(self.monitor)\n",
        "        if 'loss' in self.monitor and current < self.best:\n",
        "            self.best = current\n",
        "            self.wait = 0\n",
        "        elif 'acc' in self.monitor and  current > self.best:\n",
        "            self.best = current\n",
        "            self.wait = 0\n",
        "        else:\n",
        "            self.wait += 1\n",
        "            if self.wait >= self.patience:\n",
        "                if self.job == 0:\n",
        "                    lr = float(K.get_value(self.model.optimizer.learning_rate))\n",
        "                    new_lr = lr * self.factor\n",
        "                    if new_lr < self.min_lr:\n",
        "                        new_lr = self.min_lr\n",
        "                        self.job = 1\n",
        "                    K.set_value(self.model.optimizer.lr, new_lr)\n",
        "                    self.wait = 0\n",
        "                    print(f\"\\nLearning rate reduced from {'{:.3g}'.format(lr)} to {'{:.3g}'.format(new_lr)}\")\n",
        "                elif self.job == 1:\n",
        "                    self.stopped_epoch = epoch\n",
        "                    self.model.stop_training = True\n",
        "\n",
        "    def on_train_end(self, logs=None):\n",
        "        if self.stopped_epoch > 0:\n",
        "            print(f\"Epoch {self.stopped_epoch + 1}: early stopping\")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "cdeba886",
      "metadata": {},
      "outputs": [],
      "source": [
        "train_df = pd.read_csv(os.path.join(PATH, 'labels.csv'), index_col='id')\n",
        "train_df.head()\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "482088ef",
      "metadata": {},
      "outputs": [],
      "source": [
        "train_df.value_counts().plot.pie(autopct='%%%.2f', figsize=(25, 50));\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "945610d1",
      "metadata": {},
      "outputs": [],
      "source": [
        "samples = train_df.sample(6)\n",
        "plt.figure(figsize=(12, 8))\n",
        "\n",
        "for i, index in enumerate(samples.index):\n",
        "    plt.subplot(230 + i + 1)\n",
        "    img = mpimg.imread(os.path.join(PATH, 'train', index + '.jpg'))\n",
        "    plt.imshow(img)\n",
        "    plt.axis('off')\n",
        "    plt.title(f'True Class: {samples.loc[[index], \"breed\"].values[0]}')\n",
        "    \n",
        "plt.tight_layout()\n",
        "plt.show()\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "cfd9b9d3",
      "metadata": {},
      "outputs": [],
      "source": [
        "NUM_CLASS = train_df.breed.nunique()\n",
        "print(f'Number of classes: {NUM_CLASS}')\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "bcc91be5",
      "metadata": {},
      "outputs": [],
      "source": [
        "val_ratio = 0.2\n",
        "num_sapmle = int(len(train_df) * val_ratio / NUM_CLASS)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "52106499",
      "metadata": {},
      "outputs": [],
      "source": [
        "val_df = pd.concat([train_df[train_df.breed == lbl].sample(num_sapmle) for lbl in train_df.breed.unique()], axis=0)\n",
        "val_df = val_df.sample(frac=1)\n",
        "\n",
        "train_df = train_df.drop(val_df.index)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "f736c4fc",
      "metadata": {},
      "outputs": [],
      "source": [
        "print(f'''Number of train images: {len(train_df)}\n",
        "Number of val images: {len(val_df)}''')\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "764b4e25",
      "metadata": {},
      "outputs": [],
      "source": [
        "train_ds = ImageDatastore(os.path.join(PATH, 'train'), train_df, (INPUT_SHAPE, INPUT_SHAPE), 'train')\n",
        "val_ds = ImageDatastore(os.path.join(PATH, 'train'), val_df, (INPUT_SHAPE, INPUT_SHAPE), 'val')\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "15eb2361",
      "metadata": {},
      "outputs": [],
      "source": [
        "data_augmentation = tf.keras.Sequential([\n",
        "    tf.keras.layers.RandomFlip(),\n",
        "    tf.keras.layers.RandomRotation(0.2),\n",
        "    tf.keras.layers.RandomZoom(0.2)\n",
        "])\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "bf5a9a4e",
      "metadata": {},
      "outputs": [],
      "source": [
        "OUTPUT_SIGNATURE = (tf.TensorSpec(shape=(INPUT_SHAPE, INPUT_SHAPE, NUM_CHANNEL), dtype='uint8'), tf.TensorSpec(shape=(NUM_CLASS), dtype='uint8'))\n",
        "\n",
        "train = tf.data.Dataset.from_generator(generator=train_ds, output_signature=OUTPUT_SIGNATURE)\n",
        "train = tf.data.Dataset.range(1).interleave(lambda _: train, num_parallel_calls=tf.data.AUTOTUNE).batch(batch_size=BATCH_SIZE, drop_remainder=True).map(lambda X, y: (data_augmentation(X, training=True), y), num_parallel_calls=tf.data.AUTOTUNE).cache().prefetch(buffer_size=tf.data.AUTOTUNE)\n",
        "\n",
        "val = tf.data.Dataset.from_generator(generator=val_ds, output_signature=OUTPUT_SIGNATURE)\n",
        "val = tf.data.Dataset.range(1).interleave(lambda _: val, num_parallel_calls=tf.data.AUTOTUNE).batch(batch_size=BATCH_SIZE, drop_remainder=True).cache().prefetch(buffer_size=tf.data.AUTOTUNE)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "9a1d9fea",
      "metadata": {},
      "outputs": [],
      "source": [
        "def build_model(hp):\n",
        "\n",
        "    input_shape = (INPUT_SHAPE, INPUT_SHAPE, NUM_CHANNEL)\n",
        "\n",
        "    base = tf.keras.applications.MobileNetV2(input_shape=input_shape, weights='imagenet', include_top=False, pooling='avg')\n",
        "    base.trainable=False\n",
        "    base.training=False\n",
        "\n",
        "    inputs = tf.keras.Input(shape=input_shape)\n",
        "    \n",
        "    x = tf.keras.applications.mobilenet_v2.preprocess_input(inputs)\n",
        "    x = base(x)\n",
        "    \n",
        "    hp_units = hp.Int('units', min_value=32, max_value=512, step=32)\n",
        "    x=tf.keras.layers.Dense(hp_units)(x)\n",
        "    x=tf.keras.layers.BatchNormalization()(x)\n",
        "    \n",
        "    hp_act = hp.Choice('activation', values=['relu', 'tanh'])\n",
        "    x=tf.keras.layers.Activation(hp_act)(x)\n",
        "    \n",
        "    hp_drop = hp.Float('rate', min_value=0.0, max_value=0.5, step=0.1)\n",
        "    x=tf.keras.layers.Dropout(hp_drop)(x)\n",
        "    \n",
        "    outputs = tf.keras.layers.Dense(NUM_CLASS, activation=\"softmax\")(x)\n",
        "    \n",
        "    model = tf.keras.Model(inputs, outputs)\n",
        "\n",
        "    model.compile(\n",
        "        optimizer=tf.keras.optimizers.Adam(1e-3),\n",
        "        loss=tf.keras.losses.CategoricalCrossentropy(from_logits=False),\n",
        "        metrics=[tf.keras.metrics.CategoricalAccuracy(name=\"accuracy\")],\n",
        "    )\n",
        "    return model\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "2a7f2d21",
      "metadata": {},
      "outputs": [],
      "source": [
        "tuner = kt.Hyperband(\n",
        "    build_model,\n",
        "    objective='val_accuracy',\n",
        "    max_epochs=10,\n",
        "    factor=3,\n",
        "    distribution_strategy=strategy)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "681bb810",
      "metadata": {},
      "outputs": [],
      "source": [
        "tuner.search(train, epochs=10, validation_data=val)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "4dac5c14",
      "metadata": {},
      "outputs": [],
      "source": [
        "best_hps=tuner.get_best_hyperparameters(num_trials=1)[0]\n",
        "\n",
        "print(f\"\"\"\n",
        "The hyperparameter search is complete.\n",
        "The optimal number of units in the first densely-connected layer is {best_hps.get('units')}.\n",
        "The optimal activation for the first densely-connected is {best_hps.get('activation')}.\n",
        "The optimal rate for dropout is {best_hps.get('rate')}.\n",
        "\"\"\")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "0d3df125",
      "metadata": {},
      "outputs": [],
      "source": [
        "with strategy.scope():\n",
        "    model = tuner.hypermodel.build(best_hps)\n",
        "\n",
        "model.summary()\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "482fd2f1",
      "metadata": {},
      "outputs": [],
      "source": [
        "history = model.fit(\n",
        "    train,\n",
        "    epochs=1000,\n",
        "    validation_data=val,\n",
        "    callbacks=[CustomCallback(monitor='val_accuracy', factor=0.5, patience=10, min_lr=2e-6)]\n",
        ")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "3b366da9",
      "metadata": {},
      "outputs": [],
      "source": [
        "plt.plot(history.history['accuracy'])\n",
        "plt.plot(history.history['val_accuracy'])\n",
        "plt.title('Model Accuracy')\n",
        "plt.ylabel('Accuracy')\n",
        "plt.xlabel('Epoch')\n",
        "plt.legend(['train', 'val'], loc='upper left')\n",
        "plt.show()\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "fbfdc199",
      "metadata": {},
      "outputs": [],
      "source": [
        "plt.plot(history.history['loss'])\n",
        "plt.plot(history.history['val_loss'])\n",
        "plt.title('Model Loss')\n",
        "plt.ylabel('Loss')\n",
        "plt.xlabel('Epoch')\n",
        "plt.legend(['train', 'val'], loc='upper left')\n",
        "plt.show()\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "81b3c890",
      "metadata": {},
      "outputs": [],
      "source": [
        "classes = sorted(train_df.breed.unique())\n",
        "print(classes)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "6a480036",
      "metadata": {},
      "outputs": [],
      "source": [
        "plt.figure(figsize=(12, 8))\n",
        "\n",
        "for i, index in enumerate(samples.index):\n",
        "    img = mpimg.imread(os.path.join(PATH, 'train', index + '.jpg'))\n",
        "    \n",
        "    img = cv2.resize(img, (INPUT_SHAPE, INPUT_SHAPE))\n",
        "    pred = model.predict(np.expand_dims(img, 0), verbose=False)\n",
        "    cls_index = np.argmax(pred)\n",
        "    cls_name = classes[cls_index]\n",
        "    \n",
        "    plt.subplot(230 + i + 1)\n",
        "    plt.imshow(img)\n",
        "    plt.axis('off')\n",
        "    plt.title(f'True Class: {samples.loc[[index], \"breed\"].values[0]} \\n Predicted Class: {cls_name}')\n",
        "    \n",
        "plt.tight_layout()\n",
        "plt.show()\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "f6c321cd",
      "metadata": {},
      "outputs": [],
      "source": [
        "sub_test_df = pd.read_csv('/kaggle/input/dog-breed-identification/sample_submission.csv', index_col='id')\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "13433e63",
      "metadata": {},
      "outputs": [],
      "source": [
        "sub_test_ds = ImageDatastore(os.path.join(PATH, 'test'), sub_test_df, (INPUT_SHAPE, INPUT_SHAPE), 'test')\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "a6fbe08f",
      "metadata": {},
      "outputs": [],
      "source": [
        "SUB_OUTPUT_SIGNATURE = (tf.TensorSpec(shape=(INPUT_SHAPE, INPUT_SHAPE, NUM_CHANNEL), dtype='uint8'))\n",
        "sub_test = tf.data.Dataset.from_generator(generator=sub_test_ds, output_signature=SUB_OUTPUT_SIGNATURE)\n",
        "sub_test = tf.data.Dataset.range(1).interleave(lambda _:sub_test, num_parallel_calls=tf.data.AUTOTUNE).batch(batch_size=BATCH_SIZE, drop_remainder=False).cache().prefetch(buffer_size=tf.data.AUTOTUNE)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "a676bc08",
      "metadata": {},
      "outputs": [],
      "source": [
        "pred = model.predict(sub_test)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "35ff138b",
      "metadata": {},
      "outputs": [],
      "source": [
        "sub_test_df.iloc[:] = pred\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "84bb3a1d",
      "metadata": {},
      "outputs": [],
      "source": [
        "sub_test_df.to_csv(os.path.join('/kaggle', 'working', 'submission.csv'))\n",
        "sub_test_df.head()\n"
      ]
    }
  ],
  "metadata": {},
  "nbformat": 4,
  "nbformat_minor": 5
}
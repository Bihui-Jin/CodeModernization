{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "16c17f2e",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from pathlib import Path"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "66b42069",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "\n",
    "import zipfile, os, cv2\n",
    "from tqdm.auto import tqdm\n",
    "import tensorflow as tf\n",
    "\n",
    "from tensorflow.keras.models import Model\n",
    "from tensorflow.keras import layers, callbacks, utils\n",
    "\n",
    "import imgaug as ia\n",
    "from imgaug import augmenters as iaa\n",
    "\n",
    "sns.set_style('darkgrid')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "23c8f17b",
   "metadata": {},
   "outputs": [],
   "source": [
    "path_zip = '../input/denoising-dirty-documents/'\n",
    "path = '/kaggle/working/'\n",
    "\n",
    "with zipfile.ZipFile(path_zip + 'train.zip', 'r') as zip_ref:\n",
    "    zip_ref.extractall(path)\n",
    "\n",
    "with zipfile.ZipFile(path_zip + 'test.zip', 'r') as zip_ref:\n",
    "    zip_ref.extractall(path)  \n",
    "    \n",
    "with zipfile.ZipFile(path_zip + 'train_cleaned.zip', 'r') as zip_ref:\n",
    "    zip_ref.extractall(path)  \n",
    "    \n",
    "with zipfile.ZipFile(path_zip + 'sampleSubmission.csv.zip', 'r') as zip_ref:\n",
    "    zip_ref.extractall(path)\n",
    "    \n",
    "train_img = sorted(os.listdir(path + '/train'))\n",
    "train_cleaned_img = sorted(os.listdir(path + '/train_cleaned'))\n",
    "test_img = sorted(os.listdir(path + '/test'))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "43c8306d",
   "metadata": {},
   "outputs": [],
   "source": [
    "class config():\n",
    "    IMG_SIZE = (420, 540)\n",
    "\n",
    "imgs = [cv2.imread(path + 'train/' + f) for f in sorted(os.listdir(path + 'train/'))]\n",
    "print('Median Dimensions:', np.median([len(img) for img in imgs]), np.median([len(img[0]) for img in imgs]))\n",
    "del imgs\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e7efac4e",
   "metadata": {},
   "outputs": [],
   "source": [
    "def process_image(path):\n",
    "    img = cv2.imread(path)\n",
    "    img = np.asarray(img, dtype=\"float32\")\n",
    "    img = cv2.resize(img, config.IMG_SIZE[::-1])\n",
    "    img = cv2.cvtColor(img, cv2.COLOR_BGR2GRAY)\n",
    "    img = img/255.0\n",
    "    img = np.reshape(img, (*config.IMG_SIZE, 1))\n",
    "    \n",
    "    return img\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "47947efc",
   "metadata": {},
   "outputs": [],
   "source": [
    "train = []\n",
    "train_cleaned = []\n",
    "test = []\n",
    "\n",
    "for f in sorted(os.listdir(path + 'train/')):\n",
    "    train.append(process_image(path + 'train/' + f))\n",
    "\n",
    "for f in sorted(os.listdir(path + 'train_cleaned/')):\n",
    "    train_cleaned.append(process_image(path + 'train_cleaned/' + f))\n",
    "    \n",
    "for f in sorted(os.listdir(path + 'test/')):\n",
    "    test.append(process_image(path + 'test/' + f))\n",
    "    \n",
    "train = np.asarray(train)\n",
    "train_cleaned = np.asarray(train_cleaned)\n",
    "test = np.asarray(test)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "57e67fd4",
   "metadata": {},
   "outputs": [],
   "source": [
    "train.shape, train_cleaned.shape, test.shape\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "88271b78",
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, ax = plt.subplots(4, 2, figsize=(15,25))\n",
    "for i in range(4):\n",
    "    ax[i][0].imshow(tf.squeeze(train[i]), cmap='gray')\n",
    "    ax[i][0].set_title('Noise image: {}'.format(train_img[i]))\n",
    "    \n",
    "    ax[i][1].imshow(tf.squeeze(train_cleaned[i]), cmap='gray')\n",
    "    ax[i][1].set_title('Denoised image: {}'.format(train_img[i]))\n",
    "    \n",
    "    ax[i][0].get_xaxis().set_visible(False)\n",
    "    ax[i][0].get_yaxis().set_visible(False)\n",
    "    ax[i][1].get_xaxis().set_visible(False)\n",
    "    ax[i][1].get_yaxis().set_visible(False)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "79bab28f",
   "metadata": {},
   "outputs": [],
   "source": [
    "def augment_pipeline(pipeline, images, seed=19):\n",
    "    ia.seed(seed)\n",
    "    processed_images = images.copy()\n",
    "    for step in pipeline:\n",
    "        temp = np.array(step.augment_images(images))\n",
    "        processed_images = np.append(processed_images, temp, axis=0)\n",
    "    return(processed_images)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6a67b789",
   "metadata": {},
   "outputs": [],
   "source": [
    "rotate90 = iaa.Rot90(1) # rotate image 90 degrees\n",
    "rotate180 = iaa.Rot90(2) # rotate image 180 degrees\n",
    "rotate270 = iaa.Rot90(3) # rotate image 270 degrees\n",
    "random_rotate = iaa.Rot90((1,3)) # randomly rotate image from 90,180,270 degrees\n",
    "perc_transform = iaa.PerspectiveTransform(scale=(0.02, 0.1)) # Skews and transform images without black bg\n",
    "rotate10 = iaa.Affine(rotate=(10)) # rotate image 10 degrees\n",
    "rotate10r = iaa.Affine(rotate=(-10)) # rotate image 30 degrees in reverse\n",
    "crop = iaa.Crop(px=(5, 32)) # Crop between 5 to 32 pixels\n",
    "hflip = iaa.Fliplr(1) # horizontal flips for 100% of images\n",
    "vflip = iaa.Flipud(1) # vertical flips for 100% of images\n",
    "gblur = iaa.GaussianBlur(sigma=(1, 1.5)) # gaussian blur images with a sigma of 1.0 to 1.5\n",
    "motionblur = iaa.MotionBlur(8) # motion blur images with a kernel size 8\n",
    "\n",
    "seq_rp = iaa.Sequential([\n",
    "    iaa.Rot90((1,3)), # randomly rotate image from 90,180,270 degrees\n",
    "    iaa.PerspectiveTransform(scale=(0.02, 0.1)) # Skews and transform images without black bg\n",
    "])\n",
    "\n",
    "seq_cfg = iaa.Sequential([\n",
    "    iaa.Crop(px=(5, 32)), # crop images from each side by 5 to 32px (randomly chosen)\n",
    "    iaa.Fliplr(0.5), # horizontally flip 50% of the images\n",
    "    iaa.GaussianBlur(sigma=(0, 1.5)) # blur images with a sigma of 0 to 1.5\n",
    "])\n",
    "\n",
    "seq_fm = iaa.Sequential([\n",
    "    iaa.Flipud(1), # vertical flips all the images\n",
    "    iaa.MotionBlur(k=6) # motion blur images with a kernel size 6\n",
    "])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ae9aad5d",
   "metadata": {},
   "outputs": [],
   "source": [
    "pipeline = [\n",
    "    rotate90, rotate180, rotate270, hflip, vflip\n",
    "]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f38e3b12",
   "metadata": {},
   "outputs": [],
   "source": [
    "processed_train = augment_pipeline(pipeline, train)\n",
    "processed_train_cleaned = augment_pipeline(pipeline, train_cleaned)\n",
    "\n",
    "processed_train.shape, processed_train_cleaned.shape\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e010161d",
   "metadata": {},
   "outputs": [],
   "source": [
    "class DenoisingAutoencoder(Model):\n",
    "  def __init__(self):\n",
    "    super(DenoisingAutoencoder, self).__init__()\n",
    "    self.encoder = tf.keras.Sequential([\n",
    "        layers.Input(shape=(*config.IMG_SIZE, 1)), \n",
    "        layers.Conv2D(32, (3, 3), activation='relu', padding='same'),\n",
    "        layers.Conv2D(64, (3, 3), activation='relu', padding='same'),\n",
    "        layers.Conv2D(128, (3, 3), activation='relu', padding='same'),\n",
    "        layers.BatchNormalization(),\n",
    "        layers.MaxPooling2D((2, 2), padding='same'),\n",
    "        layers.Dropout(0.5),\n",
    "    ])\n",
    "\n",
    "    self.decoder = tf.keras.Sequential([\n",
    "        layers.Conv2D(128, (3, 3), activation='relu', padding='same'),\n",
    "        layers.Conv2D(64, (3, 3), activation='relu', padding='same'),\n",
    "        layers.Conv2D(32, (3, 3), activation='relu', padding='same'),\n",
    "        layers.BatchNormalization(),\n",
    "        layers.UpSampling2D((2, 2)),\n",
    "        layers.Conv2D(1, (3, 3), activation='sigmoid', padding='same')\n",
    "    ])\n",
    "\n",
    "  def call(self, x):\n",
    "    encoded = self.encoder(x)\n",
    "    decoded = self.decoder(encoded)\n",
    "    return decoded\n",
    "\n",
    "autoencoder = DenoisingAutoencoder()\n",
    "autoencoder.compile(optimizer='adam', loss='mean_squared_error', metrics=['mean_absolute_error'])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8f35fe47",
   "metadata": {},
   "outputs": [],
   "source": [
    "es = callbacks.EarlyStopping(\n",
    "    monitor='loss', patience=30, verbose=1, restore_best_weights=True\n",
    ")\n",
    "\n",
    "# rlp = callbacks.ReduceLROnPlateau(\n",
    "#     monitor='loss', factor=0.5, patience=3, min_lr=1e-6, mode='min', verbose=1\n",
    "# )\n",
    "\n",
    "history =  autoencoder.fit(\n",
    "    processed_train, processed_train_cleaned, \n",
    "#     train, train_cleaned,\n",
    "#     validation_split=0.1, \n",
    "    shuffle=True,\n",
    "    callbacks=[es], epochs=500, batch_size=12\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f0460fe9",
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, ax = plt.subplots(figsize=(20, 6))\n",
    "pd.DataFrame(history.history).plot(ax=ax)\n",
    "del history\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6b5e0a39",
   "metadata": {},
   "outputs": [],
   "source": [
    "autoencoder.encoder.summary()\n",
    "autoencoder.decoder.summary()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "54f92c00",
   "metadata": {},
   "outputs": [],
   "source": [
    "decoded_imgs = autoencoder(train[:4]).numpy()\n",
    "    \n",
    "fig, ax = plt.subplots(4, 2, figsize=(15,25))\n",
    "for i in range(4):\n",
    "    ax[i][0].imshow(tf.squeeze(train_cleaned[i]), cmap='gray')\n",
    "    ax[i][0].set_title('Denoised image: {}'.format(train_img[i]))\n",
    "    \n",
    "    ax[i][1].imshow(tf.squeeze(decoded_imgs[i]), cmap='gray')\n",
    "    ax[i][1].set_title('Predicted image: {}'.format(train_img[i]))\n",
    "    \n",
    "    ax[i][0].get_xaxis().set_visible(False)\n",
    "    ax[i][0].get_yaxis().set_visible(False)\n",
    "    ax[i][1].get_xaxis().set_visible(False)\n",
    "    ax[i][1].get_yaxis().set_visible(False)    \n",
    "\n",
    "del decoded_imgs    \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0fa70d59",
   "metadata": {},
   "outputs": [],
   "source": [
    "ids = []\n",
    "vals = []\n",
    "for i, f in tqdm(enumerate(test_img)):\n",
    "    file = path + 'test/' + f\n",
    "    imgid = int(f[:-4])\n",
    "    img = cv2.imread(file, 0)\n",
    "    img_shape = img.shape\n",
    "    decoded_img = np.squeeze(autoencoder.decoder(autoencoder.encoder(test[i:i+1]).numpy()).numpy())\n",
    "    preds_reshaped = cv2.resize(decoded_img, (img_shape[1], img_shape[0]))\n",
    "\n",
    "    for r in range(img_shape[0]):\n",
    "        for c in range(img_shape[1]):\n",
    "            ids.append(str(imgid)+'_'+str(r + 1)+'_'+str(c + 1))\n",
    "            vals.append(preds_reshaped[r, c])\n",
    "\n",
    "print('Length of IDs: {}'.format(len(ids)))            \n",
    "pd.DataFrame({'id': ids, 'value': vals}).to_csv('submission.csv',index=False)\n",
    "print('Results saved to submission.csv!')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8ae1857f",
   "metadata": {},
   "outputs": [],
   "source": [
    " \n"
   ]
  }
 ],
 "metadata": {},
 "nbformat": 4,
 "nbformat_minor": 5
}

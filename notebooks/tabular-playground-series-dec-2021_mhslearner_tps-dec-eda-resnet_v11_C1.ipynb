{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "93ac131b",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from pathlib import Path"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e8ffcf8a",
   "metadata": {},
   "outputs": [],
   "source": [
    "##from INTERNET import everything xxxxD/\n",
    "import numpy as np # linear algebra\n",
    "import pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)    \n",
    "import matplotlib as mat\n",
    "import matplotlib.pyplot as plt    \n",
    "import seaborn as sns\n",
    "import random\n",
    "import os\n",
    "import gc\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.model_selection import StratifiedKFold\n",
    "from sklearn.metrics import accuracy_score\n",
    "from sklearn.preprocessing import  LabelEncoder, RobustScaler , MinMaxScaler ,StandardScaler\n",
    "import tensorflow as tf \n",
    "from tensorflow import keras\n",
    "import tensorflow_addons as tfa\n",
    "import tensorflow.keras.backend as K \n",
    "from tensorflow.keras import layers\n",
    "from tensorflow.keras.utils import to_categorical ,plot_model\n",
    "from tensorflow.keras import callbacks\n",
    "from tensorflow.keras.layers import Dense, Dropout, Input, InputLayer, Flatten \n",
    "from tensorflow.random import set_seed\n",
    "set_seed(42)\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "sns.set_style(\"whitegrid\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "66838478",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_data = pd.read_csv(\"../input/tabular-playground-series-dec-2021/train.csv\")\n",
    "test_data= pd.read_csv(\"../input/tabular-playground-series-dec-2021/test.csv\")\n",
    "sample = pd.read_csv(\"../input/tabular-playground-series-dec-2021/sample_submission.csv\")\n",
    "train_data =train_data[train_data.Cover_Type != 5] # drop class 5 \n",
    "train= train_data.drop('Id', axis=1) # drop unused id \n",
    "test= test_data.drop('Id', axis=1)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0bbdb7ab",
   "metadata": {},
   "outputs": [],
   "source": [
    "train.head(3)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "856c09fc",
   "metadata": {},
   "outputs": [],
   "source": [
    "train.describe().style.background_gradient(cmap='RdPu')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "27c9e211",
   "metadata": {},
   "outputs": [],
   "source": [
    "# variables variaition   \n",
    "df_var=train.var().reset_index()\n",
    "df_var.columns =['feature', 'variation']\n",
    "df_var.sort_values(\"variation\",ascending = True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c53af4db",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Correlation matrix\n",
    "corrMatrix =train.corr(method='pearson', min_periods=1)\n",
    "corrMatrix.style.background_gradient(axis=None)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1385f18d",
   "metadata": {},
   "outputs": [],
   "source": [
    "cor_targ = train.corrwith(train[\"Cover_Type\"]).reset_index()\n",
    "cor_targ.columns =['feature', 'CorrelatioWithTarget']\n",
    "cor_targ.sort_values('CorrelatioWithTarget',ascending = False)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "685e6e74",
   "metadata": {},
   "outputs": [],
   "source": [
    "ax = plt.figure(figsize=(12, 6))\n",
    "cover_type= train['Cover_Type'].value_counts().sort_index()\n",
    "sns.barplot(x=cover_type.index, y=cover_type,palette=\"BuPu_r\")\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9de44bf6",
   "metadata": {},
   "outputs": [],
   "source": [
    "test.head(3)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5c12f995",
   "metadata": {},
   "outputs": [],
   "source": [
    "test.describe().style.background_gradient(axis =1)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b222c12b",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(15,8))\n",
    "features = train.columns.values[0:54]\n",
    "sns.distplot(train[features].mean(axis=1),color=\"red\", kde=True,bins=120, label='train')\n",
    "sns.distplot(test[features].mean(axis=1),color=\"darkblue\", kde=True,bins=120, label='test')\n",
    "plt.title(\"Distribution of mean values per row in the train and test data\")\n",
    "plt.legend()\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "95f18e88",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(15,5))\n",
    "sns.distplot(train[features].mean(axis=0),color=\"orange\",kde=True,bins=120, label='train')\n",
    "sns.distplot(test[features].mean(axis=0),color=\"blue\", kde=True,bins=120, label='test')\n",
    "plt.title(\"Distribution of mean values per column in the train and test set\")\n",
    "plt.legend()\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8a7faa34",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(15,5))\n",
    "sns.distplot(train[features].std(axis=1),color=\"#2F4F4F\", kde=True,bins=120, label='train')\n",
    "sns.distplot(test[features].std(axis=1),color=\"#FF6347\", kde=True,bins=120, label='test')\n",
    "plt.title(\"Distribution of std per row in the train and test data \")\n",
    "plt.legend()\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6c3c22b6",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(15,5))\n",
    "sns.distplot(train[features].std(axis=0),color=\"#778899\",kde=True,bins=120, label='train')\n",
    "sns.distplot(test[features].std(axis=0),color=\"#800080\", kde=True,bins=120, label='test')\n",
    "plt.title(\"Distribution of std per column in the train and test data\")\n",
    "plt.legend()\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "54349b5f",
   "metadata": {},
   "outputs": [],
   "source": [
    "num_cols = [\n",
    "    \"Elevation\",\n",
    "    \"Aspect\",\n",
    "    \"Slope\",\n",
    "    \"Horizontal_Distance_To_Hydrology\",\n",
    "    \"Vertical_Distance_To_Hydrology\",\n",
    "     \"Horizontal_Distance_To_Roadways\",\n",
    "    \"Hillshade_9am\",\n",
    "    \"Hillshade_Noon\",\n",
    "    \"Hillshade_3pm\",\n",
    "    \"Horizontal_Distance_To_Fire_Points\",\n",
    "]\n",
    "i = 1\n",
    "plt.figure()\n",
    "fig, ax = plt.subplots(figsize=(18, 15))\n",
    "for col in num_cols:\n",
    "    plt.subplot(5,3,i)\n",
    "    sns.distplot(train[col],color=\"yellow\", kde=True,bins=100, label='train')\n",
    "    sns.distplot(test[col],color=\"Darkblue\", kde=True,bins=100, label='test')\n",
    "    i += 1\n",
    "plt.legend()\n",
    "plt.title(\" numirical features Distribution in both train and test data\")  \n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6b4cf5d2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# remove unuseful features\n",
    "train = train.drop([ 'Soil_Type7', 'Soil_Type15','Soil_Type1'], axis=1)\n",
    "test= test.drop(['Soil_Type7', 'Soil_Type15','Soil_Type1'], axis=1)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9ac7f888",
   "metadata": {},
   "outputs": [],
   "source": [
    "y_target = train[\"Cover_Type\"].copy() ##target variable \n",
    "X_train = train.copy().drop(\"Cover_Type\",axis = 1) ##train data \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c55648c8",
   "metadata": {},
   "outputs": [],
   "source": [
    "def reduce_mem_usage(df, verbose=True):\n",
    "    numerics = ['int16', 'int32', 'int64', 'float16', 'float32', 'float64']\n",
    "    start_mem = df.memory_usage().sum() / 1024**2\n",
    "\n",
    "    for col in df.columns:\n",
    "        col_type = df[col].dtypes\n",
    "\n",
    "        if col_type in numerics:\n",
    "            c_min = df[col].min()\n",
    "            c_max = df[col].max()\n",
    "\n",
    "            if str(col_type)[:3] == 'int':\n",
    "                if c_min > np.iinfo(np.int8).min and c_max < np.iinfo(np.int8).max:\n",
    "                    df[col] = df[col].astype(np.int8)\n",
    "                elif c_min > np.iinfo(np.int16).min and c_max < np.iinfo(np.int16).max:\n",
    "                    df[col] = df[col].astype(np.int16)\n",
    "                elif c_min > np.iinfo(np.int32).min and c_max < np.iinfo(np.int32).max:\n",
    "                    df[col] = df[col].astype(np.int32)\n",
    "                elif c_min > np.iinfo(np.int64).min and c_max < np.iinfo(np.int64).max:\n",
    "                    df[col] = df[col].astype(np.int64)  \n",
    "            else:\n",
    "                if c_min > np.finfo(np.float32).min and c_max < np.finfo(np.float32).max:\n",
    "                    df[col] = df[col].astype(np.float32)\n",
    "                else:\n",
    "                    df[col] = df[col].astype(np.float64)\n",
    "\n",
    "    end_mem = df.memory_usage().sum() / 1024**2\n",
    "\n",
    "    if verbose:\n",
    "        print('Mem. usage decreased to {:5.2f} Mb ({:.1f}% reduction)'.format(end_mem, 100 * (start_mem - end_mem) / start_mem))\n",
    " \n",
    "    return df\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2cf27853",
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "X_train = reduce_mem_usage(X_train)\n",
    "test = reduce_mem_usage(test)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2eee8984",
   "metadata": {},
   "outputs": [],
   "source": [
    "# i expriment it with skew abd sumÃ¹ variable but it hurted the performance by -0.0003\n",
    "#you can expriment with others using the same model or other models \n",
    "\n",
    "def stat_features(df):\n",
    "    #df['f_mean'] = df.mean(axis=1)\n",
    "    #df['f_std']  = df.std(axis=1)\n",
    "    df['r_skew'] = df.skew(axis=1)\n",
    "    df['r_sum'] = df.sum(axis=1)\n",
    "    return df\n",
    "\n",
    "#X_train = stat_features(train_df)\n",
    "#test = stat_features(test_df)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "45e23112",
   "metadata": {},
   "outputs": [],
   "source": [
    "### delet it \n",
    "del train_data \n",
    "del test_data \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2f9da98c",
   "metadata": {},
   "outputs": [],
   "source": [
    "num_cols = [\n",
    "    \"Elevation\",\n",
    "    \"Aspect\",\n",
    "    \"Slope\",\n",
    "    \"Horizontal_Distance_To_Hydrology\",\n",
    "    \"Vertical_Distance_To_Hydrology\",\n",
    "     \"Horizontal_Distance_To_Roadways\",\n",
    "    \"Hillshade_9am\",\n",
    "    \"Hillshade_Noon\",\n",
    "    \"Hillshade_3pm\",\n",
    "    \"Horizontal_Distance_To_Fire_Points\",\n",
    "]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5b935598",
   "metadata": {},
   "outputs": [],
   "source": [
    "scaler =  StandardScaler()\n",
    "X_train[num_cols] = scaler.fit_transform(X_train[num_cols])\n",
    "test[num_cols]= scaler.transform(test[num_cols])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "36c060ee",
   "metadata": {},
   "outputs": [],
   "source": [
    "i = 1\n",
    "plt.figure()\n",
    "fig, ax = plt.subplots(figsize=(18, 15))\n",
    "for col in num_cols:\n",
    "    plt.subplot(4,4,i)\n",
    "    sns.distplot(X_train[col],color=\"yellow\", kde=True, label='train')\n",
    "    sns.distplot(test[col],color=\"Darkblue\", kde=True, label='test')\n",
    "    i += 1\n",
    "plt.legend()\n",
    "plt.title(\" numirical featur Distribution after normalization in both train and test data\")  \n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6b946f17",
   "metadata": {},
   "outputs": [],
   "source": [
    "### label encoder for target \n",
    "label_encod = LabelEncoder()\n",
    "y_encoded =label_encod.fit_transform(y_target)\n",
    "# categorical transofrm for target\n",
    "#y_cat =to_categorical(y_encoded)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "37f6eae1",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(y_encoded.shape,y_target.shape,X_train.shape,test.shape )\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "66f551f2",
   "metadata": {},
   "outputs": [],
   "source": [
    "n_classes = 6\n",
    "def get_model(X_train,):\n",
    "    inputs = layers.Input(shape = (X_train.shape[1],))\n",
    "    \n",
    "    hidden = layers.Dense(units=350, kernel_initializer=\"lecun_normal\", activation=\"selu\")(inputs)\n",
    "    flatten = layers.Flatten()(hidden)\n",
    "    dropout = layers.Dropout(0.2)(flatten)\n",
    "    hidden1 = tfa.layers.WeightNormalization(layers.Dense(units=128, activation='selu', kernel_initializer=\"lecun_normal\"))(dropout)\n",
    "    dropout1 = layers.Dropout(0.2)(layers.Concatenate()([hidden1, flatten]))\n",
    "    hidden2 = tfa.layers.WeightNormalization(layers.Dense(units=64, activation='selu'))(dropout1) \n",
    "    \n",
    "    dropout2 = layers.Dropout(0.3)(layers.Concatenate()([hidden1,flatten, hidden2]))\n",
    "    hidden3 = tfa.layers.WeightNormalization(layers.Dense(units=32, activation='selu'))(dropout2) \n",
    "    output = layers.Dense(n_classes, activation = 'softmax')(hidden3)\n",
    "    \n",
    "    model = keras.Model(inputs=inputs, outputs=output, name=\"resnet_baseline\")\n",
    "    \n",
    "    return model\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7681d980",
   "metadata": {},
   "outputs": [],
   "source": [
    "##model parameters\n",
    "early_stopping = callbacks.EarlyStopping(patience=10, min_delta=1e-5, restore_best_weights=True)\n",
    "reduce_lr = callbacks.ReduceLROnPlateau(factor = 0.6, patience = 5, verbose = 0) \n",
    "optimizer = keras.optimizers.Adam()\n",
    "metrics=['acc']\n",
    "loss= \"sparse_categorical_crossentropy\"\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "52e45c26",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = get_model(X_train)\n",
    "model.compile(loss=loss, optimizer = optimizer, metrics=metrics)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "099a1454",
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_model(\n",
    "    model,\n",
    "    show_shapes=True,\n",
    "    show_layer_names=True\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f70c8bb7",
   "metadata": {},
   "outputs": [],
   "source": [
    "model.summary()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0f15688b",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train= X_train.values\n",
    "epoch = 100\n",
    "batch_size = 2048\n",
    "val_score = []\n",
    "test_pred = np.zeros((1, 1))\n",
    "N_F = 5  #use 5 folds\n",
    "SKF= StratifiedKFold(n_splits=N_F, shuffle=True, random_state=42)\n",
    "for fold, (idx_train, idx_valid) in enumerate(SKF.split(X_train,y_encoded)):\n",
    "        X_tr, y_tr = X_train[idx_train], y_encoded[idx_train]\n",
    "        X_val, y_val = X_train[idx_valid], y_encoded[idx_valid]\n",
    "        K.clear_session()\n",
    "        model = get_model(X_tr)\n",
    "        model.compile(loss=loss, optimizer = optimizer, metrics=metrics)\n",
    "        model.fit(X_tr, y_tr,\n",
    "              batch_size = batch_size, epochs =epoch,\n",
    "              validation_data=(X_val, y_val),\n",
    "              callbacks=[early_stopping, reduce_lr], verbose=0)\n",
    "        val_pred = np.argmax(model.predict(X_val), axis=1)\n",
    "        score = accuracy_score(y_val, val_pred)\n",
    "        val_score.append(score)\n",
    "        test_pred = test_pred + model.predict(test)\n",
    "        print(f\"FOLD {fold:d}: validation accuracy is {score:.6f}\")\n",
    "        _ = gc.collect()\n",
    "print (\"**************************************************\")\n",
    "print(f\"Mean Validation Accuracy is : {np.mean(val_score)}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "86cb1b76",
   "metadata": {},
   "outputs": [],
   "source": [
    "predictions = np.argmax(test_pred, axis=1)\n",
    "predictions = label_encod.inverse_transform(predictions)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "50b09141",
   "metadata": {},
   "outputs": [],
   "source": [
    "sample['Cover_Type'] = predictions\n",
    "sample.to_csv('resnet.csv', index=False)\n",
    "sample\n"
   ]
  }
 ],
 "metadata": {},
 "nbformat": 4,
 "nbformat_minor": 5
}

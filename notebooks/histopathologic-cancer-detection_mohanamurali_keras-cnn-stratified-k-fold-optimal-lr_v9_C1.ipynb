{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1165fd45",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from pathlib import Path"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "24664cd8",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np # linear algebra\n",
    "import pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\n",
    "from sklearn.model_selection import train_test_split\n",
    "from keras.models import Sequential\n",
    "from keras.models import model_from_json\n",
    "from keras.layers import Conv2D, MaxPooling2D, MaxPool2D\n",
    "from keras.layers import Activation, Dropout, Flatten, Dense, BatchNormalization\n",
    "from keras.optimizers import RMSprop, Adam\n",
    "from keras import backend as K\n",
    "from keras.preprocessing.image import ImageDataGenerator\n",
    "from keras.applications.inception_resnet_v2 import InceptionResNetV2,preprocess_input\n",
    "from keras.optimizers import SGD\n",
    "from keras.callbacks import EarlyStopping,ReduceLROnPlateau\n",
    "from keras.layers import Dense\n",
    "from keras.models import Model\n",
    "import keras\n",
    "\n",
    "\n",
    "import os\n",
    "print(os.listdir(\"../input\"))\n",
    "\n",
    "train_dir = \"../input/train/\"\n",
    "test_dir = \"../input/test/\"\n",
    "\n",
    "dataset= pd.read_csv('../input/train_labels.csv',dtype='str')\n",
    "\n",
    "def append_ext(fn):\n",
    "    return fn+\".tif\"\n",
    "dataset[\"id\"]=dataset[\"id\"].apply(append_ext)\n",
    "\n",
    "datapath='../input/'\n",
    "train_path = datapath+'train'\n",
    "valid_path =  datapath+'train'\n",
    "test_path=datapath+'test'\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e2c51d23",
   "metadata": {},
   "outputs": [],
   "source": [
    "import keras\n",
    "train_datagen=ImageDataGenerator(\n",
    "    rotation_range=10,\n",
    "    width_shift_range=0.5,\n",
    "    height_shift_range=0.5,\n",
    "    shear_range=0.5,\n",
    "    zoom_range=0.5,\n",
    "    horizontal_flip=True,vertical_flip=True,\n",
    "    rotation_range=90,\n",
    "    rescale=1./255,\n",
    "    validation_split=0.3\n",
    "    )\n",
    "        \n",
    "train_generator = train_datagen.flow_from_dataframe(\n",
    "                dataframe=dataset,\n",
    "                directory=train_path,\n",
    "                x_col = 'id',\n",
    "                y_col = 'label',\n",
    "                has_ext=False,\n",
    "                subset='training',\n",
    "                target_size=(96, 96),\n",
    "                batch_size=32,\n",
    "                class_mode='binary'\n",
    "                )\n",
    "\n",
    "validation_generator = train_datagen.flow_from_dataframe(\n",
    "                dataframe=dataset,\n",
    "                directory=valid_path,\n",
    "                x_col = 'id',\n",
    "                y_col = 'label',\n",
    "                has_ext=False,\n",
    "                subset='validation', # This is the trick to properly separate train and validation dataset\n",
    "                target_size=(96, 96),\n",
    "                batch_size=32,\n",
    "                shuffle=False,\n",
    "                class_mode='binary'\n",
    "                )\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "da7d85ce",
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras.applications.inception_resnet_v2 import InceptionResNetV2,preprocess_input\n",
    "nClasses=1\n",
    "channels = 3\n",
    "model=InceptionResNetV2(include_top=True, weights=None,input_shape=(96,96,channels)) # sans poids ImageNet\n",
    "model.layers.pop() # Suppression de la couche totalement connecté fc1000\n",
    "\n",
    "# Ajout de la nouvelle couche de prédiction\n",
    "x = model.layers[-1].output\n",
    "x=Dense(nClasses, activation='sigmoid', name='predictions',kernel_initializer='glorot_normal')(x)\n",
    "model = Model(input=model.input,output=x)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4cb5cb27",
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in range(len(model.layers)):\n",
    "    model.layers[i].trainable = True\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e9ebc3c9",
   "metadata": {},
   "outputs": [],
   "source": [
    "#sgd = SGD(lr=0.02, decay=1e-6, momentum=0.9, nesterov=True)\n",
    "model.compile(loss='binary_crossentropy', optimizer=Adam(0.0001), metrics=['acc'])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6c7d8cdc",
   "metadata": {},
   "outputs": [],
   "source": [
    "STEP_SIZE_TRAIN=train_generator.n//train_generator.batch_size\n",
    "STEP_SIZE_VALID=validation_generator.n//validation_generator.batch_size\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3a50db5b",
   "metadata": {},
   "outputs": [],
   "source": [
    "early_stop = EarlyStopping(monitor='val_loss', min_delta=0.0001, patience=2, verbose=2)\n",
    "lr_reducer = ReduceLROnPlateau(factor=np.sqrt(0.1), cooldown=0, patience=2, min_lr=0.5e-6)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "919ce72c",
   "metadata": {},
   "outputs": [],
   "source": [
    "model.fit_generator(generator=train_generator,\n",
    "              steps_per_epoch=STEP_SIZE_TRAIN,\n",
    "              nb_epoch=10,\n",
    "              shuffle=True,verbose=1,\n",
    "              callbacks=[lr_reducer, early_stop],\n",
    "              validation_data=validation_generator,\n",
    "              validation_steps=STEP_SIZE_VALID)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "23a9d0b2",
   "metadata": {},
   "outputs": [],
   "source": [
    "import glob\n",
    "import os\n",
    "from skimage.io import imread\n",
    "from keras.preprocessing import image\n",
    "from keras.preprocessing  import image\n",
    "testing_files = glob.glob(os.path.join(test_dir,'*.tif'))\n",
    "TESTING_BATCH_SIZE=10\n",
    "submission = pd.DataFrame()\n",
    "\n",
    "\n",
    "test_files = glob.glob(os.path.join(test_dir,'*.tif'))\n",
    "submission = pd.DataFrame()\n",
    "file_batch = 5000\n",
    "max_idx = len(test_files)\n",
    "for idx in range(0, max_idx, file_batch):\n",
    "    print(\"Indexes: %i - %i\"%(idx, idx+file_batch))\n",
    "    test_df = pd.DataFrame({'path': test_files[idx:idx+file_batch]})\n",
    "    test_df['id'] = test_df.path.map(lambda x: x.split('/')[3].split(\".\")[0])\n",
    "    test_df['image'] = test_df['path'].map(imread)\n",
    "    K_test = np.stack(test_df[\"image\"].values)\n",
    "    K_test = keras.applications.inception_resnet_v2.preprocess_input(K_test)\n",
    "    predictions = model.predict(K_test)\n",
    "    test_df['label'] = predictions\n",
    "    submission = pd.concat([submission, test_df[[\"id\", \"label\"]]])\n",
    "submission.head()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f2dbb0ce",
   "metadata": {},
   "outputs": [],
   "source": [
    "submission.to_csv(\"submission.csv\", index = False, header = True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f56a5019",
   "metadata": {},
   "outputs": [],
   "source": [
    "pd.read_csv(\"submission.csv\").head()\n"
   ]
  }
 ],
 "metadata": {},
 "nbformat": 4,
 "nbformat_minor": 5
}

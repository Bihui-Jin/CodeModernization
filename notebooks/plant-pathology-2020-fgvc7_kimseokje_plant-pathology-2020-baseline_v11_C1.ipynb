{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "974a0b27",
      "metadata": {},
      "outputs": [],
      "source": [
        "import pandas as pd\n",
        "from pathlib import Path"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "1760ea44",
      "metadata": {},
      "outputs": [],
      "source": [
        "# # This Python 3 environment comes with many helpful analytics libraries installed\n",
        "# # It is defined by the kaggle/python Docker image: https://github.com/kaggle/docker-python\n",
        "# # For example, here's several helpful packages to load\n",
        "\n",
        "# import numpy as np # linear algebra\n",
        "# import pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\n",
        "\n",
        "# # Input data files are available in the read-only \"../input/\" directory\n",
        "# # For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n",
        "\n",
        "# import os\n",
        "# for dirname, _, filenames in os.walk('/kaggle/input'):\n",
        "#     for filename in filenames:\n",
        "#         print(os.path.join(dirname, filename))\n",
        "\n",
        "# # You can write up to 20GB to the current directory (/kaggle/working/) that gets preserved as output when you create a version using \"Save & Run All\" \n",
        "# # You can also write temporary files to /kaggle/temp/, but they won't be saved outside of the current session\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "0522ab3e",
      "metadata": {},
      "outputs": [],
      "source": [
        "import pandas as pd\n",
        "\n",
        "# data path\n",
        "data_path = '/kaggle/input/plant-pathology-2020-fgvc7/'\n",
        "\n",
        "train = pd.read_csv(data_path + 'train.csv')\n",
        "test = pd.read_csv(data_path + 'test.csv')\n",
        "submission = pd.read_csv(data_path + 'sample_submission.csv')\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "5402efd8",
      "metadata": {},
      "outputs": [],
      "source": [
        "train.shape, test.shape\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "fd2eb37e",
      "metadata": {},
      "outputs": [],
      "source": [
        "train.head()\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "7fe802c9",
      "metadata": {},
      "outputs": [],
      "source": [
        "test.head()\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "05ef32c2",
      "metadata": {},
      "outputs": [],
      "source": [
        "submission.head()\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "5e38ee7c",
      "metadata": {},
      "outputs": [],
      "source": [
        "# extraction by target type\n",
        "healthy = train.loc[train['healthy']==1] # DataFame \n",
        "multiple_diseases = train.loc[train['multiple_diseases']==1]\n",
        "rust = train.loc[train['rust']==1]\n",
        "scab = train.loc[train['scab']==1]\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "991dcf0f",
      "metadata": {},
      "outputs": [],
      "source": [
        "import matplotlib as mpl\n",
        "import matplotlib.pyplot as plt\n",
        "%matplotlib inline\n",
        "\n",
        "# rc is used for set viual envrionments\n",
        "mpl.rc('font', size=15)\n",
        "plt.figure(figsize=(7,7))\n",
        "\n",
        "label = ['healty', 'multiple diseases', 'rust', 'scab']\n",
        "plt.pie([len(healthy), len(multiple_diseases), len(rust), len(scab)],labels=label, autopct='%.1f%%')\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "e4f8bfe0",
      "metadata": {},
      "outputs": [],
      "source": [
        "import matplotlib.gridspec as gridspec\n",
        "import cv2\n",
        "\n",
        "def show_image(img_ids, rows=2, cols=3):\n",
        "    assert len(img_ids) <= rows*cols \n",
        "    \n",
        "    plt.figure(figsize=(15,8))\n",
        "    grid = gridspec.GridSpec(rows, cols)\n",
        "    \n",
        "    for idx, img_id in enumerate(img_ids):\n",
        "        img_path = f'{data_path}/images/{img_id}.jpg'\n",
        "        image = cv2.imread(img_path)\n",
        "        image = cv2.cvtColor(image, cv2.COLOR_BGR2RGB) # convert color formate for cv2\n",
        "        ax = plt.subplot(grid[idx])\n",
        "        ax.imshow(image)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "f6da8e05",
      "metadata": {},
      "outputs": [],
      "source": [
        "healthy\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "28879aef",
      "metadata": {},
      "outputs": [],
      "source": [
        "num_of_imgs = 6\n",
        "last_healthy_img_ids = healthy['image_id'][-num_of_imgs:] # 마지막 6개에 대한 sereis 객체 반환\n",
        "last_multiple_diseases_img_ids = multiple_diseases['image_id'][-num_of_imgs:]\n",
        "last_rust_img_ids = rust['image_id'][-num_of_imgs:]\n",
        "last_scab_img_ids = scab['image_id'][-num_of_imgs:]\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "87c43870",
      "metadata": {},
      "outputs": [],
      "source": [
        "show_image(last_healthy_img_ids)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "0ee8dcff",
      "metadata": {},
      "outputs": [],
      "source": [
        "show_image(last_multiple_diseases_img_ids)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "9a4859aa",
      "metadata": {},
      "outputs": [],
      "source": [
        "show_image(last_rust_img_ids)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "609d28cb",
      "metadata": {},
      "outputs": [],
      "source": [
        "show_image(last_scab_img_ids)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "6955c44b",
      "metadata": {},
      "outputs": [],
      "source": [
        "import torch\n",
        "import random\n",
        "import numpy as np\n",
        "import os\n",
        "\n",
        "# fix seed\n",
        "seed = 50\n",
        "os.environ['PYTHONHASHSEED'] = str(seed)\n",
        "random.seed(seed)\n",
        "np.random.seed(seed) # ?? 추가 설명 필요\n",
        "torch.manual_seed(seed)\n",
        "torch.cuda.manual_seed(seed)\n",
        "torch.cuda.manual_seed_all(seed)\n",
        "torch.backends.cudnn.deterministic = True\n",
        "torch.backends.cudnn.benchmark = False\n",
        "torch.backends.cudnn.enabled = False\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "80bacf08",
      "metadata": {},
      "outputs": [],
      "source": [
        "device = 'cuda' if torch.cuda.is_available() else 'cpu'\n",
        "print(device)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "e66d536b",
      "metadata": {},
      "outputs": [],
      "source": [
        "from sklearn.model_selection import train_test_split # DataLoader에 쓸게 아니라면 sklearn을 쓰면 된다.\n",
        "\n",
        "train, valid = train_test_split(train, \n",
        "                                test_size = 0.1,\n",
        "                                stratify=train[['healthy', 'multiple_diseases', 'rust', 'scab']], # 이 부분이 해당 열을 비율대로 뽑는거??\n",
        "                                random_state=50)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "1218f75c",
      "metadata": {},
      "outputs": [],
      "source": [
        "import cv2\n",
        "from torch.utils.data import Dataset\n",
        "import numpy as np\n",
        "\n",
        "class ImageDataset(Dataset):\n",
        "    def __init__(self, df, img_dir=',/', transform=None, is_test=False):\n",
        "        super().__init__()\n",
        "        self.df = df\n",
        "        self.img_dir = img_dir\n",
        "        self.transform = transform\n",
        "        self.is_test = is_test\n",
        "        \n",
        "    def __len__(self):\n",
        "        return len(self.df)\n",
        "    \n",
        "    def __getitem__(self, idx):\n",
        "        img_id = self.df.iloc[idx, 0] # .loc 과 iloc의 차이는?\n",
        "        img_path = self.img_dir + img_id + '.jpg'\n",
        "        image = cv2.imread(img_path)\n",
        "        image = cv2.cvtColor(image, cv2.COLOR_BGR2RGB)\n",
        "        \n",
        "        if self.transform is not None:\n",
        "            image = self.transform(image=image)['image']\n",
        "            \n",
        "        if self.is_test:\n",
        "            return image\n",
        "        else:\n",
        "            label = np.argmax(self.df.iloc[idx,1:5]) # ???\n",
        "            return image, label\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "61778727",
      "metadata": {},
      "outputs": [],
      "source": [
        "import albumentations as A\n",
        "from albumentations.pytorch import ToTensorV2\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "71950d87",
      "metadata": {},
      "outputs": [],
      "source": [
        "transform_train = A.Compose([\n",
        "    A.Resize(450, 650), # 상위권들의 토론글을 보면 이미지를 크게 조정할수록 성능이 좋다고 함. (원래는 800x800 정도로 잡는다고 함)\n",
        "    A.RandomBrightnessContrast(brightness_limit=0.2,     # 밝기 대비 조절을 통해 빛의 양이 다른 환경에서도 일반적으로 인실할 수 있도록 만듬.\n",
        "                              contrast_limit=0.2, p=0.3), # ? 나중에 일일히 찾아보도록 하자.\n",
        "    A.VerticalFlip(p=0.2),\n",
        "    A.HorizontalFlip(p=0.5), \n",
        "    A.ShiftScaleRotate(         # 이동, 스케일링, 회전 변환\n",
        "        shift_limit=0.1,\n",
        "        scale_limit=0.2,\n",
        "        rotate_limit=30, p=0.3),\n",
        "    A.OneOf([A.Emboss(p=1),    # 양가화, 날카로움, 블러 효과\n",
        "             A.Sharpen(p=1),\n",
        "             A.Blur(p=1)], p=0.3),    \n",
        "    A.PiecewiseAffine(p=0.3),\n",
        "    A.Normalize(),\n",
        "    ToTensorV2()\n",
        "]) # 어떻게 처리하면 더 좋은 성능을 이끌어낼 수 있는지를 고민해보면 좋다고 함.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "82fe2945",
      "metadata": {},
      "outputs": [],
      "source": [
        "transform_test = A.Compose([\n",
        "    A.Resize(450, 650),\n",
        "    A.Normalize(), # 범위를 비슷하게 잡아줘야 비교하기 편함 (값이 작아야 활성화함수에 가서 학습되지 쉽)\n",
        "    ToTensorV2() # 파이토치는 텐서 객체만 취급하므로 변환기에 꼭 필\n",
        "])\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "d769d4a1",
      "metadata": {},
      "outputs": [],
      "source": [
        "img_dir = '/kaggle/input/plant-pathology-2020-fgvc7/images/'\n",
        "\n",
        "dataset_train = ImageDataset(train, img_dir=img_dir, transform=transform_train)\n",
        "dataset_valid = ImageDataset(valid, img_dir=img_dir, transform=transform_test)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "b3900745",
      "metadata": {},
      "outputs": [],
      "source": [
        "# 멀티 프로세싱 관련 설정이라는데 자세한건 코딩 다 하고 나서 알아보자.\n",
        "def seed_worker(worker_id):\n",
        "    worker_seed = torch.initial_seed() % 2**32\n",
        "    np.random.seed(worker_seed)\n",
        "    random.seed(worker_seed)\n",
        "    \n",
        "g = torch.Generator()\n",
        "g.manual_seed(0)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "013d5cb2",
      "metadata": {},
      "outputs": [],
      "source": [
        "from torch.utils.data import DataLoader\n",
        "\n",
        "batch_size = 4 # 훈련 데이터가 많이 않아서 작게 설정. 질문: batch size가 크면 클수록 좋은거 아닌가?? 어느정도 있어야 일반적인 경향으로 학습되지 않나?\n",
        "\n",
        "loader_train = DataLoader(dataset_train, batch_size=batch_size,\n",
        "                        shuffle=True, worker_init_fn=seed_worker,\n",
        "                        generator=g, num_workers=2)\n",
        "loader_valid = DataLoader(dataset_valid, batch_size=batch_size,\n",
        "                         shuffle=False, worker_init_fn=seed_worker,\n",
        "                         generator=g, num_workers=2)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "d046fa6f",
      "metadata": {},
      "outputs": [],
      "source": [
        "!pip install efficientnet-pytorch==0.7.1\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "685a14e8",
      "metadata": {},
      "outputs": [],
      "source": [
        "from efficientnet_pytorch import EfficientNet\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "8aa6da09",
      "metadata": {},
      "outputs": [],
      "source": [
        "# model = EfficientNet.from_pretrained('efficientnet-b7', num_classes=4)\n",
        "# model = model.to(device)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "28ee3d0d",
      "metadata": {},
      "outputs": [],
      "source": [
        "import torch.nn as nn\n",
        "\n",
        "model = EfficientNet.from_pretrained('efficientnet-b0')\n",
        "model._fc = nn.Sequential(\n",
        "    nn.Linear(model._fc.in_features, model._fc.out_features),\n",
        "    nn.ReLU(),\n",
        "    nn.Dropout(p=0.5),\n",
        "    nn.Linear(model._fc.out_features, 4)\n",
        ")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "ffda0fce",
      "metadata": {},
      "outputs": [],
      "source": [
        "criterion = nn.CrossEntropyLoss()\n",
        "optimizer = torch.optim.AdamW(model.parameters(), lr=0.00006, weight_decay=0.0001)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "e0cd30df",
      "metadata": {},
      "outputs": [],
      "source": [
        "from sklearn.metrics import roc_auc_score\n",
        "from tqdm.notebook import tqdm\n",
        "\n",
        "epochs = 5\n",
        "\n",
        "model = model.to(device)\n",
        "\n",
        "for epoch in range(epochs):\n",
        "    model.train()\n",
        "    epoch_train_loss = 0\n",
        "    \n",
        "    for images, labels in tqdm(loader_train):\n",
        "        images = images.to(device); labels = labels.to(device)\n",
        "        outputs = model(images)\n",
        "        loss = criterion(outputs, labels)\n",
        "        \n",
        "        optimizer.zero_grad() # 업데이트 될 가중치값을 0으로 초기화\n",
        "        loss.backward()  # 미분값 계산\n",
        "        optimizer.step() # 업데이트 적용\n",
        "        \n",
        "        epoch_train_loss += loss.item() * images.shape[0]\n",
        "        \n",
        "    print(f'epoch [{epoch+1}/{epochs}] - train_loss: {epoch_train_loss/len(loader_train.dataset):.4f}') # 매 에포크마다 성능 비교\n",
        "    \n",
        "    \n",
        "    model.eval()\n",
        "    epoch_valid_loss = 0\n",
        "    preds_list = []\n",
        "    true_onehot_list = []\n",
        "    \n",
        "    with torch.no_grad():\n",
        "        for images, labels in loader_valid:\n",
        "            images = images.to(device); labels = labels.to(device)\n",
        "            outputs = model(images)\n",
        "            \n",
        "            loss = criterion(outputs, labels)\n",
        "            \n",
        "            preds = torch.softmax(outputs.cpu(), dim=1).numpy()\n",
        "            true_onehot = torch.eye(4)[labels].cpu().numpy()\n",
        "            preds_list.extend(preds)\n",
        "            true_onehot_list.extend(true_onehot)\n",
        "            \n",
        "            epoch_valid_loss += loss.item() * images.shape[0]\n",
        "            \n",
        "    print(f'epoch [{epoch+1}/{epochs}] - val_loss: {epoch_valid_loss/len(loader_valid):.4f}/ val_ROC AUC: {roc_auc_score(true_onehot_list,preds_list):.4f}')\n",
        "            \n",
        "        \n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "061a66b4",
      "metadata": {},
      "outputs": [],
      "source": [
        "dataset_test = ImageDataset(test, img_dir=img_dir,\n",
        "                           transform=transform_test, is_test=True)\n",
        "loader_test = DataLoader(dataset_test, batch_size=batch_size,\n",
        "                        shuffle=False, worker_init_fn=seed_worker,\n",
        "                        generator=g, num_workers=2)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "1c129db1",
      "metadata": {},
      "outputs": [],
      "source": [
        "model.eval()\n",
        "\n",
        "preds = np.zeros((len(test), 4))\n",
        "\n",
        "with torch.no_grad():\n",
        "    for i, images in enumerate(loader_test):\n",
        "        images = images.to(device)\n",
        "        outputs = model(images)\n",
        "        preds_part = torch.softmax(outputs.cpu(), dim=1).squeeze().numpy()\n",
        "        preds[i*batch_size:(i+1)*batch_size] += preds_part\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "d5abdbf4",
      "metadata": {},
      "outputs": [],
      "source": [
        "submission[['healthy', 'multiple_diseases', 'rust', 'scab']] = preds\n",
        "submission.to_csv('submittion.csv', index=False)\n"
      ]
    }
  ],
  "metadata": {},
  "nbformat": 4,
  "nbformat_minor": 5
}
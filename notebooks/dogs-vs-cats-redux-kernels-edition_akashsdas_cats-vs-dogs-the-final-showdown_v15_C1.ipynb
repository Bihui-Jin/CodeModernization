{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3c409220",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from pathlib import Path"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "63839b99",
   "metadata": {},
   "outputs": [],
   "source": [
    "import gc\n",
    "import os\n",
    "from os import listdir\n",
    "from os.path import isfile, join\n",
    "\n",
    "import json\n",
    "import zipfile\n",
    "import itertools\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "import cv2\n",
    "\n",
    "from sklearn.metrics import confusion_matrix\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras import Sequential\n",
    "from tensorflow.keras.models import Model\n",
    "from tensorflow.keras.callbacks import Callback\n",
    "from tensorflow.keras.optimizers import Adam, RMSprop\n",
    "from tensorflow.keras.applications import VGG16, InceptionV3\n",
    "from tensorflow.keras.callbacks import ReduceLROnPlateau\n",
    "from tensorflow.keras.layers import Dense, Flatten, Dropout\n",
    "from tensorflow.keras.metrics import AUC, Precision, Recall\n",
    "from tensorflow.keras.preprocessing.image import ImageDataGenerator\n",
    "from tensorflow.keras.preprocessing.image import load_img, img_to_array\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2b28dd87",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Extracting all of the zip files\n",
    "\n",
    "# Training dataset\n",
    "with zipfile.ZipFile('../input/dogs-vs-cats-redux-kernels-edition/train.zip', 'r') as z:\n",
    "     z.extractall('../data')\n",
    "    \n",
    "# Testing dataset\n",
    "with zipfile.ZipFile('../input/dogs-vs-cats-redux-kernels-edition/test.zip', 'r') as z:\n",
    "    z.extractall('../data')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "27c592f5",
   "metadata": {},
   "outputs": [],
   "source": [
    "os.listdir('../data')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b49576e3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Cat = 0, Dog = 1\n",
    "def create_df():\n",
    "    path = '../data/train'\n",
    "    dataset = []\n",
    "    for f in listdir(path):\n",
    "        if isfile(join(path, f)):\n",
    "            if 'cat' in f:\n",
    "                dataset.append({'label': 0, 'img_path': join(path, f)})\n",
    "            elif 'dog' in f:\n",
    "                dataset.append({'label': 1, 'img_path': join(path, f)})\n",
    "\n",
    "    df = pd.DataFrame(dataset)\n",
    "\n",
    "    # shuffling the dataframe and resetting the index\n",
    "    df = df.sample(frac=1).reset_index(drop=True)\n",
    "    \n",
    "    return df\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "56a71808",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Getting the dataset\n",
    "df = create_df()\n",
    "df.sample(5)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e15bb469",
   "metadata": {},
   "outputs": [],
   "source": [
    "# converting labels dtype to str\n",
    "# to use class_mode='binary' in ImageDataGenerators\n",
    "df.label = df.label.astype('str')\n",
    "df.sample(5)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2dc4e2cb",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(f'Dataset size: {len(df)}')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8df22cde",
   "metadata": {},
   "outputs": [],
   "source": [
    "# See if dataset is balanced or not\n",
    "\n",
    "plt.figure(figsize=(8, 4))\n",
    "plt.title('Number of classes')\n",
    "g = sns.countplot(df.label, palette='icefire')\n",
    "g.set(xlabel='Classes', ylabel='Count')\n",
    "sns.despine(offset=5)\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4d71daa5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Splitting the training and validation sets\n",
    "x_train, x_val, y_train, y_val = train_test_split(df.img_path, df.label, test_size=0.1, random_state=0)\n",
    "\n",
    "# Splitting the remaining training set into training and test sets\n",
    "# This set is different from the set ==> /kaggle/working/dogs-vs-cats/test/\n",
    "x_train, x_test, y_train, y_test = train_test_split(x_train, y_train, test_size=0.1, random_state=0)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7932bf4e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Converting the above pandas series to dataframe\n",
    "train_df = pd.DataFrame({ 'label': y_train, 'img_path': x_train }).reset_index(drop=True)\n",
    "val_df   = pd.DataFrame({ 'label': y_val, 'img_path': x_val }).reset_index(drop=True)\n",
    "test_df  = pd.DataFrame({ 'label': y_test, 'img_path': x_test }).reset_index(drop=True)\n",
    "\n",
    "# Printing the sets size\n",
    "print(f'Training set size: {len(train_df)}')\n",
    "print(f'Validation set size: {len(val_df)}')\n",
    "print(f'Testing set size: {len(test_df)}')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "abb6212f",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_df.sample(5)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "61a495f2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Looking at first 25 training examples\n",
    "\n",
    "plt.figure(figsize=(15, 15))\n",
    "for i, _img_path in enumerate(x_train[:25]):\n",
    "    plt.subplot(5, 5, i+1)\n",
    "    plt.xticks([])\n",
    "    plt.yticks([])\n",
    "    plt.title('')\n",
    "    img = load_img(_img_path)\n",
    "    plt.imshow(img)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "debc9c63",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Global variables\n",
    "\n",
    "IMG_HEIGHT = 150\n",
    "IMG_WIDTH  = 150\n",
    "CHANNELS   = 3\n",
    "\n",
    "BATCH_SIZE = 128\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "15e48d4c",
   "metadata": {},
   "outputs": [],
   "source": [
    "def process_images(list_of_images):\n",
    "    x = []  # holds images\n",
    "    y = []  # hold labels\n",
    "    \n",
    "    for image in list_of_images:\n",
    "        x.append(\n",
    "            cv2.resize(\n",
    "                cv2.imread(image, cv2.IMREAD_COLOR),\n",
    "                (IMG_HEIGHT, IMG_WIDTH),\n",
    "                interpolation=cv2.INTER_CUBIC\n",
    "            )\n",
    "        )\n",
    "        \n",
    "        if 'dog' in image:\n",
    "            y.append(1)\n",
    "        if 'cat' in image:\n",
    "            y.append(0)\n",
    "    \n",
    "    return x, y\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9f5ba687",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_datagen = ImageDataGenerator(\n",
    "    rescale=1./255, \n",
    "    rotation_range=10, \n",
    "    width_shift_range=0.2, \n",
    "    height_shift_range=0.2, \n",
    "    horizontal_flip=True,\n",
    "    vertical_flip=True,\n",
    "    zoom_range = 0.1,\n",
    ")\n",
    "\n",
    "val_datagen = ImageDataGenerator(rescale=1./255)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a059948f",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_generator = train_datagen.flow_from_dataframe(\n",
    "    train_df,\n",
    "    x_col='img_path',\n",
    "    y_col='label',\n",
    "    target_size=(IMG_HEIGHT, IMG_WIDTH),\n",
    "    batch_size=BATCH_SIZE,\n",
    "    shuffle=True,\n",
    "    class_mode='binary'\n",
    ")\n",
    "\n",
    "val_generator = val_datagen.flow_from_dataframe(\n",
    "    val_df,\n",
    "    x_col='img_path',\n",
    "    y_col='label',\n",
    "    target_size=(IMG_HEIGHT, IMG_WIDTH),\n",
    "    batch_size=BATCH_SIZE,\n",
    "    # shuffle=True,\n",
    "    class_mode='binary'\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2db226b1",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_VGG16_model(input_shape):\n",
    "    model = VGG16(weights='imagenet', include_top=False, input_shape=input_shape)\n",
    "    x = Flatten()(model.output)\n",
    "    Dropout(0.5)(x)\n",
    "    Dense(4096, activation='relu')(x)\n",
    "    output = Dense(1, activation='sigmoid')(x)\n",
    "    model = Model(model.input, output)\n",
    "    \n",
    "    return model\n",
    "\n",
    "\n",
    "def get_InceptionV3_model(input_shape):\n",
    "    model = InceptionV3(weights='imagenet', include_top=False, input_shape=input_shape)\n",
    "    x = Flatten()(model.output)\n",
    "    Dropout(0.5)(x)\n",
    "    Dense(4096, activation='relu')(x)\n",
    "    output = Dense(1, activation='sigmoid')(x)\n",
    "    model = Model(model.input, output)\n",
    "    \n",
    "    return model\n",
    "\n",
    "\n",
    "model = get_InceptionV3_model(input_shape=(IMG_HEIGHT, IMG_WIDTH, CHANNELS))\n",
    "model.summary()\n",
    "print()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "74f591b9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Building the CustomCallback for getting more info on model's performance\n",
    "class CustomCallback(Callback):\n",
    "    def on_epoch_end(self, epoch, logs=None):\n",
    "        precision = logs['precision']\n",
    "        recall = logs['recall']\n",
    "        f1_score = (2 * (precision * recall)) / (precision + recall)\n",
    "        \n",
    "        loss = logs['loss']\n",
    "        accuracy = logs['accuracy']\n",
    "        auc_roc = logs['auc_roc']\n",
    "        \n",
    "        # Validation\n",
    "        val_loss = logs['val_loss']\n",
    "        val_accuracy = logs['val_accuracy']\n",
    "        val_auc_roc = logs['val_auc_roc']\n",
    "        val_precision = logs['val_precision']\n",
    "        val_recall = logs['val_recall']\n",
    "        val_f1_score = (2 * (val_precision * val_recall)) / (val_precision + val_recall)\n",
    "        \n",
    "        info = {\n",
    "            'loss': round(loss, 5),\n",
    "            'accuracy': round(accuracy, 4),\n",
    "            'auc_roc': round(auc_roc, 4),\n",
    "            'precision': round(precision, 4),\n",
    "            'recall': round(recall, 4),\n",
    "            'f1_score': round(f1_score, 4),\n",
    "            'val_loss': round(val_loss, 5),\n",
    "            'val_accuracy': round(val_accuracy, 4),\n",
    "            'val_auc_roc': round(val_auc_roc, 4),\n",
    "            'val_precision': round(val_precision, 4),\n",
    "            'val_recall': round(val_recall, 4),\n",
    "            'val_f1_score': round(val_f1_score, 4),\n",
    "        }\n",
    "        \n",
    "        print(f'\\n{json.dumps(info, indent=2)}')\n",
    "        print()\n",
    "\n",
    "        \n",
    "\n",
    "callbacks = [\n",
    "    ReduceLROnPlateau(monitor='val_loss',factor=0.1, patience=2, min_lr=0.000001, verbose=1),\n",
    "    CustomCallback()\n",
    "]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dd004138",
   "metadata": {},
   "outputs": [],
   "source": [
    "num_epoch = 1\n",
    "optimizer = RMSprop(learning_rate=0.0001)\n",
    "loss = 'binary_crossentropy'\n",
    "\n",
    "metrics = [\n",
    "    'accuracy', \n",
    "    AUC(curve='ROC', name='auc_roc'), \n",
    "    Precision(name='precision'), \n",
    "    Recall(name='recall')\n",
    "]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "aaa40480",
   "metadata": {},
   "outputs": [],
   "source": [
    "model.compile(\n",
    "    optimizer=optimizer,\n",
    "    loss=loss,\n",
    "    metrics=metrics\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4db9b7de",
   "metadata": {},
   "outputs": [],
   "source": [
    "history = model.fit(\n",
    "    train_generator, \n",
    "    steps_per_epoch=x_train.shape[0] // BATCH_SIZE,\n",
    "    batch_size=BATCH_SIZE, \n",
    "    validation_data=val_generator, \n",
    "    epochs=num_epoch,\n",
    "    callbacks=callbacks\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3f7ae45d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Accuracy\n",
    "\n",
    "plt.plot(history.history['accuracy'][1:], label='train acc')\n",
    "plt.plot(history.history['val_accuracy'][1:], label='validation acc')\n",
    "plt.xlabel('Epoch')\n",
    "plt.ylabel('Accuracy')\n",
    "plt.legend(loc='lower right')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "16a6a8a3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Loss\n",
    "\n",
    "plt.plot(history.history['loss'][1:], label='train loss')\n",
    "plt.plot(history.history['val_loss'][1:], label='validation loss')\n",
    "plt.xlabel('Epoch')\n",
    "plt.ylabel('Loss')\n",
    "plt.legend(loc='lower right')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9db64030",
   "metadata": {},
   "outputs": [],
   "source": [
    "top_layer = model.layers[1]\n",
    "plt.imshow(top_layer.get_weights()[0][:, :, :, 0].squeeze())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "632a3846",
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_filters_for_conv_layer(model, layer_index, num_columns=5, cmap='binary', how_many='all'):\n",
    "    layer = model.layers[layer_index]\n",
    "    filter_weights = layer.get_weights()[0]\n",
    "    \n",
    "    num_filters = layer.filters if how_many == 'all' else how_many\n",
    "    num_rows = (num_filters // num_columns) + (num_filters % num_columns)\n",
    "    # example:\n",
    "    # num_rows = (96 // 5) + (96 % 5) == 20 (to plot all the filters)\n",
    "    \n",
    "    f, axs = plt.subplots(num_rows, num_columns, figsize=(20, 5 * num_rows))\n",
    "    row_count = 0  # to plot num_columns figs in an individual row\n",
    "    \n",
    "    if not isinstance(axs, np.ndarray):\n",
    "        # When num_cloumns == how_many\n",
    "        axs = np.array(axs)  # to make axs iterable\n",
    "        # list can also be inplace np.array but since plt.subplots axs output is of type np.ndarray I kept \n",
    "        \n",
    "    for idx, row_ax in enumerate(axs):\n",
    "        # plotting filters in a row\n",
    "        for i, ax in enumerate(row_ax):\n",
    "            if row_count + i >= num_filters:\n",
    "                break\n",
    "                \n",
    "            if len(filter_weights.shape) == 4:\n",
    "                if filter_weights.shape[2] == 1:\n",
    "                    # For plotting filters whose weight shape is == (kernel_size_x, kernel_size_y, 1, #filters)\n",
    "                    # example: (11, 11, 1, 96)\n",
    "                    ax.imshow(filter_weights[:, :, :, row_count + i].squeeze(), cmap=cmap)\n",
    "                else:\n",
    "                    # For plotting filters whose weight shape is == (kernel_size_x, kernel_size_y, num > 1, #filters)\n",
    "                    # example: (5, 5, 96, 256)\n",
    "                    # because if ax.imshow(filter_weights[:, :, :, row_count + i].squeeze(), cmap=cmap)\n",
    "                    # is used then we'll have array of (5, 5, 96) which is invalid image data for plotting 2D image\n",
    "                    # (in above case where `filter_weights.shape[2] == 1` there we'll end up with (11, 11, 1) which\n",
    "                    # after applying the `squeeze` function will be (11, 11) which is valid image data) so in \n",
    "                    # that case we'll just plot (5, 5) plot in the first 3D array i.e. (5, 5, 0, row_count + i) \n",
    "                    # => this is what we'll plot. To plot (5, 5, row_count + i, 0) just change indexing from\n",
    "                    # [:, :, 0, row_count + i] to [:, :, row_count + i, 0]\n",
    "                    ax.imshow(filter_weights[:, :, 0, row_count + i].squeeze(), cmap=cmap)\n",
    "                    \n",
    "                # For generalization this can be used, but to understand why 0 need to be used,\n",
    "                # using the above way\n",
    "                # ax.imshow(filter_weights[:, :, 0, row_count + i].squeeze(), cmap=cmap)\n",
    "            else:\n",
    "                break\n",
    "                            \n",
    "        # increasing row_count by num_columns\n",
    "        row_count += num_columns \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "54f0f843",
   "metadata": {},
   "outputs": [],
   "source": [
    "conv_layers_idxs = [idx for idx in range(len(model.layers)) if 'conv' in model.layers[idx].name]\n",
    "print(len(conv_layers_idxs))\n",
    "\n",
    "' | '.join([str(idx) for idx in conv_layers_idxs])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "17377c86",
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_filters_for_conv_layer(\n",
    "    model, \n",
    "    conv_layers_idxs[0], \n",
    "    cmap=sns.cubehelix_palette(start=.5, rot=-.5, as_cmap=True), \n",
    "    how_many=20\n",
    ")  \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "49aa3ca8",
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_filters_for_conv_layer(\n",
    "    model, \n",
    "    conv_layers_idxs[1], \n",
    "    num_columns=5,\n",
    "    how_many=10\n",
    ")  \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8d3b4367",
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_feature_maps_for_single_conv_layer(model, layer_id, input_img, num_columns=10, cmap='binary'):\n",
    "    ref_model = Model(inputs=model.inputs, outputs=model.layers[layer_id].output)\n",
    "    feature_map = ref_model.predict(input_img)\n",
    "    \n",
    "    num_filters = feature_map[0].shape[2]\n",
    "    num_rows = (num_filters // num_columns) + (num_filters % num_columns)\n",
    "\n",
    "    fig = plt.figure(figsize=(16, 2 * num_rows))\n",
    "    ix = 1\n",
    "    for _ in range(num_rows):\n",
    "        for _ in range(num_columns):\n",
    "            if ix == num_filters:\n",
    "                break\n",
    "        \n",
    "            # specify subplot and turn of axis\n",
    "            ax = plt.subplot(num_rows, num_columns, ix)\n",
    "            ax.set_xticks([])\n",
    "            ax.set_yticks([])\n",
    "        \n",
    "            # plot filter channel in grayscale\n",
    "            plt.imshow(feature_map[0, :, :, ix-1], cmap=cmap)\n",
    "            ix += 1\n",
    "            \n",
    "    # show the figure\n",
    "    plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "23e6466b",
   "metadata": {},
   "outputs": [],
   "source": [
    "visualize_feature_maps_for = 0\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3dbfb6b6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Doing as `x_train` pd.Series index are not uniform, so resetting the index\n",
    "img_path = x_train.reset_index(drop=True)[visualize_feature_maps_for]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "278fd79a",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.imshow(load_img(img_path))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a701d685",
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_feature_maps_for_single_conv_layer(\n",
    "    model, \n",
    "    conv_layers_idxs[0], \n",
    "    process_images([img_path])[0][0][np.newaxis, ...], \n",
    "    num_columns=8,\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8f68e79f",
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_feature_maps_for_single_conv_layer(\n",
    "    model, \n",
    "    conv_layers_idxs[2], \n",
    "    process_images([img_path])[0][0][np.newaxis, ...],\n",
    "    cmap=sns.cubehelix_palette(start=.5, rot=-.5, as_cmap=True),\n",
    "    num_columns=8,\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2b20ac38",
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_feature_maps_for_single_conv_layer(\n",
    "    model, \n",
    "    conv_layers_idxs[len(conv_layers_idxs) // 2], \n",
    "    process_images([img_path])[0][0][np.newaxis, ...],\n",
    "    cmap=sns.cubehelix_palette(as_cmap=True),\n",
    "    num_columns=8,\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8aeb6c75",
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_feature_maps_for_single_conv_layer(\n",
    "    model, \n",
    "    conv_layers_idxs[-1], \n",
    "    process_images([img_path])[0][0][np.newaxis, ...],\n",
    "    cmap=sns.cubehelix_palette(start=.5, rot=-.5, as_cmap=True),\n",
    "    num_columns=8,\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e16d16e8",
   "metadata": {},
   "outputs": [],
   "source": [
    "visualize_feature_maps_for = 1\n",
    "\n",
    "# Doing as `x_train` pd.Series index are not uniform, so resetting the index\n",
    "img_path = x_train.reset_index(drop=True)[visualize_feature_maps_for]\n",
    "\n",
    "plt.imshow(load_img(img_path))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d5d3e97a",
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_feature_maps_for_single_conv_layer(\n",
    "    model, \n",
    "    conv_layers_idxs[0], \n",
    "    process_images([img_path])[0][0][np.newaxis, ...],\n",
    "    cmap=sns.cubehelix_palette(start=.5, rot=-.5, as_cmap=True),\n",
    "    num_columns=8,\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ffe9f98a",
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_feature_maps_for_single_conv_layer(\n",
    "    model, \n",
    "    conv_layers_idxs[2], \n",
    "    process_images([img_path])[0][0][np.newaxis, ...],\n",
    "    cmap=sns.cubehelix_palette(as_cmap=True),\n",
    "    num_columns=8,\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3e2d90b5",
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_feature_maps_for_single_conv_layer(\n",
    "    model, \n",
    "    conv_layers_idxs[len(conv_layers_idxs) // 2], \n",
    "    process_images([img_path])[0][0][np.newaxis, ...],\n",
    "    num_columns=8,\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f04945b5",
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_feature_maps_for_single_conv_layer(\n",
    "    model, \n",
    "    conv_layers_idxs[-1], \n",
    "    process_images([img_path])[0][0][np.newaxis, ...],\n",
    "    cmap=sns.cubehelix_palette(as_cmap=True),\n",
    "    num_columns=8,\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a6d0aa00",
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_confusion_matrix(cm, classes, normalize=False, title='Confusion matrix'):\n",
    "    plt.figure(figsize=(4, 4))\n",
    "    \n",
    "    plt.imshow(cm, interpolation='nearest', cmap=sns.cubehelix_palette(start=.5, rot=-.5, as_cmap=True))\n",
    "    plt.title(title)\n",
    "    plt.colorbar(fraction=0.046, pad=0.04)\n",
    "    tick_marks = np.arange(len(classes))\n",
    "    plt.xticks(tick_marks, classes, rotation=45)\n",
    "    plt.yticks(tick_marks, classes)\n",
    "\n",
    "    if normalize:\n",
    "        cm = cm.astype('float') / cm.sum(axis=1)[:, np.newaxis]\n",
    "\n",
    "    thresh = cm.max() / 2.\n",
    "    for i, j in itertools.product(range(cm.shape[0]), range(cm.shape[1])):\n",
    "        plt.text(j, i, cm[i, j],\n",
    "                 horizontalalignment=\"center\",\n",
    "                 color=\"white\" if cm[i, j] > thresh else \"black\")\n",
    "\n",
    "    plt.tight_layout()\n",
    "    plt.ylabel('True label')\n",
    "    plt.xlabel('Predicted label')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a2949918",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Cat = 0, Dog = 1\n",
    "test_datagen = ImageDataGenerator(rescale=1./255)\n",
    "test_generator = test_datagen.flow_from_dataframe(\n",
    "    test_df, \n",
    "    x_col='img_path',\n",
    "    y_col='label',    \n",
    "    batch_size=BATCH_SIZE, \n",
    "    target_size=(IMG_HEIGHT, IMG_WIDTH),\n",
    "    class_mode='binary'\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a715b08e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Evaluating labelled test data\n",
    "test_results = model.evaluate(train_generator, steps=x_test.shape[0] // BATCH_SIZE)\n",
    "\n",
    "print()\n",
    "\n",
    "print(f'Test Loss: {test_results[0]}')\n",
    "print(f'Test Accuracy: {test_results[1]}')\n",
    "print(f'Test ACU: {test_results[2]}')\n",
    "print(f'Test Precision: {test_results[3]}')\n",
    "print(f'Test Recall: {test_results[4]}')\n",
    "\n",
    "f1_score_result = 2 * (test_results[3] * test_results[4]) / (test_results[3] + test_results[4])\n",
    "print(f'Test F1 Score: {f1_score_result}')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4438508a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Cat = 0, Dog = 1\n",
    "test_datagen = ImageDataGenerator(rescale=1./255)\n",
    "test_generator = test_datagen.flow_from_dataframe(\n",
    "    test_df, \n",
    "    x_col='img_path',\n",
    "    y_col='label',    \n",
    "    batch_size=BATCH_SIZE, \n",
    "    target_size=(IMG_HEIGHT, IMG_WIDTH),\n",
    "    class_mode='binary'\n",
    ")\n",
    "\n",
    "predictions = model.predict(test_generator, verbose=1)\n",
    "predictions = predictions.flatten()\n",
    "\n",
    "results = []\n",
    "for i in predictions:\n",
    "    if i >= 0.5:\n",
    "        results.append(1)\n",
    "    else:\n",
    "        results.append(0)\n",
    "\n",
    "plt.figure(figsize=(15, 15))\n",
    "for i, _img_path in enumerate(test_generator.filenames[:25]):\n",
    "    plt.subplot(5, 5, i+1)\n",
    "    plt.xticks([])\n",
    "    plt.yticks([])\n",
    "    if results[i] == 0:\n",
    "        plt.xlabel(f'Prediction: Cat')\n",
    "    else:\n",
    "        plt.xlabel(f'Prediction: Dog')\n",
    "    img = load_img(_img_path)\n",
    "    plt.imshow(img)\n",
    "    \n",
    "# compute the confusion matrix\n",
    "confusion_mtx = confusion_matrix(test_generator.labels, results) \n",
    "\n",
    "# plot the confusion matrix\n",
    "plot_confusion_matrix(confusion_mtx, classes=range(2)) \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d9f91ce0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Getting test data ready for prediction\n",
    "test_imgs = [sample for sample in test_df.img_path]\n",
    "x_test, y_test = process_images(test_imgs)\n",
    "print(f'x_test length: {len(x_test)}, y_test length: {len(y_test)}')\n",
    "\n",
    "x = np.asarray(x_test)\n",
    "\n",
    "del x_test\n",
    "gc.collect()\n",
    "\n",
    "test_datagen = ImageDataGenerator(rescale=1./255)\n",
    "test_generator = test_datagen.flow(x, batch_size=BATCH_SIZE, shuffle=False)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e62e9cfe",
   "metadata": {},
   "outputs": [],
   "source": [
    "predictions = model.predict(test_generator, verbose=1)\n",
    "predictions = predictions.flatten()\n",
    "\n",
    "results = []\n",
    "for i in predictions:\n",
    "    if i >= 0.5:\n",
    "        results.append(1)\n",
    "    else:\n",
    "        results.append(0)\n",
    "\n",
    "plt.figure(figsize=(15, 15))\n",
    "for i, _img_path in enumerate(test_imgs[:25]):\n",
    "    plt.subplot(5, 5, i+1)\n",
    "    plt.xticks([])\n",
    "    plt.yticks([])\n",
    "    if results[i] == 0:\n",
    "        plt.xlabel(f'Prediction: Cat')\n",
    "    else:\n",
    "        plt.xlabel(f'Prediction: Dog')\n",
    "    img = load_img(_img_path)\n",
    "    plt.imshow(img)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fb7faa7c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# compute the confusion matrix\n",
    "labels_list = test_df.label.astype('int')\n",
    "confusion_mtx = confusion_matrix(labels_list, results) \n",
    "\n",
    "# plot the confusion matrix\n",
    "plot_confusion_matrix(confusion_mtx, classes=range(2)) \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ecc09d29",
   "metadata": {},
   "outputs": [],
   "source": [
    "TEST_DIR = '../data/test/'\n",
    "test_imgs = [TEST_DIR + i for i in os.listdir(TEST_DIR)]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f6857c6c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Getting test data ready for prediction\n",
    "x_test, y_test = process_images(test_imgs)\n",
    "print(f'x_test length: {len(x_test)}, y_test length: {len(y_test)}')\n",
    "\n",
    "x = np.asarray(x_test)\n",
    "\n",
    "del x_test\n",
    "gc.collect()\n",
    "\n",
    "test_datagen = ImageDataGenerator(rescale=1./255)\n",
    "test_generator = test_datagen.flow(x, batch_size=BATCH_SIZE, shuffle=False)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "603081a5",
   "metadata": {},
   "outputs": [],
   "source": [
    "predictions = model.predict(test_generator, verbose=1)\n",
    "predictions = predictions.flatten()\n",
    "\n",
    "results = []\n",
    "for i in predictions:\n",
    "    if i >= 0.5:\n",
    "        results.append(1)\n",
    "    else:\n",
    "        results.append(0)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b44fe6df",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(predictions[:10])\n",
    "print()\n",
    "print(results[:10])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5bb083e8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Cat = 0, Dog = 1\n",
    "\n",
    "plt.figure(figsize=(15, 15))\n",
    "for i, _img_path in enumerate(test_imgs[:25]):\n",
    "    plt.subplot(5, 5, i+1)\n",
    "    plt.xticks([])\n",
    "    plt.yticks([])\n",
    "    if results[i] == 0:\n",
    "        plt.xlabel(f'Prediction: Cat')\n",
    "    else:\n",
    "        plt.xlabel(f'Prediction: Dog')\n",
    "    # plt.xlabel(f'Prediction: {predictions[i]}')\n",
    "    img = load_img(_img_path)\n",
    "    plt.imshow(img)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "69ab0c6c",
   "metadata": {},
   "outputs": [],
   "source": [
    "submission = pd.read_csv('../input/dogs-vs-cats-redux-kernels-edition/sample_submission.csv')\n",
    "submission.head()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "334dd1ff",
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in submission.index:\n",
    "    # submission['label'].iloc[i] = results[i]\n",
    "    submission['label'].iloc[i] = predictions[i]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "afff9d86",
   "metadata": {},
   "outputs": [],
   "source": [
    "submission.to_csv('sample_submission.csv', index=False)\n",
    "submission.head()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "025d2a8a",
   "metadata": {},
   "outputs": [],
   "source": [
    "model.save('model')\n"
   ]
  }
 ],
 "metadata": {},
 "nbformat": 4,
 "nbformat_minor": 5
}

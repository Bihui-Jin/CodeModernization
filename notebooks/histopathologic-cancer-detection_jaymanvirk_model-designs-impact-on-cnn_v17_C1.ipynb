{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "df9eec8d",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from pathlib import Path"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d97adc3f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# basics\n",
    "import os\n",
    "import time\n",
    "import numpy as np\n",
    "\n",
    "# EDA\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from PIL import Image\n",
    "\n",
    "# Data preprocessing\n",
    "import tensorflow as tf\n",
    "import tensorflow_io as tfio\n",
    "from sklearn.utils import resample\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "# Convolutional neural network\n",
    "from keras.models import Sequential\n",
    "from tensorflow.keras import layers, models\n",
    "\n",
    "# helper functions\n",
    "from sklearn.metrics import roc_auc_score\n",
    "from tensorflow.keras.models import load_model\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ee1f94b1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Print list of files and directories in folder\n",
    "input_dir = '/kaggle/input/histopathologic-cancer-detection'\n",
    "list_l = [os.path.join(input_dir, x) for x in os.listdir(input_dir)]\n",
    "list_l\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e687a702",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Set datasets and directory names\n",
    "sample_data = pd.read_csv(list_l[0])\n",
    "train_data = pd.read_csv(list_l[1])\n",
    "train_dir = list_l[3] + '/'\n",
    "test_dir = list_l[2] + '/'\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "77f717d6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Cleaning\n",
    "del list_l\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "afafe019",
   "metadata": {},
   "outputs": [],
   "source": [
    "def print_short_summary(name, data):\n",
    "    \"\"\"\n",
    "    Prints data head, shape and info.\n",
    "    Args:\n",
    "        name (str): name of dataset\n",
    "        data (dataframe): dataset in a pd.DataFrame format\n",
    "    \"\"\"\n",
    "    print(name)\n",
    "    print('\\n1. Data head:')\n",
    "    print(data.head())\n",
    "    print('\\n2. Data shape: {}'.format(data.shape))\n",
    "    print('\\n3. Data info:')\n",
    "    data.info()\n",
    "    \n",
    "def print_number_files(dirpath):\n",
    "    print('{}: {} files'.format(dirpath, len(os.listdir(dirpath))))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "71d7cc53",
   "metadata": {},
   "outputs": [],
   "source": [
    "print_short_summary('Train data', train_data)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a57371c3",
   "metadata": {},
   "outputs": [],
   "source": [
    "print_short_summary('Sample data', sample_data)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "872edf2f",
   "metadata": {},
   "outputs": [],
   "source": [
    "print_number_files(train_dir)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "11f4f20c",
   "metadata": {},
   "outputs": [],
   "source": [
    "print_number_files(test_dir)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4fc21bf8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Cleaning\n",
    "del print_short_summary, print_number_files\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "effe5706",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plot horizontal barplot of number of records per label\n",
    "plt.figure(figsize=(16, 9))\n",
    "tmp = train_data['label'].value_counts()\n",
    "sns.barplot(y=['No Cancer', 'Cancer'], x=tmp.values, orient='h')\n",
    "plt.xlabel('Number of records')\n",
    "plt.ylabel('Label')\n",
    "plt.title('Number of records per label')\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "288e606c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Cleaning\n",
    "del tmp\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "af2e7b86",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_images_to_plot(file_names):\n",
    "    \"\"\"\n",
    "    Returns list of images\n",
    "    Args:\n",
    "        file_names: list of filenames\n",
    "    Returns:\n",
    "        list of image objects\n",
    "    \"\"\"\n",
    "    return [Image.open(f) for f in file_names]\n",
    "\n",
    "def get_image_label(dirname, data, labels, n = 5):\n",
    "    \"\"\"\n",
    "    Return dictionary with label-imagepath\n",
    "    Args:\n",
    "        dirname: name of the directory\n",
    "        data: dataset of file names\n",
    "        labels: list of labels\n",
    "        n (opt): number of images per label\n",
    "    Returns:\n",
    "        dict_img: dictionary with label-imagepath pairs\n",
    "    \"\"\"\n",
    "    dict_img = {}\n",
    "    for l in labels:\n",
    "        indexes = data['label'] == l\n",
    "        tmp = data[indexes][:n]\n",
    "        tmp = dirname + tmp['id'] + '.tif'\n",
    "        tmp = tmp.values\n",
    "        tmp = get_images_to_plot(tmp)\n",
    "        dict_img[l] = tmp\n",
    "        \n",
    "    return dict_img\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "63dcc8d4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Print original image size\n",
    "img_path = train_dir + train_data['id'][0] + '.tif'\n",
    "img = Image.open(img_path)\n",
    "print('Original image size: {}'.format(img.size))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "388928da",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get 5 filenames per label\n",
    "data = get_image_label(train_dir,train_data, [0,1])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "244adeb6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Initialize subplots with 2 rows and 5 columns\n",
    "fig, axes = plt.subplots(nrows=2, ncols=5, figsize=(16, 9))\n",
    "\n",
    "# Loop through selected images and display in the respective rows\n",
    "labels = ['No Cancer', 'Cancer']\n",
    "for i in range(10):\n",
    "    row = i // 5\n",
    "    col = i % 5\n",
    "    axes[row, col].imshow(data[row][col])\n",
    "    axes[row, col].set_title(labels[row])\n",
    "    axes[row, col].axis('off')\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "afc6803c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Cleaning\n",
    "del get_images_to_plot, get_image_label, img_path, img\n",
    "del data, fig, axes, labels, row, col\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cc29f228",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Majority class\n",
    "no_cancer = train_data[train_data['label'] == 0]\n",
    "# Minority class\n",
    "cancer = train_data[train_data['label'] == 1]\n",
    "\n",
    "# Downsample majority class to match minority class\n",
    "no_cancer_downsampled = resample(no_cancer,\n",
    "                              replace=False, \n",
    "                              n_samples=len(cancer),\n",
    "                              random_state=0)\n",
    "\n",
    "balanced_train_data = pd.concat([no_cancer_downsampled, cancer])\n",
    "\n",
    "# Shuffle train data for training\n",
    "balanced_train_data = balanced_train_data.sample(frac=1, random_state=0).reset_index(drop=True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f1e582c2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Cleaning\n",
    "del no_cancer, cancer, no_cancer_downsampled\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8d184dbc",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get full path to image including extension\n",
    "image_paths = train_dir + balanced_train_data['id'] + '.tif'\n",
    "image_paths = image_paths.values\n",
    "\n",
    "labels = balanced_train_data['label'].values\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(image_paths\n",
    "                                                    , labels\n",
    "                                                    , test_size = 0.25\n",
    "                                                    , shuffle = True\n",
    "                                                    , random_state = 0)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bd0d59dc",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Cleaning\n",
    "del image_paths, labels\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "da6db637",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_decoded_image(image_path, label=None):\n",
    "    \"\"\"\n",
    "    Load and preprocess images using TensorFlow I/O.\n",
    "    Decode image with 4 channels RGBA.\n",
    "    Resize image to 32x32px.\n",
    "    Scale pixels from 0 to 1.\n",
    "    Args:\n",
    "        image_path: path to TIFF image\n",
    "        label (optional): true label from train data\n",
    "    Returns:\n",
    "        (img, label): for train data\n",
    "        img: for test data\n",
    "    \"\"\"\n",
    "    img = tf.io.read_file(image_path)\n",
    "    img = tfio.experimental.image.decode_tiff(img)\n",
    "    img = tf.image.resize(img, [32, 32])\n",
    "    img = tf.cast(img, tf.float32) / 255.0\n",
    "    \n",
    "    return img if label is None else (img, label)\n",
    "\n",
    "def get_prefetched_data(data, batch_size):\n",
    "    \"\"\"\n",
    "    Create a TensorFlow dataset from image paths and labels.\n",
    "    Execution in parallel.\n",
    "    Load, preprocess images and batch the data.\n",
    "    Prefetch batches to improve training performance.\n",
    "    Args:\n",
    "        data (tuple): image paths and corresponding labels\n",
    "        batch_size (int): number of samples per batch\n",
    "    Returns:\n",
    "        tf.data.Dataset: preprocessed and preloaded TensorFlow dataset for keras CNN\n",
    "    \"\"\"\n",
    "    # Autotune the degree of parallelism during training\n",
    "    AUTOTUNE = tf.data.experimental.AUTOTUNE\n",
    "    \n",
    "    # Create dataset from image paths and labels\n",
    "    dataset = tf.data.Dataset.from_tensor_slices(data)\n",
    "    \n",
    "    # Apply parallel processing to load and preprocess images\n",
    "    dataset = dataset.map(get_decoded_image, num_parallel_calls=AUTOTUNE)\n",
    "    dataset = dataset.batch(batch_size)\n",
    "    dataset = dataset.prefetch(buffer_size=AUTOTUNE)\n",
    "    \n",
    "    return dataset\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "28eba53c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Set 128 samples to be processed in each training step\n",
    "BATCH_SIZE = 128\n",
    "\n",
    "train_dataset = get_prefetched_data((X_train, y_train)\n",
    "                                    , BATCH_SIZE)\n",
    "test_dataset = get_prefetched_data((X_test, y_test)\n",
    "                                   , BATCH_SIZE)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3046b92f",
   "metadata": {},
   "outputs": [],
   "source": [
    "del X_train, y_train, X_test, y_test\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cdcf71f2",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_model_base():\n",
    "    \"\"\"\n",
    "    Return base model architecture\n",
    "    \"\"\"\n",
    "    model = models.Sequential([\n",
    "        layers.Conv2D(32, (3, 3), activation='relu', input_shape=(32, 32, 4))\n",
    "\n",
    "        , layers.Flatten()\n",
    "\n",
    "        , layers.Dense(32, activation='relu')\n",
    "\n",
    "        , layers.Dense(1, activation='sigmoid')\n",
    "    ])\n",
    "    \n",
    "    return model\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f9698bd8",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_model_base_deep():\n",
    "    \"\"\"\n",
    "    Return deeper model architecture\n",
    "    \"\"\"\n",
    "    model = models.Sequential([\n",
    "        layers.Conv2D(32, (3, 3), activation='relu', input_shape=(32, 32, 4))\n",
    "        # Add new convolutional layer\n",
    "        , layers.Conv2D(32, (3, 3), activation='relu')\n",
    "\n",
    "        , layers.Flatten()\n",
    "\n",
    "        , layers.Dense(32, activation='relu')\n",
    "        # Add new dense layer\n",
    "        , layers.Dense(32, activation='relu')\n",
    "\n",
    "        , layers.Dense(1, activation='sigmoid')\n",
    "    ])\n",
    "    \n",
    "    return model\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "674c638e",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_model_base_wide():\n",
    "    \"\"\"\n",
    "    Return wider model architecture\n",
    "    \"\"\"\n",
    "    model_drop_bn = models.Sequential([\n",
    "        # Increase number of units from 32 to 64\n",
    "        layers.Conv2D(64, (3, 3), activation='relu', input_shape=(32, 32, 4))\n",
    "\n",
    "        , layers.Flatten()\n",
    "        \n",
    "        # Increase number of units from 32 to 64\n",
    "        , layers.Dense(64, activation='relu')\n",
    " \n",
    "        , layers.Dense(1, activation='sigmoid')\n",
    "    ])\n",
    "    \n",
    "    return model_drop_bn\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8eda9c02",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_model_base_maxpool():\n",
    "    \"\"\"\n",
    "    Return maxpool model architecture\n",
    "    \"\"\"\n",
    "    model = models.Sequential([\n",
    "        layers.Conv2D(32, (3, 3), activation='relu', input_shape=(32, 32, 4))\n",
    "        # Add new layer of max pooling\n",
    "        , layers.MaxPooling2D((2, 2), strides = (2,2))\n",
    "\n",
    "        , layers.Flatten()\n",
    "\n",
    "        , layers.Dense(32, activation='relu')\n",
    "        \n",
    "        , layers.Dense(1, activation='sigmoid')\n",
    "    ])\n",
    "    \n",
    "    return model\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fa2d2d5b",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_model_base_dropout():\n",
    "    \"\"\"\n",
    "    Return dropout model architecture\n",
    "    \"\"\"\n",
    "    model = models.Sequential([\n",
    "        layers.Conv2D(32, (3, 3), activation='relu', input_shape=(32, 32, 4))\n",
    "\n",
    "        , layers.Flatten()\n",
    "\n",
    "        , layers.Dense(32, activation='relu')\n",
    "        \n",
    "        # Add new dropout layer \n",
    "        , layers.Dropout(0.25)\n",
    "        \n",
    "        , layers.Dense(1, activation='sigmoid')\n",
    "    ])\n",
    "    \n",
    "    return model\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "60d70eea",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_compiled_model(func):\n",
    "    \"\"\"\n",
    "    Create model to be trained with a multi-GPU strategy.\n",
    "    Args:\n",
    "        func: function to get model architecture\n",
    "    Returns:\n",
    "        compiled_model: tensorflow model that performs data parallelism\n",
    "                            by copying all of the model's variables\n",
    "                            to each processor\n",
    "    \"\"\"\n",
    "    # Check if GPU is available\n",
    "    gpus = tf.config.experimental.list_physical_devices('GPU')\n",
    "    if gpus:\n",
    "        # Create a MirroredStrategy.\n",
    "        strategy = tf.distribute.MirroredStrategy()\n",
    "\n",
    "        print('Number of devices: {}'.format(strategy.num_replicas_in_sync))\n",
    "    else:\n",
    "        strategy = tf.distribute.OneDeviceStrategy(device=\"/cpu:0\")\n",
    "        print('No GPU available, falling back to CPU.')\n",
    "\n",
    "    with strategy.scope():\n",
    "        compiled_model = func()\n",
    "        compiled_model.compile(optimizer = tf.keras.optimizers.Adam()\n",
    "                              , loss = tf.keras.losses.BinaryCrossentropy()\n",
    "                              , metrics = [tf.keras.metrics.AUC()])\n",
    "\n",
    "    return compiled_model\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "29915763",
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_model_scores(scores, model_name):\n",
    "    \"\"\"\n",
    "    Plot train and test ROC AUC scores of a model by epoch\n",
    "    \"\"\"\n",
    "    train_scores, test_scores = scores\n",
    "    epochs = range(1, len(train_scores) + 1)\n",
    "\n",
    "    # Plot train and test scores\n",
    "    plt.figure(figsize=(16, 9))\n",
    "    plt.plot(epochs, train_scores, label='Train score')\n",
    "    plt.plot(epochs, test_scores, label='Test score')\n",
    "    plt.title('Train and test ROC AUC scores of the {}'.format(model_name))\n",
    "    plt.xlabel('Epoch')\n",
    "    plt.ylabel('ROC AUC Score')\n",
    "    plt.legend()\n",
    "    plt.grid(True)\n",
    "    plt.show()\n",
    "\n",
    "    \n",
    "def get_model_results(model_name, model):\n",
    "    \"\"\"\n",
    "    Return tuple of runtime, train and test scores.\n",
    "    Compile, fit and save model along the way.\n",
    "    Args:\n",
    "        model: fitted model\n",
    "    Returns:\n",
    "        (runtime, (train_scores, test_scores) )\n",
    "    \"\"\"\n",
    "    model = get_compiled_model(model)\n",
    "    \n",
    "    st = time.time()\n",
    "    model.fit(train_dataset, epochs=5, validation_data=test_dataset)\n",
    "    runtime = time.time() - st\n",
    "    \n",
    "    model.save('{}.h5'.format(model_name))\n",
    "    \n",
    "    train_scores = model.history.history['auc']\n",
    "    test_scores = model.history.history['val_auc']\n",
    "    \n",
    "    tf.keras.backend.clear_session()\n",
    "    \n",
    "    return (runtime, (train_scores, test_scores))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "718e6083",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get train and test scores of every epoch\n",
    "runtime_base, scores_base = get_model_results('model_base',get_model_base)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "20f1946f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plot scores\n",
    "plot_model_scores(scores_base, 'base model')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "396d00c0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get train and test scores of every epoch\n",
    "runtime_base_deep, scores_base_deep = get_model_results('model_base_deep'\n",
    "                                                          ,get_model_base_deep)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d6a51eb3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plot scores\n",
    "plot_model_scores(scores_base_deep, 'base + additional layers model')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a90e7752",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get train and test scores of every epoch\n",
    "runtime_base_wide, scores_base_wide = get_model_results('model_base_wide'\n",
    "                                                          ,get_model_base_wide)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e6b3c004",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plot scores\n",
    "plot_model_scores(scores_base_wide, 'base + wider layers model')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7944e563",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get train and test scores of every epoch\n",
    "runtime_base_maxpool, scores_base_maxpool = get_model_results('model_base_maxpool'\n",
    "                                                                ,get_model_base_maxpool)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0b3f2468",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plot scores\n",
    "plot_model_scores(scores_base_maxpool, 'base + max pooling model')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bdd1cdf0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get train and test scores of every epoch\n",
    "runtime_base_dropout, scores_base_dropout = get_model_results('model_base_dropout'\n",
    "                                                                ,get_model_base_dropout)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d2e449dc",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plot scores\n",
    "plot_model_scores(scores_base_dropout, 'base + dropout model')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3aab4516",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Print table results comparison\n",
    "results = [('Base', runtime_base, scores_base)\n",
    "          ,('Base + Add. layers', runtime_base_deep, scores_base_deep)\n",
    "          ,('Base + Wider layers', runtime_base_wide, scores_base_wide)\n",
    "          ,('Base + Max pooling', runtime_base_maxpool, scores_base_maxpool)\n",
    "          ,('Base + Dropout', runtime_base_dropout, scores_base_dropout)]\n",
    "table = []\n",
    "for i in range(len(results)):\n",
    "    tmp = {\n",
    "            'model': results[i][0]\n",
    "            , 'runtime (sec)': results[i][1]\n",
    "            , 'train_roc_auc_score': results[i][2][0][-1]\n",
    "            , 'test_roc_auc_score': results[i][2][1][-1]\n",
    "        }\n",
    "    table.append(tmp)\n",
    "\n",
    "\n",
    "pd.DataFrame(table).sort_values(by = ['test_roc_auc_score'\n",
    "                                      ,'runtime (sec)']\n",
    "                                , ascending = [False, True])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cd1cfd06",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Cleaning\n",
    "del results, tmp, table, train_dataset, test_dataset, train_data, train_dir, test_dir\n",
    "del get_model_results, plot_model_scores, get_compiled_model\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "54313706",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load top performed model\n",
    "model = load_model('model_base_deep.h5')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "84b4dd04",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create prefethed dataset of images to classify\n",
    "submis_data = test_dir + sample_data['id'] + '.tif'\n",
    "submis_data = submis_data.values\n",
    "\n",
    "submis_dataset = get_prefetched_data((submis_data)\n",
    "                                    , BATCH_SIZE)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a074f091",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Set results\n",
    "results = model.predict(submis_dataset)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "151969f2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create table of ids and labels like sample_submission\n",
    "sample_data['label'] = np.ravel(np.round(results))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6974d829",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Print submission table\n",
    "sample_data\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "648b7a62",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Make submission\n",
    "sample_data.to_csv('submission.csv', index=False)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b5411b04",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Cleaning\n",
    "del submis_data, submis_dataset, sample_data\n",
    "del get_decoded_image, get_prefetched_data\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2e527221",
   "metadata": {},
   "outputs": [],
   "source": [
    " \n"
   ]
  }
 ],
 "metadata": {},
 "nbformat": 4,
 "nbformat_minor": 5
}

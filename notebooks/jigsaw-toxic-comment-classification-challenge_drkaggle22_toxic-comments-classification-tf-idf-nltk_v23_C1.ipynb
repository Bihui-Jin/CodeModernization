{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "9f5fe6cc",
      "metadata": {},
      "outputs": [],
      "source": [
        "import pandas as pd\n",
        "from pathlib import Path"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "3b753e42",
      "metadata": {},
      "outputs": [],
      "source": [
        "# This Python 3 environment comes with many helpful analytics libraries installed\n",
        "# It is defined by the kaggle/python Docker image: https://github.com/kaggle/docker-python\n",
        "# For example, here's several helpful packages to load\n",
        "\n",
        "import numpy as np # linear algebra\n",
        "import pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\n",
        "\n",
        "# Input data files are available in the read-only \"../input/\" directory\n",
        "# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n",
        "\n",
        "import os\n",
        "for dirname, _, filenames in os.walk('/kaggle/input'):\n",
        "    for filename in filenames:\n",
        "        print(os.path.join(dirname, filename))\n",
        "\n",
        "# You can write up to 20GB to the current directory (/kaggle/working/) that gets preserved as output when you create a version using \"Save & Run All\" \n",
        "# You can also write temporary files to /kaggle/temp/, but they won't be saved outside of the current session\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "5013fbf5",
      "metadata": {},
      "outputs": [],
      "source": [
        "df_train = pd.read_csv('/kaggle/input/jigsaw-toxic-comment-classification-challenge/train.csv.zip', index_col='id')\n",
        "\n",
        "df_test = pd.read_csv('/kaggle/input/jigsaw-toxic-comment-classification-challenge/test.csv.zip', index_col='id')\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "d38d5e83",
      "metadata": {},
      "outputs": [],
      "source": [
        "pd.set_option('display.max_rows', None)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "8bcfc2ca",
      "metadata": {},
      "outputs": [],
      "source": [
        "df = pd.concat([df_train, df_test])\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "4eb2a987",
      "metadata": {},
      "outputs": [],
      "source": [
        "df_train['comment_text'] = df_train['comment_text'].str.lower()\n",
        "df_test['comment_text'] = df_test['comment_text'].str.lower()\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "8d1c1d23",
      "metadata": {},
      "outputs": [],
      "source": [
        "df_train.info()\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "eea80710",
      "metadata": {},
      "outputs": [],
      "source": [
        "import re\n",
        "\n",
        "def remove_special_characters(text):\n",
        "    text = re.sub(r'http\\S+', ' ', text )\n",
        "    text = re.sub(r'[^\\w\\s]', ' ', text)\n",
        "    text = re.sub(r'\\bhttps?://[a-zA-Z0-9-]+(?:\\.[a-zA-Z0-9-]+)+\\b', ' ', text)\n",
        "    text = re.sub(r'\\s+', ' ', text).strip()\n",
        "    text = re.sub(r'\\d', ' ', text)  # Corrected line\n",
        "    text= re.sub(r'[\\u4e00-\\u9fff]+', ' ', text)\n",
        "    return text\n",
        "\n",
        "df_train['comment_text'] = df_train['comment_text'].apply(remove_special_characters)\n",
        "df_test['comment_text'] = df_test['comment_text'].apply(remove_special_characters)\n",
        "\n",
        "print(df_train['comment_text'].head(100))\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "126de4b4",
      "metadata": {},
      "outputs": [],
      "source": [
        "import string \n",
        "from nltk import word_tokenize\n",
        "\n",
        "df_train['tokens'] = df_train['comment_text'].apply(word_tokenize)\n",
        "df_test['tokens'] = df_test['comment_text'].apply(word_tokenize)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "dcedb1e3",
      "metadata": {},
      "outputs": [],
      "source": [
        "from sklearn.model_selection import train_test_split\n",
        "train, valid = train_test_split(df_train, train_size=0.8, random_state=42)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "98d6ddc8",
      "metadata": {},
      "outputs": [],
      "source": [
        "from sklearn.feature_extraction.text import TfidfVectorizer\n",
        "from nltk import word_tokenize\n",
        "\n",
        "vec = TfidfVectorizer(ngram_range=(1, 2), \n",
        "                      min_df=3, \n",
        "                      max_df=0.9, \n",
        "                      strip_accents='unicode', \n",
        "                      use_idf=1,\n",
        "                      smooth_idf=1, \n",
        "                      sublinear_tf=1,\n",
        "                      binary=1,\n",
        "                      stop_words='english')\n",
        "trn_term_doc = vec.fit_transform(df_train['comment_text'])\n",
        "val_term_doc = vec.transform(valid['comment_text'])\n",
        "test_term_doc = vec.transform(df_test['comment_text'])\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "70c411ac",
      "metadata": {},
      "outputs": [],
      "source": [
        "x = trn_term_doc\n",
        "val_x = val_term_doc\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "e7f04eaa",
      "metadata": {},
      "outputs": [],
      "source": [
        "from sklearn.linear_model import LogisticRegression\n",
        "from sklearn.metrics import roc_auc_score\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "a101e321",
      "metadata": {},
      "outputs": [],
      "source": [
        "epsilon = 1e-9  # Define epsilon as a small positive constant\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "1c50c230",
      "metadata": {},
      "outputs": [],
      "source": [
        "# Define a function to calculate the probability of each word given a specific class (toxic or non-toxic)\n",
        "def probability(y_i, y):\n",
        "    # Sum the occurrences of each word in comments labeled with y_i (1 for toxic, 0 for non-toxic)\n",
        "    occurences = x[y == y_i].sum(0)\n",
        "    # Add a smoothing factor of 1 to avoid division by zero and handle words not present in some classes\n",
        "    \n",
        "    return (occurences + 1) / ((y == y_i).sum() + 1)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "e3a8a182",
      "metadata": {},
      "outputs": [],
      "source": [
        "# Define a function to train a logistic regression model for binary classification (toxic or non-toxic)\n",
        "def get_model(y):\n",
        "    # Convert the target labels to a numpy array\n",
        "    y = y.values\n",
        "    # Calculate the log-ratio of probabilities of each word being toxic vs. non-toxic\n",
        "    loga = np.log((probability(1, y) + epsilon) / (probability(0, y) + epsilon) )\n",
        "    # Multiply the input features by the log-ratio to incorporate the information about word toxicity\n",
        "    x_loga = x.multiply(loga)\n",
        "    # Initialize a naive bayes model with specified hyperparameters\n",
        "    model = LogisticRegression(C=1.0,  # Regularization parameter\n",
        "                                    penalty='l2',  # Penalty term ('l1' or 'l2')\n",
        "                                    solver='liblinear',  # Optimization algorithm\n",
        "                                    max_iter=100,  # Maximum number of iterations\n",
        "                                    random_state=42)\n",
        "    \n",
        "    # Fit the model to the modified input features and target labels\n",
        "    return model.fit(x_loga, y), loga\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "78524170",
      "metadata": {},
      "outputs": [],
      "source": [
        "classes = ['toxic', 'severe_toxic', 'obscene', 'threat', 'insult', 'identity_hate']\n",
        "train_labels = df_train.drop([ 'comment_text'], axis = 1)\n",
        "valid_labels = valid.drop([ 'comment_text'], axis = 1)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "21d7a26a",
      "metadata": {},
      "outputs": [],
      "source": [
        "  # Dictionary to store ROC AUC scores for each class\n",
        "model = {}\n",
        "ROC_AUC_Scores = {}\n",
        "for i, col in enumerate(classes):\n",
        "    print(col)\n",
        "\n",
        "    # Train model for current class\n",
        "    model_trained, loga = get_model(train_labels[col])\n",
        "    model[col] = (model_trained, loga)\n",
        "    # Make predictions on validation set\n",
        "    preds = model_trained.predict(val_x.multiply(loga)).reshape(-1, 1)\n",
        "\n",
        "    # Calculate ROC AUC score for current class and store it\n",
        "    roc_auc = roc_auc_score(valid_labels[col], preds)\n",
        "    ROC_AUC_Scores[col] = roc_auc\n",
        "    # Print ROC AUC scores for each class\n",
        "for col, roc_auc in ROC_AUC_Scores.items():\n",
        "    print(f\"ROC AUC for class: '{col}': {roc_auc}\")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "fe74a4fd",
      "metadata": {},
      "outputs": [],
      "source": [
        "preds = np.zeros((len(df_test), len(classes)))\n",
        "\n",
        "for i, col in enumerate(classes):\n",
        "    print(col)\n",
        "    preds[:, i] = model[col][0].predict_proba(test_term_doc.multiply(model[col][1]))[:, 1]\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "9cdf2568",
      "metadata": {},
      "outputs": [],
      "source": [
        "submid = pd.DataFrame({'id': df_test.index})  # Use index as 'id' column\n",
        "submission = pd.concat([submid, pd.DataFrame(preds, columns=classes)], axis=1)\n",
        "submission.to_csv('submission.csv', index=False)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "14dfe51f",
      "metadata": {},
      "outputs": [],
      "source": [
        "submission.head()\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "9c8f1d5c",
      "metadata": {},
      "outputs": [],
      "source": [
        " \n"
      ]
    }
  ],
  "metadata": {},
  "nbformat": 4,
  "nbformat_minor": 5
}
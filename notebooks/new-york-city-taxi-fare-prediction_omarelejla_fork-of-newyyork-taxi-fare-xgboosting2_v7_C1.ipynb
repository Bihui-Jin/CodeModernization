{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4aa13ce2",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from pathlib import Path"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ac6e8ef0",
   "metadata": {},
   "outputs": [],
   "source": [
    "#install tensorflowv2\n",
    "! pip install tensorflow==2.0.0-rc0 \n",
    "import tensorflow as tf\n",
    "print(tf.__version__)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "612ec203",
   "metadata": {},
   "outputs": [],
   "source": [
    "# For example, here's several helpful packages to load in \n",
    "\n",
    "import numpy as np # linear algebra\n",
    "import pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\n",
    "from sklearn.ensemble import RandomForestRegressor\n",
    "import pandas as pd \n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "\n",
    "\n",
    "# Input data files are available in the \"../input/\" directory.\n",
    "# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n",
    "\n",
    "import os\n",
    "for dirname, _, filenames in os.walk('/kaggle/input'):\n",
    "    for filename in filenames:\n",
    "        print(os.path.join(dirname, filename))\n",
    "#loading dataset\n",
    "train_iop_path='/kaggle/input/new-york-city-taxi-fare-prediction/train.csv'\n",
    "test_iop_path='/kaggle/input/new-york-city-taxi-fare-prediction/test.csv'\n",
    "dataset_train=pd.read_csv(train_iop_path, nrows=10_000, index_col='key')\n",
    "dataset_test=pd.read_csv(test_iop_path, nrows=10000, index_col='key')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7523e936",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"dataset_train old size\", len(dataset_train))\n",
    "\n",
    "dataset_train = dataset_train[dataset_train.dropoff_longitude != 0]\n",
    "print(\"new size\", len(dataset_train))\n",
    "dataset_train.head(5)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "89b775c8",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"dataset_test old size\", len(dataset_test))\n",
    "\n",
    "dataset_test = dataset_test[dataset_test.dropoff_longitude != 0]\n",
    "print(\"new size\", len(dataset_test))\n",
    "dataset_test.head(5)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f1270a3e",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_year(pickup_date):\n",
    "  return pickup_date.year\n",
    "def get_month(pickup_date):\n",
    "  return pickup_date.month\n",
    "def get_day(pickup_date):\n",
    "  return pickup_date.day\n",
    "def get_hour(pickup_date):\n",
    "  return pickup_date.hour       \n",
    "     \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e23018cf",
   "metadata": {},
   "outputs": [],
   "source": [
    "from datetime import datetime as dt\n",
    "import warnings\n",
    "\n",
    "def preparedataset2(datasetname):\n",
    "    warnings.filterwarnings(\"ignore\")\n",
    "    datasetname.info()\n",
    "    datasetname['pickup_datetime']= pd.to_datetime(datasetname['pickup_datetime']) \n",
    "    datasetname['pickup_year'] = datasetname.apply(lambda x: get_year(x['pickup_datetime']),axis=1)\n",
    "    datasetname['pickup_month'] = datasetname.apply(lambda x: get_month(x['pickup_datetime']),axis=1)\n",
    "    datasetname['pickup_day'] = datasetname.apply(lambda x: get_day(x['pickup_datetime']),axis=1)\n",
    "    datasetname['pickup_hour'] = datasetname.apply(lambda x: get_hour(x['pickup_datetime']),axis=1)\n",
    "    datasetname['x_dis'] = (datasetname['dropoff_longitude'] - datasetname['pickup_longitude'])  \n",
    "    datasetname['y_dis'] = (datasetname['dropoff_latitude'] - datasetname['pickup_latitude']) \n",
    "    datasetname['dis'] = ((datasetname['dropoff_longitude'] - datasetname['pickup_longitude'])**2 + (datasetname['dropoff_latitude']-datasetname['pickup_latitude'])**2)**.5 \n",
    "    datasetname=datasetname.drop(['pickup_datetime'],axis=1)\n",
    "    datasetname=datasetname.drop(['pickup_longitude'],axis=1)\n",
    "    datasetname=datasetname.drop(['dropoff_latitude'],axis=1)\n",
    "    datasetname=datasetname.drop(['dropoff_longitude'],axis=1)\n",
    "    datasetname=datasetname.drop(['pickup_latitude'],axis=1)\n",
    "\n",
    "   # datasetname.info()\n",
    "    return datasetname\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "461940c8",
   "metadata": {},
   "outputs": [],
   "source": [
    "#old preprocesing \n",
    "from datetime import datetime as dt\n",
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")\n",
    "def preparedataset(datasetname):\n",
    "    datasetname['pickup_year']=0\n",
    "    datasetname['pickup_month']=0\n",
    "    datasetname['pickup_day']=0\n",
    "    datasetname['pickup_hour']=0\n",
    "  #  datasetname['pickup_minute']=0\n",
    " #   datasetname['pickup_second']=0\n",
    "    datasetname['dis'] =0\n",
    "    datasetname['x_dis']=0\n",
    "    datasetname['y_dis']=0\n",
    "    \n",
    "    datasetname.head()\n",
    "#print(datetime.strptime(df['pickup_datetime'][0].replace(\"UTC\",''),\"%Y-%m-%d %H:%M:%S \"))\n",
    "\n",
    "    for k in range(len(datasetname.index)):\n",
    "        datetime=dt.strptime(datasetname['pickup_datetime'][k].replace(\"UTC\",''),\"%Y-%m-%d %H:%M:%S \")\n",
    "        datasetname['pickup_year'][k]=datetime.year\n",
    "        datasetname['pickup_month'][k]=datetime.month\n",
    "        datasetname['pickup_day'][k]=datetime.day\n",
    "        datasetname['pickup_hour'][k]=datetime.hour\n",
    "      # datasetname['pickup_minute'][k]=datetime.minute\n",
    "      # datasetname['pickup_second'][k]=datetime.second\n",
    "        \n",
    "    datasetname['x_dis'] = (datasetname['dropoff_longitude'] - datasetname['pickup_longitude'])  \n",
    "    datasetname['y_dis'] = (datasetname['dropoff_latitude'] - datasetname['pickup_latitude']) \n",
    "    datasetname['dis'] = ((datasetname['dropoff_longitude'] - datasetname['pickup_longitude'])**2 + (datasetname['dropoff_latitude']-datasetname['pickup_latitude'])**2)**.5 \n",
    "    datasetname=datasetname.drop(['pickup_datetime'],axis=1)\n",
    "    datasetname=datasetname.drop(['pickup_longitude'],axis=1)\n",
    "    datasetname=datasetname.drop(['dropoff_latitude'],axis=1)\n",
    "    datasetname=datasetname.drop(['dropoff_longitude'],axis=1)\n",
    "    datasetname=datasetname.drop(['pickup_latitude'],axis=1)\n",
    "\n",
    "    return datasetname\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2d768084",
   "metadata": {},
   "outputs": [],
   "source": [
    "df=preparedataset2(dataset_train)\n",
    "df.head(5)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ff488ac3",
   "metadata": {},
   "outputs": [],
   "source": [
    "test_df=preparedataset2(dataset_test)\n",
    "test_df.head(5)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b38de403",
   "metadata": {},
   "outputs": [],
   "source": [
    "#spliting the dataset \n",
    "from sklearn.model_selection import train_test_split\n",
    "y = df.fare_amount\n",
    "X=df.drop('fare_amount',axis=1)\n",
    "X_train, X_valid, y_train, y_valid = train_test_split(X, y)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "51310335",
   "metadata": {},
   "outputs": [],
   "source": [
    "#applying XCbossting \n",
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")\n",
    "from xgboost import XGBRegressor\n",
    "from sklearn.metrics import mean_absolute_error\n",
    "result={}\n",
    "best_istemator=0\n",
    "best_learing_rate=0\n",
    "best_mae=100000000000\n",
    "for lr in [X / 100 for X in range(10,50, 5)]:\n",
    "    for ns in range(200,701,50):\n",
    "        #print(\"n_estimators\",ns)\n",
    "        #print(\"learning_rate\",lr)\n",
    "        my_model = XGBRegressor(n_estimators=ns, learning_rate=lr,n_jobs=4)\n",
    "        my_model.fit(X_train, y_train)\n",
    "\n",
    "        predictions = my_model.predict(X_valid)\n",
    "\n",
    "        mae=mean_absolute_error(predictions, y_valid)\n",
    "        if(mae < best_mae):\n",
    "            best_mae=mae\n",
    "            best_istemator=ns\n",
    "            best_learing_rate=lr\n",
    "            print(\"better found\")\n",
    "            print(ns , lr, mae)\n",
    "        result[(ns,lr)]=mae\n",
    "my_model_2 = XGBRegressor(n_estimators=best_istemator, learning_rate=best_learing_rate, n_jobs=4)\n",
    "my_model_2.fit(X_train,y_train)\n",
    "predictions_2 = my_model_2.predict(X_valid)\n",
    "mae_2 = mean_absolute_error( y_valid, predictions_2) \n",
    "# Uncomment to print MAE\n",
    "print(\"best_istemator:\" , best_istemator)\n",
    "print(\"best_learing_rate:\" , best_learing_rate)\n",
    "print(\"Mean Absolute Error:\" , mae_2)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "39197599",
   "metadata": {},
   "outputs": [],
   "source": [
    "from xgboost import XGBRegressor\n",
    "my_model_2 = XGBRegressor(n_estimators=700, learning_rate=0.2, n_jobs=4)\n",
    "my_model_2.fit(X_train,y_train)\n",
    "\n",
    "test_preds = my_model_2.predict(test_df)\n",
    "\n",
    "output = pd.DataFrame({'key': test_df.index,\n",
    "                      'fare_amount': test_preds})\n",
    "output.to_csv('submission.csv', index=False)\n"
   ]
  }
 ],
 "metadata": {},
 "nbformat": 4,
 "nbformat_minor": 5
}

{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "67fde8dc",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from pathlib import Path"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bb728d95",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import os\n",
    "\n",
    "import glob\n",
    "\n",
    "import tensorflow as tf\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "AUTOTUNE = tf.data.experimental.AUTOTUNE\n",
    "\n",
    "import torch\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dd62e149",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"Num GPUs Available: \", len(tf.config.experimental.list_physical_devices('GPU')))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d73f0b75",
   "metadata": {},
   "outputs": [],
   "source": [
    "import zipfile\n",
    "zip_df = zipfile.ZipFile(\"/kaggle/input/dogs-vs-cats-redux-kernels-edition/train.zip\", 'r')\n",
    "zip_df.extractall(\"/kaggle/working/\")\n",
    "zip_df.close()\n",
    "zip_df = zipfile.ZipFile(\"/kaggle/input/dogs-vs-cats-redux-kernels-edition/test.zip\", 'r')\n",
    "zip_df.extractall(\"/kaggle/working/\")\n",
    "zip_df.close()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9971733a",
   "metadata": {},
   "outputs": [],
   "source": [
    "#folder check\n",
    "dataset_path = './dataset'\n",
    "if not os.path.isdir(dataset_path):\n",
    "    os.mkdir(dataset_path)\n",
    "\n",
    "train_path = os.path.join(dataset_path,'train')\n",
    "val_path = os.path.join(dataset_path,'val')\n",
    "test_path = os.path.join(dataset_path,'test')\n",
    "if not os.path.isdir(train_path):\n",
    "    os.mkdir(train_path)\n",
    "if not os.path.isdir(val_path):\n",
    "    os.mkdir(val_path)\n",
    "if not os.path.isdir(test_path):\n",
    "    os.mkdir(test_path)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "be5c9121",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_path(path,name):\n",
    "    return glob.glob(path+'/*.'+name)\n",
    "check = lambda x: 1 if x.split('.')[1].split('/')[-1] == 'dog' else 0\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cfc4d37b",
   "metadata": {},
   "outputs": [],
   "source": [
    "data_list = get_path('./train','jpg')\n",
    "result = list(map(check,data_list))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1d8c6024",
   "metadata": {},
   "outputs": [],
   "source": [
    "print('dogs:',result.count(1),'cats:',result.count(0))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d7f05e60",
   "metadata": {},
   "outputs": [],
   "source": [
    "dogs_list = [i for i in data_list if check(i)]\n",
    "cats_list = [i for i in data_list if not check(i)]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5aa21f00",
   "metadata": {},
   "outputs": [],
   "source": [
    "split_ratio = 0.8\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c560979a",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_data = []\n",
    "val_data = []\n",
    "train_label = []\n",
    "val_label = []\n",
    "\n",
    "for i in range(12500):\n",
    "    if (i < len(data_list)/2*split_ratio):\n",
    "        train_data.append(dogs_list[i])\n",
    "        train_data.append(cats_list[i])\n",
    "    else:\n",
    "        val_data.append(dogs_list[i])\n",
    "        val_data.append(cats_list[i])\n",
    "\n",
    "train_label = list(map(check,train_data))\n",
    "val_label = list(map(check,val_data))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fca8a961",
   "metadata": {},
   "outputs": [],
   "source": [
    "class_label = ['dog','cat']\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "02cc8869",
   "metadata": {},
   "outputs": [],
   "source": [
    "img_size = 224\n",
    "\n",
    "def preprocess_image(image):\n",
    "  image = tf.image.decode_jpeg(image, channels=3)\n",
    "  image = tf.image.resize(image, [img_size, img_size])\n",
    "\n",
    "  return image\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ca9e2d87",
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_and_preprocess_image(path):\n",
    "  image = tf.io.read_file(path)\n",
    "  return preprocess_image(image)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "516b38c9",
   "metadata": {},
   "outputs": [],
   "source": [
    "ds_train = tf.data.Dataset.from_tensor_slices((train_data,train_label))\n",
    "ds_val = tf.data.Dataset.from_tensor_slices((val_data,val_label))\n",
    "\n",
    "def load_and_preprocess_from_path_label(path, label):\n",
    "  return load_and_preprocess_image(path), tf.one_hot(label, 2)\n",
    "\n",
    "ds_train = ds_train.map(load_and_preprocess_from_path_label)\n",
    "ds_val = ds_val.map(load_and_preprocess_from_path_label)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "09d10afc",
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras.applications import EfficientNetB0\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras import layers\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "afa464b8",
   "metadata": {},
   "outputs": [],
   "source": [
    "batch_size = 64\n",
    "dsb_train = ds_train.batch(batch_size=batch_size, drop_remainder=True)\n",
    "dsb_train = dsb_train.prefetch(tf.data.AUTOTUNE)\n",
    "\n",
    "dsb_val = ds_val.batch(batch_size=batch_size, drop_remainder=True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "31e21bae",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = EfficientNetB0(weights='imagenet', drop_connect_rate=0.4)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "90f2bb72",
   "metadata": {},
   "outputs": [],
   "source": [
    "img_augmentation = Sequential(\n",
    "    [\n",
    "        layers.RandomRotation(factor=0.15),\n",
    "        layers.RandomTranslation(height_factor=0.1, width_factor=0.1),\n",
    "        layers.RandomFlip(),\n",
    "        layers.RandomContrast(factor=0.1),\n",
    "    ],\n",
    "    name=\"img_augmentation\",\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cdd992e7",
   "metadata": {},
   "outputs": [],
   "source": [
    "def build_model(num_classes):\n",
    "    inputs = layers.Input(shape=(img_size, img_size, 3))\n",
    "    x = img_augmentation(inputs)\n",
    "    model = EfficientNetB0(include_top=False, input_tensor=x, weights=\"imagenet\")\n",
    "\n",
    "    # Freeze the pretrained weights\n",
    "    model.trainable = False\n",
    "\n",
    "    # Rebuild top\n",
    "    x = layers.GlobalAveragePooling2D(name=\"avg_pool\")(model.output)\n",
    "    x = layers.BatchNormalization()(x)\n",
    "\n",
    "    top_dropout_rate = 0.2\n",
    "    x = layers.Dropout(top_dropout_rate, name=\"top_dropout\")(x)\n",
    "    outputs = layers.Dense(num_classes, activation=\"softmax\", name=\"pred\")(x)\n",
    "\n",
    "    # Compile\n",
    "    model = tf.keras.Model(inputs, outputs, name=\"EfficientNet\")\n",
    "    optimizer = tf.keras.optimizers.Adam(learning_rate=1e-2)\n",
    "    model.compile(\n",
    "        optimizer=optimizer, loss=\"categorical_crossentropy\", metrics=[\"accuracy\"]\n",
    "    )\n",
    "    return model\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "31d656a0",
   "metadata": {},
   "outputs": [],
   "source": [
    "strategy = tf.distribute.MirroredStrategy()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "63805694",
   "metadata": {},
   "outputs": [],
   "source": [
    "#with strategy.scope():\n",
    "new_model = build_model(num_classes=2)\n",
    "\n",
    "epochs = 10  \n",
    "hist = new_model.fit(dsb_train, epochs=epochs, validation_data=dsb_val, verbose=2)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d2bd8064",
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_hist(hist):\n",
    "    plt.plot(hist.history[\"accuracy\"])\n",
    "    plt.plot(hist.history[\"val_accuracy\"])\n",
    "    plt.title(\"model accuracy\")\n",
    "    plt.ylabel(\"accuracy\")\n",
    "    plt.xlabel(\"epoch\")\n",
    "    plt.legend([\"train\", \"validation\"], loc=\"upper left\")\n",
    "    plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c4fec364",
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_hist(hist)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fddfb0a7",
   "metadata": {},
   "outputs": [],
   "source": [
    "test_list = get_path('./test','jpg')\n",
    "id_load = lambda x : int(x.split('/')[-1].split('.')[0])\n",
    "id_list = list(map(id_load,test_list))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "37793d7e",
   "metadata": {},
   "outputs": [],
   "source": [
    "ds_test = tf.data.Dataset.from_tensor_slices((test_list,id_list))\n",
    "\n",
    "def test(image,id):\n",
    "    return load_and_preprocess_image(image),id\n",
    "\n",
    "ds_test = ds_test.map(test)\n",
    "dsb_test = ds_test.batch(batch_size=100, drop_remainder=True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3171db44",
   "metadata": {},
   "outputs": [],
   "source": [
    "submission = {'id':[],'label':[]}\n",
    "dog_prediction = lambda x:x[1]\n",
    "\n",
    "for batch in dsb_test:\n",
    "    results = new_model.predict(batch[0])\n",
    "    id = batch[1].numpy()\n",
    "    \n",
    "    submission['id'].extend(id)\n",
    "    submission['label'].extend(map(dog_prediction,results))\n",
    "    \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d5af71b6",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "submission_df=pd.DataFrame(submission)\n",
    "submission_df.to_csv('submission.csv',index=False)\n"
   ]
  }
 ],
 "metadata": {},
 "nbformat": 4,
 "nbformat_minor": 5
}

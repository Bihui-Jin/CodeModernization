{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "68934df2",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from pathlib import Path"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b68d147a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# This Python 3 environment comes with many helpful analytics libraries installed\n",
    "# It is defined by the kaggle/python docker image: https://github.com/kaggle/docker-python\n",
    "# For example, here's several helpful packages to load in \n",
    "\n",
    "import numpy as np # linear algebra\n",
    "import pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib.image as Image\n",
    "# Input data files are available in the \"../input/\" directory.\n",
    "# For example, running this (by clicking run or pressing Shift+Enter) will list the files in the input directory\n",
    "\n",
    "import os\n",
    "print(os.listdir(\"../input\"))\n",
    "from sklearn.model_selection import train_test_split\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "import torchvision.transforms as transforms\n",
    "\n",
    "# Any results you write to the current directory are saved as output.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "98ac20cc",
   "metadata": {},
   "outputs": [],
   "source": [
    "data_dir = \"../input\"\n",
    "train_dir = data_dir + \"/train/train\"\n",
    "test_dir = data_dir + \"/test/test\"\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4c16c4ed",
   "metadata": {},
   "outputs": [],
   "source": [
    "labels = pd.read_csv(data_dir + \"/train.csv\")\n",
    "labels.head()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "25c1eb36",
   "metadata": {},
   "outputs": [],
   "source": [
    "balance = labels['has_cactus'].value_counts()\n",
    "balance\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "44c6c250",
   "metadata": {},
   "outputs": [],
   "source": [
    "train, valid = train_test_split(labels, stratify=labels.has_cactus, test_size=0.2)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "12fcb96f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# define hyper-params\n",
    "num_epochs = 25\n",
    "num_classes = 2\n",
    "batch_size = 128\n",
    "learning_rate = 0.002\n",
    "device = torch.device('cuda:0' if torch.cuda.is_available() else 'cpu')\n",
    "device\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9f76143e",
   "metadata": {},
   "outputs": [],
   "source": [
    "class cactData(Dataset):\n",
    "    def __init__(self, split_data, data_root = './', transform=None):\n",
    "        super().__init__()\n",
    "        self.df = split_data.values\n",
    "        self.data_root = data_root\n",
    "        self.transform = transform\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.df)\n",
    "    \n",
    "    def __getitem__(self, index):\n",
    "        img_name,label = self.df[index]\n",
    "        img_path = os.path.join(self.data_root, img_name)\n",
    "        image = Image.imread(img_path)\n",
    "        if self.transform is not None:\n",
    "            image = self.transform(image)\n",
    "        return image, label\n",
    "    \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f2820eab",
   "metadata": {},
   "outputs": [],
   "source": [
    "mean = [0.5, 0.5, 0.5]\n",
    "std = [0.5, 0.5, 0.5]\n",
    "\n",
    "train_transf = transforms.Compose([transforms.ToPILImage(),\n",
    "#                                     transforms.Normalize(mean, std),\n",
    "#                                   transforms.RandomCrop(20),\n",
    "                                   transforms.ToTensor()\n",
    "                                  ])\n",
    "\n",
    "valid_transf = transforms.Compose([transforms.ToPILImage(),\n",
    "                                  transforms.ToTensor()])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "18ae81a1",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_data = cactData(train, train_dir, train_transf)\n",
    "valid_data = cactData(valid, train_dir, valid_transf)\n",
    "\n",
    "train_loader = DataLoader(dataset=train_data, batch_size=batch_size, shuffle=True, num_workers=0)\n",
    "\n",
    "valid_loader = DataLoader(dataset=valid_data, batch_size=batch_size//2, shuffle=False, num_workers=0)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "533f2bef",
   "metadata": {},
   "outputs": [],
   "source": [
    "### image dimension for each layer = (width - kernel_size + 2 * padding)/stride  + 1\n",
    "class CactCNN(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(CactCNN, self).__init__()\n",
    "        self.conv1 = nn.Sequential(\n",
    "            nn.Conv2d(3, 32, 4, 2, 0),\n",
    "            nn.BatchNorm2d(32),\n",
    "            nn.ReLU()\n",
    "        )\n",
    "        # 1 + (32 - 4 + 0)/2 = 15\n",
    "        # 32 * 15 * 15\n",
    "        self.conv2 = nn.Sequential(\n",
    "            nn.Conv2d(32, 64, 3, 2, 0),\n",
    "            nn.BatchNorm2d(64),\n",
    "            nn.ReLU()\n",
    "        )\n",
    "        # 1 + (15 - 3 + 0)/2 = 7\n",
    "        # 64 * 7 * 7\n",
    "        self.conv3 = nn.Sequential(\n",
    "            nn.Conv2d(64, 128, 3, 2, 0),\n",
    "            nn.BatchNorm2d(128),\n",
    "            nn.ReLU()\n",
    "        )\n",
    "        # 1 + (7 - 3 + 0)/2 = 3\n",
    "        # 128 * 3 * 3\n",
    "        self.conv4 = nn.Sequential(\n",
    "            nn.Conv2d(128, 256, 3, 2, 0),\n",
    "            nn.BatchNorm2d(256),\n",
    "            nn.ReLU()\n",
    "        )\n",
    "        #  1 + (3 - 3 + 0)/2 = 1\n",
    "        # 256 * 1 * 1\n",
    "        \n",
    "        self.fc = nn.Sequential(\n",
    "            nn.Linear(256*1*1, 1024),\n",
    "            nn.ReLU(),\n",
    "            nn.Dropout(p=0.2),\n",
    "            nn.Linear(1024,2)\n",
    "        )\n",
    "    def forward(self, x):\n",
    "        x = self.conv1(x)\n",
    "\n",
    "        x = self.conv2(x)\n",
    "\n",
    "        x = self.conv3(x)\n",
    "\n",
    "        x = self.conv4(x)\n",
    "\n",
    "        x = x.view(x.shape[0],-1)\n",
    "        x = self.fc(x)\n",
    "        return x\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7252193d",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = CactCNN().to(device)\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "optimizer = torch.optim.Adam(model.parameters(), lr=learning_rate)\n",
    "print(device)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "585aa177",
   "metadata": {},
   "outputs": [],
   "source": [
    "for epoch in range(num_epochs):\n",
    "    for i, (images, labels) in enumerate(train_loader):\n",
    "        images = images.to(device)\n",
    "        labels = labels.to(device)\n",
    "#         print(images[0].shape)\n",
    "        \n",
    "        out = model(images)\n",
    "        loss = criterion(out, labels)\n",
    "        \n",
    "        optimizer.zero_grad()\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "    print('Epoch: {}/{}, Loss: {}'.format(epoch+1, num_epochs, loss.item()))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9f5ebeb9",
   "metadata": {},
   "outputs": [],
   "source": [
    "model.eval()\n",
    "with torch.no_grad():\n",
    "    correct = 0\n",
    "    total = 0\n",
    "    for images, labels in valid_loader:\n",
    "        images = images.to(device)\n",
    "        labels = labels.to(device)\n",
    "        outputs = model(images)\n",
    "        _, predicted = torch.max(outputs.data, 1)\n",
    "        total += labels.size(0)\n",
    "        correct += (predicted == labels).sum().item()\n",
    "    print('Test Accuracy: {} %'.format(100 * correct / total))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6935856a",
   "metadata": {},
   "outputs": [],
   "source": [
    "submit = pd.read_csv(data_dir + '/sample_submission.csv')\n",
    "test_data = cactData(split_data = submit, data_root = test_dir, transform = valid_transf)\n",
    "test_loader = DataLoader(dataset = test_data, batch_size=32, shuffle=False, num_workers=0)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5ca14c8a",
   "metadata": {},
   "outputs": [],
   "source": [
    "model.eval()\n",
    "predict = []\n",
    "for batch_i, (data, target) in enumerate(test_loader):\n",
    "    data, target = data.to(device), target.to(device)\n",
    "    output = model(data)\n",
    "\n",
    "    pr = output[:,1].detach().cpu().numpy()\n",
    "    for i in pr:\n",
    "        predict.append(i)\n",
    "\n",
    "submit['has_cactus'] = predict\n",
    "submit.to_csv('submission.csv', index=False)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0f79d274",
   "metadata": {},
   "outputs": [],
   "source": [
    " \n"
   ]
  }
 ],
 "metadata": {},
 "nbformat": 4,
 "nbformat_minor": 5
}

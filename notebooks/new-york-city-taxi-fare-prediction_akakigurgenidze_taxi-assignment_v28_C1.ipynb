{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7507e80e",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from pathlib import Path"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dcbd6294",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.metrics import mean_squared_error\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Dense, Dropout\n",
    "\n",
    "# Load the data\n",
    "train_df =  pd.read_csv('/kaggle/input/new-york-city-taxi-fare-prediction/train.csv', nrows = 10_000_000)\n",
    "test_df =  pd.read_csv('/kaggle/input/new-york-city-taxi-fare-prediction/test.csv')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0c1f4fd3",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_df.head()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "55b41333",
   "metadata": {},
   "outputs": [],
   "source": [
    "test_df.head()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "06cd8c7e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# check datatypes\n",
    "train_df.dtypes\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d3c5eb23",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_df.describe()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "89e57555",
   "metadata": {},
   "outputs": [],
   "source": [
    "num_rows = len(train_df)\n",
    "train_df = train_df[(train_df['fare_amount'] > 0)]\n",
    "print(f'Drop {num_rows - len(train_df)} rows')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0db964c8",
   "metadata": {},
   "outputs": [],
   "source": [
    "def change_outliers_by_range(df, column_name, min_range, max_range):\n",
    "    before_len = df.shape[0]\n",
    "    mask = (df[column_name].between(min_range,max_range))\n",
    "    selected_rows = df[mask]\n",
    "    changed_rows = before_len - selected_rows.shape[0]\n",
    "    \n",
    "    dtype_of_column = df[column_name].dtype\n",
    "    mean_of_column = selected_rows[column_name].mean()\n",
    "    if dtype_of_column == np.int64:\n",
    "        mean_of_column = round(mean_of_column)\n",
    "    \n",
    "    df.loc[~mask, column_name] = mean_of_column\n",
    "    return changed_rows\n",
    "    \n",
    "\n",
    "def change_outliers(df):\n",
    "    print(\"Change\", change_outliers_by_range(df, 'pickup_latitude', 40.5, 41.0), \"rows by pickup lat\")\n",
    "    print(\"Change\", change_outliers_by_range(df, 'dropoff_latitude', 40.5, 41.0), \"rows by dropoff lat\")\n",
    "    print(\"Change\", change_outliers_by_range(df, 'pickup_longitude', -74.3, -73.6), \"rows by pickup long\")\n",
    "    print(\"Change\", change_outliers_by_range(df, 'dropoff_longitude', -74.3, -73.6), \"rows by dropoff long\")\n",
    "    print(\"Change\", change_outliers_by_range(df, 'passenger_count', 1, 8), \"rows by passenger cnt\")\n",
    "    \n",
    "\n",
    "print(\"Training data outliers: \")\n",
    "change_outliers(train_df)\n",
    "print(\"\\nTest data outliers: \")\n",
    "change_outliers(test_df)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2fbf563c",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_df.describe()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4add5fe4",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_df.isnull().sum()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fc23892d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Data preprocessing\n",
    "def preprocess_data(df):\n",
    "    airport_lat_long = (40.644600, -73.779700)\n",
    "    la_guardia_airport_lat_long = (40.7733, -73.8718)\n",
    "    near_airport = (((df[\"pickup_latitude\"] <= airport_lat_long[0] + 0.005) & \n",
    "                (df[\"pickup_latitude\"] >= airport_lat_long[0] - 0.005) & \n",
    "                (df[\"pickup_longitude\"] <= airport_lat_long[1] + 0.005) & \n",
    "                (df[\"pickup_longitude\"] >= airport_lat_long[1] - 0.005)) |\n",
    "                \n",
    "                ((df[\"pickup_latitude\"] <= la_guardia_airport_lat_long[0] + 0.002) & \n",
    "                (df[\"pickup_latitude\"] >= la_guardia_airport_lat_long[0] - 0.003) & \n",
    "                (df[\"pickup_longitude\"] <= la_guardia_airport_lat_long[1] + 0.005) & \n",
    "                (df[\"pickup_longitude\"] >= la_guardia_airport_lat_long[1] - 0.005))).astype(int)\n",
    "\n",
    "    df['near_airport'] = near_airport\n",
    "    \n",
    "    df['manhattan_distance'] = (abs(df['pickup_longitude'] - df['dropoff_longitude']) +\n",
    "                                 abs(df['pickup_latitude'] - df['dropoff_latitude']))\n",
    "    \n",
    "    df['pickup_datetime'] = pd.to_datetime(df['pickup_datetime'])\n",
    "    df['pickup_year'] = df['pickup_datetime'].dt.year\n",
    "    df['pickup_month'] = df['pickup_datetime'].dt.month\n",
    "    df['pickup_hour'] = df['pickup_datetime'].dt.hour\n",
    "    df['pickup_day'] = df['pickup_datetime'].dt.dayofweek\n",
    "    is_weekend = ((df[\"pickup_day\"] >=5) & \n",
    "                    (df[\"pickup_day\"] <=6)).astype(int)\n",
    "    df['is_weekend'] = is_weekend\n",
    "    \n",
    "    is_holiday = (\n",
    "        ((df['pickup_month'] == 12) & (df['pickup_datetime'].dt.day == 25)) |  \n",
    "        ((df['pickup_month'] == 12) & (df['pickup_datetime'].dt.day == 26)) | \n",
    "        ((df['pickup_month'] == 12) & (df['pickup_datetime'].dt.day == 31)) |  \n",
    "        ((df['pickup_month'] == 1) & (df['pickup_datetime'].dt.day == 1)) | \n",
    "        ((df['pickup_month'] == 7) & (df['pickup_datetime'].dt.day == 4))\n",
    "    ).astype(int)\n",
    "\n",
    "    df['is_holiday'] = is_holiday\n",
    "    \n",
    "\n",
    "preprocess_data(train_df)\n",
    "preprocess_data(test_df)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0f671718",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_df.head()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "04bcbcf9",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_df[\"near_airport\"].sum()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c0fd686d",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_df[\"is_holiday\"].sum()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0e61d25c",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_df[\"is_weekend\"].sum()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "02c0e2c2",
   "metadata": {},
   "outputs": [],
   "source": [
    "grouped = train_df.groupby('pickup_hour')['fare_amount'].mean().reset_index()\n",
    "\n",
    "plt.figure(figsize=(12, 6))\n",
    "plt.bar(grouped['pickup_hour'], grouped['fare_amount'])\n",
    "plt.title('Average Fare Amount by Hour of Day')\n",
    "plt.xlabel('Hour of Day')\n",
    "plt.ylabel('Average Fare Amount')\n",
    "plt.xticks(grouped['pickup_hour'])\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "675c92a2",
   "metadata": {},
   "outputs": [],
   "source": [
    "grouped = train_df.groupby('near_airport')['fare_amount'].mean().reset_index()\n",
    "\n",
    "plt.figure(figsize=(2, 5))\n",
    "plt.bar(grouped['near_airport'], grouped['fare_amount'])\n",
    "plt.title('Average Fare Amount by Near Airport')\n",
    "plt.xlabel('Is Near of Airport')\n",
    "plt.ylabel('Average Fare Amount')\n",
    "plt.xticks(grouped['near_airport'])\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2fd0bb13",
   "metadata": {},
   "outputs": [],
   "source": [
    "grouped = train_df.groupby('pickup_year')['fare_amount'].mean().reset_index()\n",
    "\n",
    "plt.figure(figsize=(6, 6))\n",
    "plt.bar(grouped['pickup_year'], grouped['fare_amount'])\n",
    "plt.title('Average Fare Amount by Year')\n",
    "plt.xlabel('Year')\n",
    "plt.ylabel('Average Fare Amount')\n",
    "plt.xticks(grouped['pickup_year'])\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dd2afa75",
   "metadata": {},
   "outputs": [],
   "source": [
    "grouped = train_df.groupby('pickup_month')['fare_amount'].mean().reset_index()\n",
    "\n",
    "plt.figure(figsize=(6, 6))\n",
    "plt.bar(grouped['pickup_month'], grouped['fare_amount'])\n",
    "plt.title('Average Fare Amount by Month')\n",
    "plt.xlabel('Month')\n",
    "plt.ylabel('Average Fare Amount')\n",
    "plt.xticks(grouped['pickup_month'])\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "eff3f193",
   "metadata": {},
   "outputs": [],
   "source": [
    "grouped = train_df.groupby('passenger_count')['fare_amount'].mean().reset_index()\n",
    "\n",
    "plt.figure(figsize=(6, 6))\n",
    "plt.bar(grouped['passenger_count'], grouped['fare_amount'])\n",
    "plt.title('Average Fare Amount by Passenger Count')\n",
    "plt.xlabel('Passenger Count')\n",
    "plt.ylabel('Average Fare Amount')\n",
    "plt.xticks(grouped['passenger_count'])\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "95b6124f",
   "metadata": {},
   "outputs": [],
   "source": [
    "grouped = train_df.groupby('pickup_day')['fare_amount'].mean().reset_index()\n",
    "\n",
    "plt.figure(figsize=(5, 4))\n",
    "plt.bar(grouped['pickup_day'], grouped['fare_amount'])\n",
    "plt.title('Average Fare Amount by Day')\n",
    "plt.xlabel('Day')\n",
    "plt.ylabel('Average Fare Amount')\n",
    "plt.xticks(grouped['pickup_day'])\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "836629d8",
   "metadata": {},
   "outputs": [],
   "source": [
    "grouped = train_df.groupby('is_holiday')['fare_amount'].mean().reset_index()\n",
    "\n",
    "plt.figure(figsize=(2, 4))\n",
    "plt.bar(grouped['is_holiday'], grouped['fare_amount'])\n",
    "plt.title('Average Fare Amount by Holiday')\n",
    "plt.xlabel('Is Holiday')\n",
    "plt.ylabel('Average Fare Amount')\n",
    "plt.xticks(grouped['is_holiday'])\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "10b467e5",
   "metadata": {},
   "outputs": [],
   "source": [
    "features = ['pickup_longitude', 'pickup_latitude', 'dropoff_longitude', 'dropoff_latitude', 'near_airport', 'manhattan_distance', 'pickup_year', 'pickup_month', 'pickup_hour', 'passenger_count']\n",
    "X = train_df[features].values\n",
    "y = train_df['fare_amount'].values\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e1c89f8a",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_test = test_df[features].values\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "66c24e05",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Feature scaling\n",
    "# scaler = StandardScaler()\n",
    "# X = scaler.fit_transform(X)\n",
    "# X_test = scaler.transform(X_test)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fb61979a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Split data into train and validation sets\n",
    "X_train, X_val, y_train, y_val = train_test_split(X, y, test_size=0.2, random_state=69)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "66d7fe4e",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(X.shape)\n",
    "print(y.shape)\n",
    "\n",
    "print(X_train.shape)\n",
    "print(y_train.shape)\n",
    "\n",
    "print(X_val.shape)\n",
    "print(y_val.shape)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7589d6ff",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.linear_model import LinearRegression\n",
    "from sklearn.metrics import mean_squared_error\n",
    "\n",
    "# Train Linear Regression model\n",
    "lr_model = LinearRegression()\n",
    "lr_model.fit(X_train, y_train)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e37d2416",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Evaluate on validation set\n",
    "validation_predictions_lr = lr_model.predict(X_val)\n",
    "validation_rmse_lr = np.sqrt(mean_squared_error(y_val, validation_predictions_lr))\n",
    "print(\"Validation RMSE (Linear Regression):\", validation_rmse_lr)\n",
    "\n",
    "# Evaluate on full training set\n",
    "train_predictions_lr = lr_model.predict(X)\n",
    "train_rmse_lr = np.sqrt(mean_squared_error(y, train_predictions_lr))\n",
    "print(\"Training RMSE (Linear Regression):\", train_rmse_lr)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c335af3e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Make predictions on the test set\n",
    "test_predictions_lr = lr_model.predict(X_test)\n",
    "\n",
    "# Save predictions to a CSV file\n",
    "submission_df_lr =  pd.DataFrame(\n",
    "    {'key': test_df.key, 'fare_amount': test_predictions_lr},\n",
    "    columns = ['key', 'fare_amount'])\n",
    "submission_df_lr.to_csv('lr_submission.csv', index=False)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3344071e",
   "metadata": {},
   "outputs": [],
   "source": [
    "import xgboost as xgb\n",
    "\n",
    "# Define XGBoost model parameters\n",
    "xgb_params = {\n",
    "    'objective': 'reg:squarederror',  # Regression task\n",
    "    'eval_metric': 'rmse',  # Evaluation metric (Root Mean Squared Error)\n",
    "    'max_depth': 20,  # Maximum depth of the decision trees\n",
    "    'subsample': 0.85,  # Subsample ratio of the training instances\n",
    "    'colsample_bytree': 0.8,  # Subsample ratio of columns when constructing each tree\n",
    "    'eta': 0.04,  # Learning rate\n",
    "    'min_child_weight': 3,  # Minimum sum of instance weight needed in a child\n",
    "    'gamma': 0.1,  # Minimum loss reduction required to make a further partition\n",
    "    'seed': 42,  # Random seed for reproducibility\n",
    "    'tree_method': 'hist',  # Use the histogram-based algorithm for better performance\n",
    "    'nthread': -1,  # Use all available CPU cores\n",
    "}\n",
    "\n",
    "# Convert data to DMatrix format for XGBoost\n",
    "dtrain = xgb.DMatrix(X_train, label=y_train)\n",
    "dval = xgb.DMatrix(X_val)\n",
    "dtest = xgb.DMatrix(X_test)\n",
    "dallTrain = xgb.DMatrix(X)\n",
    "\n",
    "# Train XGBoost model\n",
    "xgb_model = xgb.train(xgb_params, dtrain, num_boost_round=80)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8b3a73e4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Evaluate on validation set\n",
    "validation_predictions_xgb = xgb_model.predict(dval)\n",
    "validation_rmse_xgb = np.sqrt(mean_squared_error(y_val, validation_predictions_xgb))\n",
    "print(\"Validation RMSE (XGBoost):\", validation_rmse_xgb)\n",
    "\n",
    "# Train on validation set\n",
    "train_predictions_xgb = xgb_model.predict(dallTrain)\n",
    "train_rmse_xgb = np.sqrt(mean_squared_error(y, train_predictions_xgb))\n",
    "print(\"Train RMSE (XGBoost):\", train_rmse_xgb)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "57c43535",
   "metadata": {},
   "outputs": [],
   "source": [
    "# # Define the model\n",
    "# model = Sequential([\n",
    "#     Dense(128, activation='relu', input_shape=(X_train.shape[1],)),\n",
    "#     Dropout(0.2),\n",
    "#     Dense(64, activation='relu'),\n",
    "#     Dropout(0.2),\n",
    "#     Dense(1, activation='linear')\n",
    "# ])\n",
    "\n",
    "# # Compile the model\n",
    "# model.compile(optimizer='adam', loss='mean_squared_error')\n",
    "\n",
    "# # Train the model\n",
    "# model.fit(X_train, y_train, epochs=10, batch_size=128, validation_data=(X_val, y_val))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9e6a8b97",
   "metadata": {},
   "outputs": [],
   "source": [
    "# # Evaluate the model\n",
    "# val_predictions = model.predict(X_val)\n",
    "# val_rmse = np.sqrt(mean_squared_error(y_val, val_predictions))\n",
    "# print(\"Validation RMSE: (Neural Network)\", val_rmse)\n",
    "\n",
    "# # Evaluate the model\n",
    "# train_predictions = model.predict(X)\n",
    "# train_rmse = np.sqrt(mean_squared_error(y, train_predictions))\n",
    "# print(\"Train RMSE: (Neural Network)\", train_rmse)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f042e811",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Make predictions on the test set\n",
    "test_predictions_xgb = xgb_model.predict(dtest)\n",
    "\n",
    "# Save predictions to a CSV file\n",
    "submission_df_xgb =  pd.DataFrame(\n",
    "    {'key': test_df.key, 'fare_amount': test_predictions_xgb},\n",
    "    columns = ['key', 'fare_amount'])\n",
    "submission_df_xgb.to_csv('submission.csv', index=False)\n"
   ]
  }
 ],
 "metadata": {},
 "nbformat": 4,
 "nbformat_minor": 5
}

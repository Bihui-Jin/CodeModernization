{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "e640d02e",
      "metadata": {},
      "outputs": [],
      "source": [
        "import pandas as pd\n",
        "from pathlib import Path"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "19ae01e4",
      "metadata": {},
      "outputs": [],
      "source": [
        "import numpy as np\n",
        "import pandas as pd\n",
        "import matplotlib.pyplot as plt\n",
        "import zipfile\n",
        "import os\n",
        "import cv2\n",
        "\n",
        "from sklearn.model_selection import train_test_split\n",
        "\n",
        "from tensorflow.keras.models import Sequential\n",
        "from tensorflow.keras.layers import Conv2D, MaxPooling2D, UpSampling2D, Dropout, BatchNormalization, Input\n",
        "from tensorflow.keras.callbacks import EarlyStopping\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "0f4df8de",
      "metadata": {},
      "outputs": [],
      "source": [
        "# path to zipped & working directories\n",
        "path_zip = '/kaggle/input/denoising-dirty-documents/'\n",
        "path = '/kaggle/working/'\n",
        "\n",
        "# unzip files first to working directory\n",
        "# We could use also unzipped data source, but why not to learn something new?\n",
        "with zipfile.ZipFile(path_zip + 'train.zip', 'r') as zip_ref:\n",
        "    zip_ref.extractall(path)\n",
        "\n",
        "with zipfile.ZipFile(path_zip + 'test.zip', 'r') as zip_ref:\n",
        "    zip_ref.extractall(path)  \n",
        "    \n",
        "with zipfile.ZipFile(path_zip + 'train_cleaned.zip', 'r') as zip_ref:\n",
        "    zip_ref.extractall(path)  \n",
        "    \n",
        "with zipfile.ZipFile(path_zip + 'sampleSubmission.csv.zip', 'r') as zip_ref:\n",
        "    zip_ref.extractall(path)  \n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "d6d6eceb",
      "metadata": {},
      "outputs": [],
      "source": [
        "# store image names in list for later use\n",
        "train_img = sorted(os.listdir(path + '/train'))\n",
        "train_cleaned_img = sorted(os.listdir(path + '/train_cleaned'))\n",
        "test_img = sorted(os.listdir(path + '/test'))\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "f30d0cb3",
      "metadata": {},
      "outputs": [],
      "source": [
        "# prepare function\n",
        "def process_image(path):\n",
        "    img = cv2.imread(path)\n",
        "    img = np.asarray(img, dtype=\"float32\")\n",
        "    img = cv2.resize(img, (540, 420))\n",
        "    img = cv2.cvtColor(img, cv2.COLOR_BGR2GRAY)\n",
        "    img = img/255.0\n",
        "    img = np.reshape(img, (420, 540, 1))\n",
        "    \n",
        "    return img\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "14106d1d",
      "metadata": {},
      "outputs": [],
      "source": [
        "# preprocess images\n",
        "train = []\n",
        "train_cleaned = []\n",
        "test = []\n",
        "\n",
        "for f in sorted(os.listdir(path + 'train/')):\n",
        "    train.append(process_image(path + 'train/' + f))\n",
        "\n",
        "for f in sorted(os.listdir(path + 'train_cleaned/')):\n",
        "    train_cleaned.append(process_image(path + 'train_cleaned/' + f))\n",
        "   \n",
        "for f in sorted(os.listdir(path + 'test/')):\n",
        "    test.append(process_image(path + 'test/' + f))\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "3643468c",
      "metadata": {},
      "outputs": [],
      "source": [
        "plt.figure(figsize=(15,25))\n",
        "for i in range(0,8,2):\n",
        "    plt.subplot(4,2,i+1)\n",
        "    plt.xticks([])\n",
        "    plt.yticks([])\n",
        "    plt.imshow(train[i][:,:,0], cmap='gray')\n",
        "    plt.title('Noise image: {}'.format(train_img[i]))\n",
        "    \n",
        "    plt.subplot(4,2,i+2)\n",
        "    plt.xticks([])\n",
        "    plt.yticks([])\n",
        "    plt.imshow(train_cleaned[i][:,:,0], cmap='gray')\n",
        "    plt.title('Denoised image: {}'.format(train_img[i]))\n",
        "\n",
        "plt.show()\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "fb193782",
      "metadata": {},
      "outputs": [],
      "source": [
        "# convert list to numpy array\n",
        "X_train = np.asarray(train)\n",
        "y_train = np.asarray(train_cleaned)\n",
        "X_test = np.asarray(test)\n",
        "\n",
        "X_train, X_val, y_train, y_val = train_test_split(X_train, y_train, test_size=0.15)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "80c0dd65",
      "metadata": {},
      "outputs": [],
      "source": [
        "conv_autoencoder = Sequential()\n",
        "# Encoder\n",
        "conv_autoencoder.add(Conv2D(filters=32, kernel_size=(3,3), input_shape=(420,540,1), activation='relu', padding='same'))\n",
        "conv_autoencoder.add(Conv2D(filters=16, kernel_size=(3,3), activation='relu', padding='same'))\n",
        "conv_autoencoder.add(MaxPooling2D((2, 2), padding='same'))\n",
        "conv_autoencoder.add(Conv2D(filters= 8, kernel_size=(3,3), activation='relu', padding='same'))\n",
        "# Decoder\n",
        "conv_autoencoder.add(Conv2D(filters= 8, kernel_size=(3,3), activation='relu', padding='same'))\n",
        "conv_autoencoder.add(Conv2D(filters=16, kernel_size=(3,3), activation='relu', padding='same'))\n",
        "conv_autoencoder.add(UpSampling2D((2, 2)))\n",
        "conv_autoencoder.add(Conv2D(filters=32, kernel_size=(3,3), activation='relu', padding='same'))\n",
        "# Output\n",
        "conv_autoencoder.add(Conv2D(filters=1, kernel_size=(3,3), activation='sigmoid', padding='same'))\n",
        "\n",
        "conv_autoencoder.summary()\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "a68c5c4e",
      "metadata": {},
      "outputs": [],
      "source": [
        "conv_autoencoder.compile(optimizer='adam', loss='mean_squared_error', metrics=['mse'])\n",
        "\n",
        "early_stop = EarlyStopping(monitor='loss', patience=10, restore_best_weights=True)\n",
        "conv_autoencoder.fit(X_train, y_train, validation_data = (X_val, y_val), epochs=500, batch_size=16, callbacks= [early_stop], verbose=0)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "50e2ebc2",
      "metadata": {},
      "outputs": [],
      "source": [
        "y_pred = conv_autoencoder.predict(X_test, batch_size=16)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "ebb2af46",
      "metadata": {},
      "outputs": [],
      "source": [
        "plt.figure(figsize=(15,25))\n",
        "for i in range(0,8,2):\n",
        "    plt.subplot(4,2,i+1)\n",
        "    plt.xticks([])\n",
        "    plt.yticks([])\n",
        "    plt.imshow(X_test[i][:,:,0], cmap='gray')\n",
        "    plt.title('Noisy image: {}'.format(test_img[i]))\n",
        "    \n",
        "    plt.subplot(4,2,i+2)\n",
        "    plt.xticks([])\n",
        "    plt.yticks([])\n",
        "    plt.imshow(y_pred[i][:,:,0], cmap='gray')\n",
        "    plt.title('Denoised by autoencoder: {}'.format(test_img[i]))\n",
        "\n",
        "plt.show()\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "8389bcf9",
      "metadata": {},
      "outputs": [],
      "source": [
        "# it will take a while!\n",
        "ids = []\n",
        "vals = []\n",
        "for i, f in enumerate(test_img):\n",
        "    file = path + 'test/' + f\n",
        "    imgid = int(f[:-4])\n",
        "    img = cv2.imread(file, 0)\n",
        "    img_shape = img.shape\n",
        "    # print('Processing image: {} \\tinto size: {}'.format(f, img_shape))    # uncomment to see progress\n",
        "    preds_reshaped = cv2.resize(y_pred[i], (img_shape[1], img_shape[0]))\n",
        "\n",
        "    for r in range(img_shape[0]):\n",
        "        for c in range(img_shape[1]):\n",
        "            ids.append(str(imgid)+'_'+str(r + 1)+'_'+str(c + 1))\n",
        "            vals.append(preds_reshaped[r, c])\n",
        "\n",
        "submission = pd.DataFrame({'id': ids, 'value': vals})\n",
        "submission.to_csv('submission.csv',index = False)\n",
        "\n",
        "print('Results saved to submission.csv!')\n",
        "\n",
        "# quick check if length of IDs is OK\n",
        "# we should get there number 14230080\n",
        "print('Length of IDs: {}'.format(len(ids)))\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "133d2f04",
      "metadata": {},
      "outputs": [],
      "source": [
        "# check first few rows of submission\n",
        "my_submission = pd.read_csv('submission.csv')\n",
        "my_submission.head(5)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "332bf56b",
      "metadata": {},
      "outputs": [],
      "source": [
        " \n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "2c4955d5",
      "metadata": {},
      "outputs": [],
      "source": [
        " \n"
      ]
    }
  ],
  "metadata": {},
  "nbformat": 4,
  "nbformat_minor": 5
}
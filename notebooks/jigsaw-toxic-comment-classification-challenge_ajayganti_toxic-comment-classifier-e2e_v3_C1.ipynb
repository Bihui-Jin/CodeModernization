{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8760a8a8",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from pathlib import Path"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "56551814",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras.models import Model,Sequential\n",
    "from tensorflow.keras.layers import Dense,Embedding,Input,Activation,LSTM,GlobalMaxPool1D,Dropout\n",
    "from tensorflow.keras.preprocessing.text import Tokenizer\n",
    "from tensorflow.keras.preprocessing.sequence import pad_sequences\n",
    "from tensorflow.keras import initializers, optimizers, layers\n",
    "from sklearn.metrics import roc_auc_score\n",
    "import re\n",
    "import warnings\n",
    "warnings.simplefilter(action=\"ignore\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2f3e8b0e",
   "metadata": {},
   "outputs": [],
   "source": [
    "!ls /kaggle/input/jigsaw-toxic-comment-classification-challenge/\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "918973bd",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_df = pd.read_csv('/kaggle/input/jigsaw-toxic-comment-classification-challenge/train.csv.zip')\n",
    "train_df.head()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "056faadb",
   "metadata": {},
   "outputs": [],
   "source": [
    "test_df = pd.read_csv('/kaggle/input/jigsaw-toxic-comment-classification-challenge/test.csv.zip')\n",
    "test_df.head()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "675f44a9",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_df['comment_text'][0]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ab64a72e",
   "metadata": {},
   "outputs": [],
   "source": [
    "pd.DataFrame(train_df[[\"toxic\", \"severe_toxic\", \"obscene\", \"threat\", \"insult\", \"identity_hate\"]].sum(),columns=['Count'])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a1ed4540",
   "metadata": {},
   "outputs": [],
   "source": [
    "temp = pd.DataFrame(train_df[[\"toxic\", \"severe_toxic\", \"obscene\", \"threat\", \"insult\", \"identity_hate\"]].sum(),columns=['Count'])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d77848b4",
   "metadata": {},
   "outputs": [],
   "source": [
    "sns.barplot(temp.index, temp['Count'])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0690fe5b",
   "metadata": {},
   "outputs": [],
   "source": [
    "from nltk import word_tokenize\n",
    "train_df['tokenized_text'] = train_df.apply(lambda row: word_tokenize(row['comment_text']), axis=1)\n",
    "lengths = [len(line) for line in train_df[\"tokenized_text\"]]\n",
    "train_df['comment_text'].iloc[np.argmax(lengths)]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "eaa1719b",
   "metadata": {},
   "outputs": [],
   "source": [
    "import plotly.express as px\n",
    "px.histogram(lengths)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "07e3386d",
   "metadata": {},
   "outputs": [],
   "source": [
    "from nltk.corpus import stopwords\n",
    "def process_text(data):\n",
    "    stop = stopwords.words('english')\n",
    "    data['processed_text'] = data.apply(lambda row: row['comment_text'].replace(\"\\n\",\" \"), axis=1) ## Remove new lines\n",
    "    data['processed_text'] = data.apply(lambda row: re.sub('http://\\S+|https://\\S+', 'urls',row['processed_text']).lower(), axis=1) # Remove URL's\n",
    "    data['processed_text'] = data.apply(lambda row: re.sub('[^A-Za-z ]+', '',row['processed_text']).lower(), axis=1) # Removes special characters, punctuations except alphabets\n",
    "    data['processed_text'] = data['processed_text'].apply(lambda x: ' '.join([word for word in x.split() if word not in (stop)])) # Removes Stop words\n",
    "    data['processed_text'] = data.apply(lambda row: re.sub('  +', ' ',row['processed_text']).strip(), axis=1) # Removes extra spaces in between the words\n",
    "    return data\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3aae2a8e",
   "metadata": {},
   "outputs": [],
   "source": [
    "train = process_text(train_df)\n",
    "test = process_text(test_df)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "63511bcf",
   "metadata": {},
   "outputs": [],
   "source": [
    "train[\"processed_text\"] = train.apply(lambda x: x[\"comment_text\"] if len(x[\"processed_text\"])==0 else x['processed_text'], axis=1)\n",
    "test[\"processed_text\"] = test.apply(lambda x: x[\"comment_text\"] if len(x[\"processed_text\"])==0 else x['processed_text'], axis=1)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1bcd0894",
   "metadata": {},
   "outputs": [],
   "source": [
    "num_words = 30000\n",
    "tokenizer = Tokenizer(num_words=30000)\n",
    "tokenizer.fit_on_texts(train['processed_text'])\n",
    "train_tokens = tokenizer.texts_to_sequences(train['processed_text'])\n",
    "test_tokens = tokenizer.texts_to_sequences(test['processed_text'])\n",
    "train_seq = pad_sequences(train_tokens, maxlen=300)\n",
    "test_seq = pad_sequences(test_tokens, maxlen=300)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "38fedd6e",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(train_seq.shape, test_seq.shape)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "680e30de",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_labels = train[[\"toxic\", \"severe_toxic\", \"obscene\", \"threat\", \"insult\", \"identity_hate\"]]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "714d2340",
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras.callbacks import ModelCheckpoint, EarlyStopping\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0941a817",
   "metadata": {},
   "outputs": [],
   "source": [
    "filepath = '/kaggle/working/best_model_weights-{epoch:02d}.hdf5'\n",
    "save_model_callback = ModelCheckpoint(filepath=filepath, monitor='val_auc', verbose=1,save_best_only=True, mode='max')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e7aca652",
   "metadata": {},
   "outputs": [],
   "source": [
    "earlystop = EarlyStopping(monitor='val_auc', min_delta = 0.1, patience = 2, verbose = 1)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4025e867",
   "metadata": {},
   "outputs": [],
   "source": [
    "tf.keras.backend.clear_session()\n",
    "input_layer = Input(shape = (300, ))\n",
    "x = Embedding(30000, 200)(input_layer)\n",
    "x = LSTM(60, return_sequences=True)(x)\n",
    "x = GlobalMaxPool1D()(x)\n",
    "x = Dropout(0.1)(x)\n",
    "x = Dense(50, activation=\"relu\")(x)\n",
    "x = Dropout(0.1)(x)\n",
    "output_layer = Dense(6, activation=\"sigmoid\")(x)\n",
    "model = Model(inputs=input_layer, outputs=output_layer)\n",
    "model.summary()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "62b49d44",
   "metadata": {},
   "outputs": [],
   "source": [
    "model.compile(loss='binary_crossentropy',optimizer='adam',metrics=['accuracy','AUC'])\n",
    "model.fit(train_seq, train_labels, batch_size=128, validation_split=0.2, epochs = 5, callbacks=[save_model_callback, earlystop])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0093894e",
   "metadata": {},
   "outputs": [],
   "source": [
    "sample_submission = pd.read_csv(\"/kaggle/input/jigsaw-toxic-comment-classification-challenge/sample_submission.csv.zip\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cec9bc66",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_test = pd.merge(test, sample_submission, on = \"id\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e6302055",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_test.head()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7dbb07f5",
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pred = model.predict(test_seq)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d85f46a5",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_test[[\"toxic\",\"severe_toxic\",\"obscene\",\"threat\",\"insult\",\"identity_hate\"]] = y_pred\n",
    "df_test.head()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a5b75c4a",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_test.drop([\"comment_text\", \"processed_text\"], axis = 1, inplace = True)\n",
    "df_test.to_csv(\"sample_submission.csv\", index = False)\n"
   ]
  }
 ],
 "metadata": {},
 "nbformat": 4,
 "nbformat_minor": 5
}

{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ea13e78a",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from pathlib import Path"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "82858c82",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "import os\n",
    "os.environ['TF_CPP_MIN_LOG_LEVEL']='2'\n",
    "\n",
    "import glob\n",
    "\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras.applications import EfficientNetB0\n",
    "from tensorflow.keras.models import Sequential\n",
    "import tensorflow.keras.layers as layers\n",
    "\n",
    "AUTOTUNE = tf.data.experimental.AUTOTUNE\n",
    "tf.get_logger().setLevel(\"ERROR\")\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "import matplotlib.pyplot as plt\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3a5bbcf7",
   "metadata": {},
   "outputs": [],
   "source": [
    "device_name = tf.test.gpu_device_name()\n",
    "print(tf.test.gpu_device_name())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "de82e7c4",
   "metadata": {},
   "outputs": [],
   "source": [
    "import zipfile\n",
    "with zipfile.ZipFile('/kaggle/input/dogs-vs-cats-redux-kernels-edition/train.zip') as zf:\n",
    "    zf.extractall()\n",
    "with zipfile.ZipFile('/kaggle/input/dogs-vs-cats-redux-kernels-edition/test.zip') as zf:\n",
    "    zf.extractall()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "505ce574",
   "metadata": {},
   "outputs": [],
   "source": [
    "import cv2\n",
    "\n",
    "training_data_X = []\n",
    "training_data_Y = []\n",
    "IMG_SIZE = 224\n",
    "DIR_PATH = '/kaggle/working/train'\n",
    "for img in os.listdir(DIR_PATH):\n",
    "    if 'dog.' == img[:4]:\n",
    "        category = 1\n",
    "    else:\n",
    "        category = 0\n",
    "        \n",
    "    training_data_X.append(DIR_PATH + \"/\" + img)\n",
    "    training_data_Y.append(category)\n",
    "\n",
    "print(len(training_data_X))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cc460a8b",
   "metadata": {},
   "outputs": [],
   "source": [
    "x_train, x_val, y_train, y_val = train_test_split(training_data_X, training_data_Y, test_size = 0.3, random_state=50)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "aef0eb0e",
   "metadata": {},
   "outputs": [],
   "source": [
    "def image_load(path, label):\n",
    "    image = tf.image.decode_jpeg(tf.io.read_file(path), channels=3)\n",
    "    image = tf.image.resize(image, [IMG_SIZE, IMG_SIZE])\n",
    "    return image, tf.one_hot(label, 2)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d63da466",
   "metadata": {},
   "outputs": [],
   "source": [
    "ds_train = tf.data.Dataset.from_tensor_slices((x_train, y_train))\n",
    "ds_val = tf.data.Dataset.from_tensor_slices((x_val, y_val))\n",
    "\n",
    "ds_train = ds_train.map(image_load)\n",
    "ds_val = ds_val.map(image_load)\n",
    "\n",
    "print('train dataset:',len(ds_train),'validation dataset:',len(ds_val))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c3e87516",
   "metadata": {},
   "outputs": [],
   "source": [
    "batch_size = 64\n",
    "\n",
    "ds_batch_train = ds_train.batch(batch_size=batch_size, drop_remainder=True)\n",
    "ds_batch_train = ds_batch_train.prefetch(tf.data.AUTOTUNE)\n",
    "ds_batch_val = ds_val.batch(batch_size=batch_size, drop_remainder=True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d90dee80",
   "metadata": {},
   "outputs": [],
   "source": [
    "img_augmentation = Sequential(\n",
    "    [\n",
    "        layers.RandomRotation(factor=0.15),\n",
    "        layers.RandomTranslation(height_factor=0.1, width_factor=0.1),\n",
    "        layers.RandomFlip(),\n",
    "        layers.RandomContrast(factor=0.1),\n",
    "    ],\n",
    "    name=\"img_augmentation\",\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bfd5bd4f",
   "metadata": {},
   "outputs": [],
   "source": [
    "def build_model(num_classes):\n",
    "    inputs = layers.Input(shape=(IMG_SIZE, IMG_SIZE, 3))\n",
    "    x = img_augmentation(inputs)\n",
    "    model = EfficientNetB0(include_top=False, input_tensor=x, weights=\"imagenet\")\n",
    "\n",
    "    # Freeze the pretrained weights\n",
    "    model.trainable = False\n",
    "\n",
    "    # Rebuild top\n",
    "    x = layers.GlobalAveragePooling2D(name=\"avg_pool\")(model.output)\n",
    "    x = layers.BatchNormalization()(x)\n",
    "\n",
    "    top_dropout_rate = 0.2\n",
    "    x = layers.Dropout(top_dropout_rate, name=\"top_dropout\")(x)\n",
    "    outputs = layers.Dense(num_classes, activation=\"softmax\", name=\"pred\")(x)\n",
    "\n",
    "    # Compile\n",
    "    model = tf.keras.Model(inputs, outputs, name=\"EfficientNet\")\n",
    "    optimizer = tf.keras.optimizers.Adam(learning_rate=1e-2)\n",
    "    model.compile(\n",
    "        optimizer=optimizer, loss=\"categorical_crossentropy\", metrics=[\"accuracy\"]\n",
    "    )\n",
    "    return model\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e5c61acf",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = build_model(num_classes=2)\n",
    "\n",
    "epochs = 10  \n",
    "history = model.fit(ds_batch_train, epochs=epochs, validation_data=ds_batch_val, verbose=1)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bfb1ce49",
   "metadata": {},
   "outputs": [],
   "source": [
    "history_dict = history.history\n",
    "\n",
    "loss_values = history_dict['loss']\n",
    "val_loss_values = history_dict['val_loss']\n",
    "\n",
    "epochs = range(1, len(loss_values)+1)\n",
    "\n",
    "line1 = plt.plot(epochs, val_loss_values, label ='Validation/Test Loss')\n",
    "line2 = plt.plot(epochs, loss_values, label='Training Loss')\n",
    "plt.setp(line1, linewidth = 2.0, marker='+', markersize=10.0)\n",
    "plt.setp(line2, linewidth=2.0, marker='4', markersize=10.0)\n",
    "plt.legend()\n",
    "plt.grid(True)\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3db38ed0",
   "metadata": {},
   "outputs": [],
   "source": [
    "history_dict = history.history\n",
    "\n",
    "plt.plot(history_dict[\"accuracy\"])\n",
    "plt.plot(history_dict[\"val_accuracy\"])\n",
    "plt.title(\"model accuracy\")\n",
    "plt.ylabel(\"accuracy\")\n",
    "plt.xlabel(\"epoch\")\n",
    "plt.legend([\"train\", \"validation\"], loc=\"upper left\")\n",
    "plt.grid(True)\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "902dc65b",
   "metadata": {},
   "outputs": [],
   "source": [
    "testing_data = []\n",
    "testing_id = []\n",
    "\n",
    "DIR_PATH = '/kaggle/working/test'\n",
    "for img in os.listdir(DIR_PATH):\n",
    "    testing_data.append(DIR_PATH + '/' + img)\n",
    "    testing_id.append(int(img.split('.')[0]))\n",
    "\n",
    "def test_image_load(path, id):\n",
    "    image = tf.image.decode_jpeg(tf.io.read_file(path), channels=3)\n",
    "    image = tf.image.resize(image, [IMG_SIZE, IMG_SIZE])\n",
    "    return image, id\n",
    "\n",
    "print(len(testing_data))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6ec2681e",
   "metadata": {},
   "outputs": [],
   "source": [
    "ds_test = tf.data.Dataset.from_tensor_slices((testing_data, testing_id))\n",
    "\n",
    "ds_test = ds_test.map(test_image_load)\n",
    "ds_batch_test = ds_test.batch(batch_size=100, drop_remainder=True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0f61e1b9",
   "metadata": {},
   "outputs": [],
   "source": [
    "from tqdm import tqdm\n",
    "submission = {'id':[],'label':[]}\n",
    "dog_prediction = lambda x:x[1]\n",
    "\n",
    "for batch in tqdm(ds_batch_test):\n",
    "    results = model.predict(batch[0])\n",
    "    id = batch[1].numpy()\n",
    "    \n",
    "    submission['id'].extend(id)\n",
    "    submission['label'].extend(map(dog_prediction,results))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "155b6adf",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "submission_df=pd.DataFrame(submission)\n",
    "submission_df.to_csv('my_submission.csv',index=False)\n"
   ]
  }
 ],
 "metadata": {},
 "nbformat": 4,
 "nbformat_minor": 5
}

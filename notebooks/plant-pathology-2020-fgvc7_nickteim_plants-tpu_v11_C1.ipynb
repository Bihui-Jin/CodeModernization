{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "19f052a0",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from pathlib import Path"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "999b7947",
   "metadata": {},
   "outputs": [],
   "source": [
    "# # This Python 3 environment comes with many helpful analytics libraries installed\n",
    "# # It is defined by the kaggle/python docker image: https://github.com/kaggle/docker-python\n",
    "# # For example, here's several helpful packages to load in \n",
    "\n",
    "# import numpy as np # linear algebra\n",
    "# import pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\n",
    "\n",
    "# # Input data files are available in the \"../input/\" directory.\n",
    "# # For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n",
    "\n",
    "# import os\n",
    "# for dirname, _, filenames in os.walk('/kaggle/input'):\n",
    "#     for filename in filenames:\n",
    "#         print(os.path.join(dirname, filename))\n",
    "\n",
    "# # Any results you write to the current directory are saved as output.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4a968dd9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# %reload_ext autoreload\n",
    "# %autoreload 2\n",
    "# %matplotlib inline\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "21de5c89",
   "metadata": {},
   "outputs": [],
   "source": [
    "# from fastai import *\n",
    "# from fastai.vision import *\n",
    "\n",
    "# import os\n",
    "# import pandas as pd\n",
    "# import sys\n",
    "\n",
    "# from collections import Counter\n",
    "# from pathlib import Path\n",
    "# import numpy\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "df1cf522",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Path??\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a38ecb6e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# import PIL,os,mimetypes\n",
    "# Path.ls = lambda x: list(x.iterdir())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4f989041",
   "metadata": {},
   "outputs": [],
   "source": [
    " \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "39d490be",
   "metadata": {},
   "outputs": [],
   "source": [
    "# path = Path('/kaggle/input/plant-pathology-2020-fgvc7')\n",
    "# path.ls()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6d93147b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# test_df=pd.read_csv('/kaggle/input/plant-pathology-2020-fgvc7/test.csv')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b9834e48",
   "metadata": {},
   "outputs": [],
   "source": [
    "# (path/'images').ls()[:3]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9707ed82",
   "metadata": {},
   "outputs": [],
   "source": [
    "# path_tench = path/'images'/'Train_1235.jpg'\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f99c9fdd",
   "metadata": {},
   "outputs": [],
   "source": [
    "# img_fn = (path/'images').ls()[0]\n",
    "# img_fn\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7b7cabfe",
   "metadata": {},
   "outputs": [],
   "source": [
    "# img = PIL.Image.open(img_fn)\n",
    "# img #print if you want but the images is realy big\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "468cdbfc",
   "metadata": {},
   "outputs": [],
   "source": [
    "# import numpy\n",
    "# imga = numpy.array(img)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2d423858",
   "metadata": {},
   "outputs": [],
   "source": [
    "# imga.shape\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1dab04d2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# imga[:10,:10,0]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6383cf7b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# image_extensions = set(k for k,v in mimetypes.types_map.items() if v.startswith('image/'))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1bfd9534",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ' '.join(image_extensions)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3a210b83",
   "metadata": {},
   "outputs": [],
   "source": [
    "# def setify(o): return o if isinstance(o,set) else set(listify(o))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ec298b3b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# def _get_files(p, fs, extensions=None):\n",
    "#     p = Path(p)\n",
    "#     res = [p/f for f in fs if not f.startswith('.')\n",
    "#            and ((not extensions) or f'.{f.split(\".\")[-1].lower()}' in extensions)]\n",
    "#     return res\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f2a1bab5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# def get_files(path, extensions=None, recurse=False, include=None):\n",
    "#     path = Path(path)\n",
    "#     extensions = setify(extensions)\n",
    "#     extensions = {e.lower() for e in extensions}\n",
    "#     if recurse:\n",
    "#         res = []\n",
    "#         for i,(p,d,f) in enumerate(os.walk(path)): # returns (dirpath, dirnames, filenames)\n",
    "#             if include is not None and i==0: d[:] = [o for o in d if o in include]\n",
    "#             else:                            d[:] = [o for o in d if not o.startswith('.')]\n",
    "#             res += _get_files(p, f, extensions)\n",
    "#         return res\n",
    "#     else:\n",
    "#         f = [o.name for o in os.scandir(path) if o.is_file()]\n",
    "#         return _get_files(path, f, extensions)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4abda837",
   "metadata": {},
   "outputs": [],
   "source": [
    "# get_files(path, image_extensions, recurse=True)[:3]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fc51a1f1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# all_fns = get_files(path, image_extensions, recurse=True)\n",
    "# len(all_fns)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e3a93d30",
   "metadata": {},
   "outputs": [],
   "source": [
    "# %timeit -n 10 get_files(path, image_extensions, recurse=True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fd4d53dd",
   "metadata": {},
   "outputs": [],
   "source": [
    "# bs=64\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e1d995de",
   "metadata": {},
   "outputs": [],
   "source": [
    "# def get_dls(train_ds, valid_ds, bs, **kwargs):\n",
    "#     return (DataLoader(train_ds, batch_size=bs, shuffle=True, **kwargs),\n",
    "#             DataLoader(valid_ds, batch_size=bs*2, **kwargs))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "40dac8d2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# labels for our classes\n",
    "# LABEL_COLS = ['healthy', 'multiple_diseases', 'rust', 'scab']\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4d027400",
   "metadata": {},
   "outputs": [],
   "source": [
    "# from fastai import *\n",
    "# from fastai.vision import *\n",
    "\n",
    "# import os\n",
    "# import pandas as pd\n",
    "# import sys\n",
    "\n",
    "# from collections import Counter\n",
    "# from pathlib import Path\n",
    "# import numpy\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e318fee8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# label_from_df??\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "da4c817d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# test = (ImageList.from_df(test_df,path,\n",
    "#                           folder='images',\n",
    "#                           suffix='.jpg',\n",
    "#                           cols='image_id'))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "965f4450",
   "metadata": {},
   "outputs": [],
   "source": [
    "# test\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "64baaa8b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# def get_transforms(do_flip:bool=True,mixup:float=0.4, flip_vert:bool=False, max_rotate:float=10., max_zoom:float=1.1,\n",
    "#                    max_lighting:float=0.2, max_warp:float=0.2, p_affine:float=0.75,\n",
    "#                    p_lighting:float=0.75, xtra_tfms:Optional[Collection[Transform]]=None)->Collection[Transform]:\n",
    "#     \"Utility func to easily create a list of flip, rotate, `zoom`, warp, lighting transforms.\"\n",
    "#     res = [rand_crop()]\n",
    "#     if do_flip:    res.append(dihedral_affine() if flip_vert else flip_lr(p=0.5))\n",
    "#     if max_warp:   res.append(symmetric_warp(magnitude=(-max_warp,max_warp), p=p_affine))\n",
    "#     if max_rotate: res.append(rotate(degrees=(-max_rotate,max_rotate), p=p_affine))\n",
    "#     if max_zoom>1: res.append(rand_zoom(scale=(1.,max_zoom), p=p_affine))\n",
    "#     if mixup: MixUp()\n",
    "#     if max_lighting:\n",
    "#         res.append(brightness(change=(0.5*(1-max_lighting), 0.5*(1+max_lighting)), p=p_lighting))\n",
    "#         res.append(contrast(scale=(1-max_lighting, 1/(1-max_lighting)), p=p_lighting))\n",
    "#     #       train                   , valid\n",
    "#     return (res + listify(xtra_tfms), [crop_pad()])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "85aa53d4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Γ = lambda x: x.lgamma().exp()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6e897812",
   "metadata": {},
   "outputs": [],
   "source": [
    "# facts = [math.factorial(i) for i in range(7)]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cc978847",
   "metadata": {},
   "outputs": [],
   "source": [
    "# plt.plot(range(7), facts, 'ro')\n",
    "# plt.plot(torch.linspace(0,6), Γ(torch.linspace(0,6)+1))\n",
    "# plt.legend(['factorial','Γ']);\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "84638f6e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# torch.linspace(0,0.9,10)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "81fc6bf8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# _,axs = plt.subplots(1,2, figsize=(12,4))\n",
    "# x = torch.linspace(0,1, 100)\n",
    "# for α,ax in zip([0.1,0.8], axs):\n",
    "#     α = tensor(α)\n",
    "# #     y = (x.pow(α-1) * (1-x).pow(α-1)) / (gamma_func(α ** 2) / gamma_func(α))\n",
    "#     y = (x**(α-1) * (1-x)**(α-1)) / (Γ(α)**2 / Γ(2*α))\n",
    "#     ax.plot(x,y)\n",
    "#     ax.set_title(f\"α={α:.1}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4cc953a9",
   "metadata": {},
   "outputs": [],
   "source": [
    "#export\n",
    "# class NoneReduce():\n",
    "#     def __init__(self, loss_func): \n",
    "#         self.loss_func,self.old_red = loss_func,None\n",
    "        \n",
    "#     def __enter__(self):\n",
    "#         if hasattr(self.loss_func, 'reduction'):\n",
    "#             self.old_red = getattr(self.loss_func, 'reduction')\n",
    "#             setattr(self.loss_func, 'reduction', 'none')\n",
    "#             return self.loss_func\n",
    "#         else: return partial(self.loss_func, reduction='none')\n",
    "        \n",
    "#     def __exit__(self, type, value, traceback):\n",
    "#         if self.old_red is not None: setattr(self.loss_func, 'reduction', self.old_red)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "841d345d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# from torch.distributions.beta import Beta\n",
    "\n",
    "# def unsqueeze(input, dims):\n",
    "#     for dim in listify(dims): input = torch.unsqueeze(input, dim)\n",
    "#     return input\n",
    "\n",
    "# def reduce_loss(loss, reduction='mean'):\n",
    "#     return loss.mean() if reduction=='mean' else loss.sum() if reduction=='sum' else loss\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "eb9b9ca5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# class MixUp():\n",
    "#     _order = 90 #Runs after normalization and cuda\n",
    "#     def __init__(self, α:float=0.4): self.distrib = Beta(tensor([α]), tensor([α]))\n",
    "    \n",
    "#     def begin_fit(self): self.old_loss_func,self.run.loss_func = self.run.loss_func,self.loss_func\n",
    "    \n",
    "#     def begin_batch(self):\n",
    "#         if not self.in_train: return #Only mixup things during training\n",
    "#         λ = self.distrib.sample((self.yb.size(0),)).squeeze().to(self.xb.device)\n",
    "#         λ = torch.stack([λ, 1-λ], 1)\n",
    "#         self.λ = unsqueeze(λ.max(1)[0], (1,2,3))\n",
    "#         shuffle = torch.randperm(self.yb.size(0)).to(self.xb.device)\n",
    "#         xb1,self.yb1 = self.xb[shuffle],self.yb[shuffle]\n",
    "#         self.run.xb = lin_comb(self.xb, xb1, self.λ)\n",
    "        \n",
    "#     def after_fit(self): self.run.loss_func = self.old_loss_func\n",
    "    \n",
    "#     def loss_func(self, pred, yb):\n",
    "#         if not self.in_train: return self.old_loss_func(pred, yb)\n",
    "#         with NoneReduce(self.old_loss_func) as loss_func:\n",
    "#             loss1 = loss_func(pred, yb)\n",
    "#             loss2 = loss_func(pred, self.yb1)\n",
    "#         loss = lin_comb(loss1, loss2, self.λ)\n",
    "#         return reduce_loss(loss, getattr(self.old_loss_func, 'reduction', 'mean'))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a5f3bfaf",
   "metadata": {},
   "outputs": [],
   "source": [
    "#transform the data to get a bigger training set\n",
    "# tfms = get_transforms(flip_vert=True,mixup=True, max_lighting=0.1, max_zoom=1.05, max_warp=0.)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f343e187",
   "metadata": {},
   "outputs": [],
   "source": [
    "# tfms = get_transforms(mixup=1)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "82738ce5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# from_csv??\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c3807d8a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# class ImageList(ItemList):\n",
    "#     \"`ItemList` suitable for computer vision.\"\n",
    "#     _bunch,_square_show,_square_show_res = ImageDataBunch,True,True\n",
    "#     def __init__(self, *args, convert_mode='RGB', after_open:Callable=None, **kwargs):\n",
    "#         super().__init__(*args, **kwargs)\n",
    "#         self.convert_mode,self.after_open = convert_mode,after_open\n",
    "#         self.copy_new += ['convert_mode', 'after_open']\n",
    "#         self.c,self.sizes = 3,{}\n",
    "\n",
    "#     def open(self, fn):\n",
    "#         \"Open image in `fn`, subclass and overwrite for custom behavior.\"\n",
    "#         return open_image(fn, convert_mode=self.convert_mode, after_open=self.after_open)\n",
    "\n",
    "#     def get(self, i):\n",
    "#         fn = super().get(i)\n",
    "#         res = self.open(fn)\n",
    "#         self.sizes[i] = res.size\n",
    "#         return res\n",
    "    \n",
    "#     @classmethod\n",
    "#     def from_folder(cls, path:PathOrStr='.', extensions:Collection[str]=None, **kwargs)->ItemList:\n",
    "#         \"Get the list of files in `path` that have an image suffix. `recurse` determines if we search subfolders.\"\n",
    "#         extensions = ifnone(extensions, image_extensions)\n",
    "#         return super().from_folder(path=path, extensions=extensions, **kwargs)\n",
    "\n",
    "#     @classmethod\n",
    "#     def from_df(cls, df:DataFrame, path:PathOrStr, cols:IntsOrStrs=0, folder:PathOrStr=None, suffix:str='', **kwargs)->'ItemList':\n",
    "#         \"Get the filenames in `cols` of `df` with `folder` in front of them, `suffix` at the end.\"\n",
    "#         suffix = suffix or ''\n",
    "#         res = super().from_df(df, path=path, cols=cols, **kwargs)\n",
    "#         pref = f'{res.path}{os.path.sep}'\n",
    "#         if folder is not None: pref += f'{folder}{os.path.sep}'\n",
    "#         res.items = np.char.add(np.char.add(pref, res.items.astype(str)), suffix)\n",
    "#         return res\n",
    "\n",
    "#     @classmethod\n",
    "#     def from_csv(cls, path:PathOrStr, csv_name:str, header:str='infer', delimiter:str=None, **kwargs)->'ItemList':\n",
    "#         \"Get the filenames in `path/csv_name` opened with `header`.\"\n",
    "#         path = Path(path)\n",
    "#         df = pd.read_csv(path/csv_name, header=header, delimiter=delimiter)\n",
    "#         return cls.from_df(df, path=path, **kwargs)\n",
    "\n",
    "#     def reconstruct(self, t:Tensor): return Image(t.float().clamp(min=0,max=1))\n",
    "\n",
    "#     def show_xys(self, xs, ys, imgsize:int=4, figsize:Optional[Tuple[int,int]]=None, **kwargs):\n",
    "#         \"Show the `xs` (inputs) and `ys` (targets) on a figure of `figsize`.\"\n",
    "#         rows = int(np.ceil(math.sqrt(len(xs))))\n",
    "#         axs = subplots(rows, rows, imgsize=imgsize, figsize=figsize)\n",
    "#         for x,y,ax in zip(xs, ys, axs.flatten()): x.show(ax=ax, y=y, **kwargs)\n",
    "#         for ax in axs.flatten()[len(xs):]: ax.axis('off')\n",
    "#         plt.tight_layout()\n",
    "\n",
    "#     def show_xyzs(self, xs, ys, zs, imgsize:int=4, figsize:Optional[Tuple[int,int]]=None, **kwargs):\n",
    "#         \"Show `xs` (inputs), `ys` (targets) and `zs` (predictions) on a figure of `figsize`.\"\n",
    "#         if self._square_show_res:\n",
    "#             title = 'Ground truth\\nPredictions'\n",
    "#             rows = int(np.ceil(math.sqrt(len(xs))))\n",
    "#             axs = subplots(rows, rows, imgsize=imgsize, figsize=figsize, title=title, weight='bold', size=12)\n",
    "#             for x,y,z,ax in zip(xs,ys,zs,axs.flatten()): x.show(ax=ax, title=f'{str(y)}\\n{str(z)}', **kwargs)\n",
    "#             for ax in axs.flatten()[len(xs):]: ax.axis('off')\n",
    "#         else:\n",
    "#             title = 'Ground truth/Predictions'\n",
    "#             axs = subplots(len(xs), 2, imgsize=imgsize, figsize=figsize, title=title, weight='bold', size=14)\n",
    "#             for i,(x,y,z) in enumerate(zip(xs,ys,zs)):\n",
    "#                 x.show(ax=axs[i,0], y=y, **kwargs)\n",
    "#                 x.show(ax=axs[i,1], y=z, **kwargs)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e8d2e7d2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# np.random.seed(42)\n",
    "# src=(ImageList.from_csv(path,'train.csv',folder='images',suffix='.jpg')\n",
    "# #     .split_by_rand_pct(0.2)\n",
    "#     .label_from_df(cols=LABEL_COLS,label_cls = MultiCategoryList))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c50ac9ea",
   "metadata": {},
   "outputs": [],
   "source": [
    "# data = (src.transform(tfms, size=253).add_test(test)\n",
    "#         .databunch(num_workers=0).normalize(imagenet_stats))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a35ad822",
   "metadata": {},
   "outputs": [],
   "source": [
    "# data.classes\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e11a564a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# data.show_batch(rows=3, figsize=(12,9))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9b9f54fc",
   "metadata": {},
   "outputs": [],
   "source": [
    "# tfms = [make_rgb, ResizeFixed(128), to_byte_tensor, to_float_tensor]\n",
    "\n",
    "# il = ImageList.from_csv(path,'train.csv',folder='images',suffix='.jpg')\n",
    "# sd = SplitData.split_by_func(il, partial(grandparent_splitter, valid_name='Test'))\n",
    "# ll = label_from_df(cols=LABEL_COLS,label_cls = MultiCategoryList)\n",
    "# data = ll.to_databunch(bs, c_in=3, c_out=4, num_workers=4)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ec85a60b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# data.classes\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0b4f4281",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import os\n",
    "import random, re, math\n",
    "import tensorflow as tf, tensorflow.keras.backend as K\n",
    "from tensorflow.keras.layers import Dense\n",
    "from tensorflow.keras.models import Model\n",
    "from tensorflow.keras import optimizers\n",
    "from kaggle_datasets import KaggleDatasets\n",
    "\n",
    "print(tf.__version__)\n",
    "print(tf.keras.__version__)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "54430f92",
   "metadata": {},
   "outputs": [],
   "source": [
    "!pip install efficientnet\n",
    "import efficientnet.tfkeras as efn\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "63c01d1a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# tf.data.experimental.AUTOTUNE??\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "36ba5d5c",
   "metadata": {},
   "outputs": [],
   "source": [
    "AUTO = tf.data.experimental.AUTOTUNE #basic Convert a number or string to an integer, or return 0 if no arguments\n",
    "#are given. for more detail uncommen the cell above\n",
    "# Detect hardware, return appropriate distribution strategy\n",
    "try:\n",
    "    tpu = tf.distribute.cluster_resolver.TPUClusterResolver()  # TPU detection. No parameters necessary if TPU_NAME environment variable is set. On Kaggle this is always the case.\n",
    "    print('Running on TPU ', tpu.master())\n",
    "except ValueError:\n",
    "    tpu = None\n",
    "\n",
    "if tpu:\n",
    "    tf.config.experimental_connect_to_cluster(tpu)\n",
    "    tf.tpu.experimental.initialize_tpu_system(tpu)\n",
    "    strategy = tf.distribute.experimental.TPUStrategy(tpu)\n",
    "else:\n",
    "    strategy = tf.distribute.get_strategy() # default distribution strategy in Tensorflow. Works on CPU and single GPU.\n",
    "\n",
    "print(\"REPLICAS: \", strategy.num_replicas_in_sync)\n",
    "\n",
    "\n",
    "# Data access\n",
    "GCS_DS_PATH = KaggleDatasets().get_gcs_path()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b665bfa2",
   "metadata": {},
   "outputs": [],
   "source": [
    "from matplotlib import pyplot as plt\n",
    "\n",
    "img = plt.imread('../input/plant-pathology-2020-fgvc7/images/Train_0.jpg')\n",
    "print(img.shape)\n",
    "plt.imshow(img)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dc55edd3",
   "metadata": {},
   "outputs": [],
   "source": [
    "path='../input/plant-pathology-2020-fgvc7/'\n",
    "train = pd.read_csv(path + 'train.csv')\n",
    "test = pd.read_csv(path + 'test.csv')\n",
    "sub = pd.read_csv(path + 'sample_submission.csv')\n",
    "\n",
    "train_paths = train.image_id.apply(lambda x: GCS_DS_PATH + '/images/' + x + '.jpg').values #put out datapath on the TPU\n",
    "test_paths = test.image_id.apply(lambda x: GCS_DS_PATH + '/images/' + x + '.jpg').values #put out datapath on the TPU\n",
    "\n",
    "train_labels = train.loc[:, 'healthy':].values #you can also use '1' instead of 'healthy' but all it does is taking all the results the 4 different labels\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "eb3e013b",
   "metadata": {},
   "outputs": [],
   "source": [
    "train #Seeing the training csv-file\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1e2f91c4",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_labels #all the rows for the labels we want to classify\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2004add7",
   "metadata": {},
   "outputs": [],
   "source": [
    "nb_classes = 4 #number of labels, this will be used for our output layer\n",
    "BATCH_SIZE = 8 * strategy.num_replicas_in_sync # this is 8 on TPU v3-8, it is 1 on CPU and GPU #try change it to 16\n",
    "img_size = 768 #u decide but bigger images take longer to train but higher kvali and smaller images is faster but lower kvali\n",
    "EPOCHS = 40 #number of training rounds\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "05147b6b",
   "metadata": {},
   "outputs": [],
   "source": [
    "x = tf.constant([1.8, 2.2], dtype=tf.float32)\n",
    "print(type(x))\n",
    "tf.dtypes.cast(x, tf.int32)  # [1, 2], dtype=tf.int32\n",
    "print(type(x))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9a89728c",
   "metadata": {},
   "outputs": [],
   "source": [
    "type(x)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1c54207d",
   "metadata": {},
   "outputs": [],
   "source": [
    "#decode_image label every image if it has a label from csv-file and return also the image that has no label\n",
    "def decode_image(filename, label=None, image_size=(img_size, img_size)):\n",
    "    bits = tf.io.read_file(filename)#get the filename\n",
    "    image = tf.image.decode_jpeg(bits, channels=3) #channel representing some aspect of information about the image \n",
    "    #and u can have 100+ channels if you want but it is proven to be good to put it at 3\n",
    "    image = tf.cast(image, tf.float32) / 255.0 #tf.cast means = Casts a tensor to a new type. so the images tensor becomes a type float\n",
    "    image = tf.image.resize(image, image_size) #resize the image for the size given above\n",
    "    if label is None:  #if there is no label for an image\n",
    "        return image #jusst return the image\n",
    "    else:\n",
    "        return image, label #else return the image with the label\n",
    "    \n",
    "#data_augment just take the images and do som augment to them\n",
    "def data_augment(image, label=None, seed=2020): \n",
    "    image = tf.image.random_flip_left_right(image, seed=seed) #flip randomly images to left or right\n",
    "    image = tf.image.random_flip_up_down(image, seed=seed) #flip the images randomly up or down\n",
    "    image=tf.image.adjust_saturation(image, 10)\n",
    "    image=tf.image.resize_with_crop_or_pad(img, 800, 900)\n",
    "    \n",
    "    #for every new image\n",
    "    if label is None:  #if there is no label for an image\n",
    "        return image#jusst return the image\n",
    "    else:\n",
    "        return image, label #else return the image with the label\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6d350461",
   "metadata": {},
   "outputs": [],
   "source": [
    "saturated = tf.image.adjust_saturation(img, 10)\n",
    "plt.imshow(saturated)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f3e4ca20",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.imshow(img) #if we look at the before and after picture it is clear to see that illness of the plant is much clear on the saturated image, so we are gonna use it in our data aurgment function above \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "70394cbc",
   "metadata": {},
   "outputs": [],
   "source": [
    "#making the training dataset for more detail on the given functions uncommen the cell below\n",
    "train_dataset = (\n",
    "    tf.data.Dataset #explaned above nut just a API blok iniziator\n",
    "    .from_tensor_slices((train_paths, train_labels)) #Creates a `Dataset` whose elements are slices of the given tensors\n",
    "    # 'from_tensor_slices' --> The given tensors are sliced along their first dimension. This operation\n",
    "#     preserves the structure of the input tensors, removing the first dimension\n",
    "#     of each tensor and using it as the dataset dimension. All input tensors\n",
    "#     must have the same size in their first dimensions.\n",
    "    .map(decode_image, num_parallel_calls=AUTO) #Maps `map_func` across the elements of this dataset# note here is 'map_func'='decode_image' which returned the labels with the images\n",
    "    #This transformation applies `map_func` to each element of this dataset, and\n",
    "#     returns a new dataset containing the transformed elements, in the same\n",
    "#     order as they appeared in the input. `map_func` can be used to change both\n",
    "#     the values and the structure of a dataset's elements. For example, adding 1\n",
    "#     to each element, or projecting a subset of element components.\n",
    "    .map(data_augment, num_parallel_calls=AUTO)#note here we use data_augment wich fliped the images for ech element in the dataset\n",
    "    .repeat() #Repeats this dataset so each original value is seen `count` times. #see exsampel below #  The default behavior (if\n",
    "        #count` is `None` or `-1`) is for the dataset be repeated indefinitely.\n",
    "\n",
    "    .shuffle(512) #Randomly shuffles the elements of this dataset.#and it randomize by 512 (u set value) each time\n",
    "    .batch(BATCH_SIZE) \n",
    "    .prefetch(AUTO) #Creates a `Dataset` that prefetches elements from this dataset.\n",
    "#     Most dataset input pipelines should end with a call to `prefetch`. This\n",
    "#     allows later elements to be prepared while the current element is being\n",
    "#     processed. This often improves latency and throughput, at the cost of\n",
    "#     using additional memory to store prefetched elements.\n",
    "    )\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "eb799681",
   "metadata": {},
   "outputs": [],
   "source": [
    "#  tf.data.Dataset??\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "35e8df0b",
   "metadata": {},
   "outputs": [],
   "source": [
    "test_dataset = (\n",
    "    tf.data.Dataset #explaned above nut just a API blok iniziator\n",
    "    .from_tensor_slices(test_paths)\n",
    "    .map(decode_image, num_parallel_calls=AUTO) \n",
    "    #note we dont flip the testing images because then we cant validate the predictions from the model\n",
    "    .batch(BATCH_SIZE)\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e45fa16c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# tf.keras.callbacks??\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b05ca346",
   "metadata": {},
   "outputs": [],
   "source": [
    "#predifened learning rates for optimal preformaze\n",
    "LR_START = 0.00001\n",
    "LR_MAX = 0.0001 * strategy.num_replicas_in_sync\n",
    "LR_MIN = 0.00001\n",
    "LR_RAMPUP_EPOCHS = 15\n",
    "LR_SUSTAIN_EPOCHS = 3\n",
    "LR_EXP_DECAY = .8\n",
    "#here we change the learning depending on what epoch we are at \n",
    "def lrfn(epoch):\n",
    "    if epoch < LR_RAMPUP_EPOCHS: #if epoch is lower then 15\n",
    "        lr = (LR_MAX - LR_START) / LR_RAMPUP_EPOCHS * epoch + LR_START #take this learning rate\n",
    "    elif epoch < LR_RAMPUP_EPOCHS + LR_SUSTAIN_EPOCHS:#if epoch is lower then 15+3=18 \n",
    "        lr = LR_MAX #then take this learning rate\n",
    "    else: #else if is above 18 then \n",
    "        lr = (LR_MAX - LR_MIN) * LR_EXP_DECAY**(epoch - LR_RAMPUP_EPOCHS - LR_SUSTAIN_EPOCHS) + LR_MIN#take this learning rate\n",
    "    return lr\n",
    "    \n",
    "lr_callback = tf.keras.callbacks.LearningRateScheduler(lrfn, verbose=True) #create a callback to make the functionality possible when we do the actual training. \n",
    "#verbose = true just means we want to see the traning proces bar\n",
    "\n",
    "#plot the learning rate schedular \n",
    "rng = [i for i in range(EPOCHS)]\n",
    "y = [lrfn(x) for x in rng]\n",
    "plt.plot(rng, y)\n",
    "print(\"Learning rate schedule: {:.3g} to {:.3g} to {:.3g}\".format(y[0], max(y), y[-1]))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "31e25294",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_model():\n",
    "    #pretrained_model = tf.keras.applications.MobileNetV2(input_shape=[*IMAGE_SIZE, 3], include_top=False)\n",
    "#     pretrained_model = tf.keras.applications.Xception(weights='imagenet', input_shape=(img_size, img_size, 3), include_top=False)\n",
    "    #pretrained_model = tf.keras.applications.VGG16(weights='imagenet', include_top=False ,input_shape=[*IMAGE_SIZE, 3])\n",
    "#     pretrained_model = tf.keras.applications.ResNet50(weights='imagenet', include_top=False, input_shape=(img_size, img_size, 3))\n",
    "    #pretrained_model = tf.keras.applications.MobileNet(weights='imagenet', include_top=False, input_shape=[*IMAGE_SIZE, 3])\n",
    "    # EfficientNet can be loaded through efficientnet.tfkeras library (https://github.com/qubvel/efficientnet)\n",
    "    pretrained_model = efn.EfficientNetB7(weights='imagenet', include_top=False, pooling='avg', input_shape=(img_size, img_size, 3))\n",
    "    pretrained_model.trainable = True\n",
    "    \n",
    "    model = tf.keras.Sequential([\n",
    "        pretrained_model,\n",
    "#         tf.keras.layers.GlobalAveragePooling2D(),\n",
    "        tf.keras.layers.Flatten(),\n",
    "        tf.keras.layers.Dense(4, activation='softmax') #4 since there are 4 labels and therefor 4 diferent predictions \n",
    "    ])\n",
    "\n",
    "#     x = pretrained_model.output\n",
    "#     predictions = Dense(4, activation=\"softmax\")(x)\n",
    "    return model\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5dc05c5e",
   "metadata": {},
   "outputs": [],
   "source": [
    "with strategy.scope():\n",
    "    model = get_model()\n",
    "model.compile(optimizer='adam', loss='categorical_crossentropy',metrics=['accuracy'])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6d94ee07",
   "metadata": {},
   "outputs": [],
   "source": [
    "#  model.compile(\n",
    "#         optimizer='adam',\n",
    "#         loss = 'categorical_crossentropy',\n",
    "#         metrics=['accuracy']\n",
    "#     )\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3366569d",
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "history=model.fit(\n",
    "    train_dataset, \n",
    "    steps_per_epoch=train_labels.shape[0] // BATCH_SIZE,\n",
    "    callbacks=[lr_callback],\n",
    "    epochs=16\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4308c01e",
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "probs = model.predict(test_dataset)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a7283215",
   "metadata": {},
   "outputs": [],
   "source": [
    "sub.loc[:, 'healthy':] = probs\n",
    "sub.to_csv('submission.csv', index=False)\n",
    "sub.head()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f2516bdf",
   "metadata": {},
   "outputs": [],
   "source": [
    "# train_paths\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "14f07902",
   "metadata": {},
   "outputs": [],
   "source": [
    "# data.classes\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "419a47d7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# class AvgStatsCallback(Callback):\n",
    "#     def __init__(self, metrics):\n",
    "#         self.train_stats,self.valid_stats = AvgStats(metrics,True),AvgStats(metrics,False)\n",
    "        \n",
    "#     def begin_epoch(self):\n",
    "#         self.train_stats.reset()\n",
    "#         self.valid_stats.reset()\n",
    "        \n",
    "#     def after_loss(self):\n",
    "#         stats = self.train_stats if self.in_train else self.valid_stats\n",
    "#         with torch.no_grad(): stats.accumulate(self.run)\n",
    "    \n",
    "#     def after_epoch(self):\n",
    "#         print(self.train_stats)\n",
    "#         print(self.valid_stats)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b88cf76a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# def accuracy(out, yb): return (torch.argmax(out, dim=1)==yb).float().mean()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c038f94e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# class CudaCallback(Callback):\n",
    "#     def begin_fit(self): self.model.cuda()\n",
    "#     def begin_batch(self): self.run.xb,self.run.yb = self.xb.cuda(),self.yb.cuda()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "12710d81",
   "metadata": {},
   "outputs": [],
   "source": [
    "# cbfs = [partial(AvgStatsCallback,accuracy),\n",
    "#         CudaCallback]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1ee9403f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# def normalize_chan(x, mean, std):\n",
    "#     return (x-mean[...,None,None]) / std[...,None,None]\n",
    "\n",
    "# _m = tensor([0.47, 0.48, 0.45])\n",
    "# _s = tensor([0.29, 0.28, 0.30])\n",
    "# norm_imagenette = partial(normalize_chan, mean=_m.cuda(), std=_s.cuda())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d61916f5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# class BatchTransformXCallback(Callback):\n",
    "#     _order=2\n",
    "#     def __init__(self, tfm): self.tfm = tfm\n",
    "#     def begin_batch(self): self.run.xb = self.tfm(self.xb)\n",
    "\n",
    "# def view_tfm(*size):\n",
    "#     def _inner(x): return x.view(*((-1,)+size))\n",
    "#     return _inner\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9b491223",
   "metadata": {},
   "outputs": [],
   "source": [
    "# cbfs.append(partial(BatchTransformXCallback, norm_imagenette))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "02ba663a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# nfs = [64,64,128,256]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "eda9e522",
   "metadata": {},
   "outputs": [],
   "source": [
    " \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "594d6a3d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# import math\n",
    "# def prev_pow_2(x): return 2**math.floor(math.log2(x))\n",
    "\n",
    "# def get_cnn_layers(data, nfs, layer, **kwargs):\n",
    "#     def f(ni, nf, stride=2): return layer(ni, nf, 3, stride=stride, **kwargs)\n",
    "#     l1 = data.c\n",
    "#     l2 = prev_pow_2(l1*3*3)\n",
    "#     layers =  [f(l1  , l2  , stride=1),\n",
    "#                f(l2  , l2*2, stride=2),\n",
    "#                f(l2*2, l2*4, stride=2)]\n",
    "#     nfs = [l2*4] + nfs\n",
    "#     layers += [f(nfs[i], nfs[i+1]) for i in range(len(nfs)-1)]\n",
    "#     layers += [nn.AdaptiveAvgPool2d(1), Lambda(flatten), \n",
    "#                nn.Linear(nfs[-1], data.c)]\n",
    "#     return layers\n",
    "\n",
    "# def get_cnn_model(data, nfs, layer, **kwargs):\n",
    "#     return nn.Sequential(*get_cnn_layers(data, nfs, layer, **kwargs))\n",
    "\n",
    "# def get_learn_run(nfs, data, lr, layer, cbs=None, opt_func=None, **kwargs):\n",
    "#     model = get_cnn_model(data, nfs, layer, **kwargs)\n",
    "#     init_cnn(model)\n",
    "#     return get_runner(model, data, lr=lr, cbs=cbs, opt_func=opt_func)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "438dbb4f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# def combine_scheds(pcts, scheds):\n",
    "#     assert sum(pcts) == 1.\n",
    "#     pcts = tensor([0] + listify(pcts))\n",
    "#     assert torch.all(pcts >= 0)\n",
    "#     pcts = torch.cumsum(pcts, 0)\n",
    "#     def _inner(pos):\n",
    "#         idx = (pos >= pcts).nonzero().max()\n",
    "#         actual_pos = (pos-pcts[idx]) / (pcts[idx+1]-pcts[idx])\n",
    "#         return scheds[idx](actual_pos)\n",
    "#     return _inner\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1ad403f7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# def annealer(f):\n",
    "#     def _inner(start, end): return partial(f, start, end)\n",
    "#     return _inner\n",
    "\n",
    "# @annealer\n",
    "# def sched_lin(start, end, pos): return start + pos*(end-start)\n",
    "\n",
    "# import torch\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "105836ee",
   "metadata": {},
   "outputs": [],
   "source": [
    "# @annealer\n",
    "# def sched_cos(start, end, pos): return start + (1 + math.cos(math.pi*(1-pos))) * (end-start) / 2\n",
    "# @annealer\n",
    "# def sched_no(start, end, pos):  return start\n",
    "# @annealer\n",
    "# def sched_exp(start, end, pos): return start * (end/start) ** pos\n",
    "\n",
    "# def cos_1cycle_anneal(start, high, end):\n",
    "#     return [sched_cos(start, high), sched_cos(high, end)]\n",
    "\n",
    "# #This monkey-patch is there to be able to plot tensors\n",
    "# torch.Tensor.ndim = property(lambda x: len(x.shape))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6ac42098",
   "metadata": {},
   "outputs": [],
   "source": [
    "# sched = combine_scheds([0.3,0.7], cos_1cycle_anneal(0.1,0.3,0.05))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d46c0692",
   "metadata": {},
   "outputs": [],
   "source": [
    "# class ParamScheduler(Callback):\n",
    "#     _order=1\n",
    "#     def __init__(self, pname, sched_funcs): self.pname,self.sched_funcs = pname,sched_funcs\n",
    "        \n",
    "#     def begin_fit(self):\n",
    "#         if not isinstance(self.sched_funcs, (list,tuple)):\n",
    "#             self.sched_funcs = [self.sched_funcs] * len(self.opt.param_groups)\n",
    "\n",
    "#     def set_param(self):\n",
    "#         assert len(self.opt.param_groups)==len(self.sched_funcs)\n",
    "#         for pg,f in zip(self.opt.param_groups,self.sched_funcs):\n",
    "#             pg[self.pname] = f(self.n_epochs/self.epochs)\n",
    "            \n",
    "#     def begin_batch(self): \n",
    "#         if self.in_train: self.set_param()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b007c0e4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# def flatten(x):      return x.view(x.shape[0], -1)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "27ab74c9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# def init_cnn(m, uniform=False):\n",
    "#     f = init.kaiming_uniform_ if uniform else init.kaiming_normal_\n",
    "#     for l in m:\n",
    "#         if isinstance(l, nn.Sequential):\n",
    "#             f(l[0].weight, a=0.1)\n",
    "#             l[0].bias.data.zero_()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f85c6a1f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# def get_learn_run(nfs, data, lr, layer, cbs=None, opt_func=None, uniform=False, **kwargs):\n",
    "#     model = get_cnn_model(data, nfs, layer, **kwargs)\n",
    "#     init_cnn(model, uniform=uniform)\n",
    "#     return get_runner(model, data, lr=lr, cbs=cbs, opt_func=opt_func)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "42d13f76",
   "metadata": {},
   "outputs": [],
   "source": [
    "# from torch.nn import init\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "098c9de2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# arch = models.resnet50\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3493fd84",
   "metadata": {},
   "outputs": [],
   "source": [
    " \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5e9a2b97",
   "metadata": {},
   "outputs": [],
   "source": [
    "# resnet50??\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3a5bb572",
   "metadata": {},
   "outputs": [],
   "source": [
    "# models??\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c602a563",
   "metadata": {},
   "outputs": [],
   "source": [
    "# def accuracy_thresh(y_pred:Tensor, y_true:Tensor, thresh:float=0.5, sigmoid:bool=True)->Rank0Tensor:\n",
    "#     \"Computes accuracy when `y_pred` and `y_true` are the same size.\"\n",
    "#     if sigmoid: y_pred = y_pred.sigmoid()\n",
    "#     return ((y_pred>thresh).byte()==y_true.byte()).float().mean()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ad9bd419",
   "metadata": {},
   "outputs": [],
   "source": [
    " \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e2725b4d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# accuracy_thresh??\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4f1f8984",
   "metadata": {},
   "outputs": [],
   "source": [
    "# cnn_config??\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "171d3739",
   "metadata": {},
   "outputs": [],
   "source": [
    "# create_cnn_model??\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e2a41a58",
   "metadata": {},
   "outputs": [],
   "source": [
    "# create_cnn??\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a674ae6a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# arch = models.resnet50\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "526adfa5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# acc_02 = partial(accuracy_thresh, thresh=0.2)\n",
    "# f_score = partial(fbeta, thresh=0.2)\n",
    "# learn = create_cnn(data, arch, metrics=[acc_02], model_dir='/kaggle/working')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "32b0298d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# lr=1e-03\n",
    "# learn.fit_one_cycle(5,slice(lr))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bc89f2aa",
   "metadata": {},
   "outputs": [],
   "source": [
    "# learn,run = get_learn_run(nfs, data, 0.2, conv_layer, cbs=cbfs+[\n",
    "#     partial(ParamScheduler, 'lr', sched)\n",
    "# ])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fcea0126",
   "metadata": {},
   "outputs": [],
   "source": [
    " \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cf635266",
   "metadata": {},
   "outputs": [],
   "source": [
    "# path2 = Path('/kaggle/input/plant-pathology-2020-fgvc7/images')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3d47e1de",
   "metadata": {},
   "outputs": [],
   "source": [
    "# df = pd.read_csv(path/'train.csv')\n",
    "# df.head()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "95249351",
   "metadata": {},
   "outputs": [],
   "source": [
    "# test_df = pd.read_csv('../input/plant-pathology-2020-fgvc7/test.csv')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d82cf3f8",
   "metadata": {},
   "outputs": [],
   "source": [
    " \n"
   ]
  }
 ],
 "metadata": {},
 "nbformat": 4,
 "nbformat_minor": 5
}

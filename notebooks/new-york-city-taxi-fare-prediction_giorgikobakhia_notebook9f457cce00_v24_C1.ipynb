{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e2e8c1f9",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from pathlib import Path"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "13714fc4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# This Python 3 environment comes with many helpful analytics libraries installed\n",
    "# It is defined by the kaggle/python Docker image: https://github.com/kaggle/docker-python\n",
    "# For example, here's several helpful packages to load\n",
    "\n",
    "import numpy as np # linear algebra\n",
    "import pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\n",
    "\n",
    "# Input data files are available in the read-only \"../input/\" directory\n",
    "# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n",
    "\n",
    "import os\n",
    "for dirname, _, filenames in os.walk('/kaggle/input'):\n",
    "    for filename in filenames:\n",
    "        print(os.path.join(dirname, filename))\n",
    "\n",
    "# You can write up to 20GB to the current directory (/kaggle/working/) that gets preserved as output when you create a version using \"Save & Run All\" \n",
    "# You can also write temporary files to /kaggle/temp/, but they won't be saved outside of the current session\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import folium\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "76871aa1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# მონაცემების ჩატვირთვა\n",
    "train_df =  pd.read_csv('/kaggle/input/new-york-city-taxi-fare-prediction/train.csv', nrows = 10_000)\n",
    "test_df =  pd.read_csv('/kaggle/input/new-york-city-taxi-fare-prediction/test.csv')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e85dd84e",
   "metadata": {},
   "outputs": [],
   "source": [
    "test_df.shape\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b16fc7ec",
   "metadata": {},
   "outputs": [],
   "source": [
    "test_df.describe()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "834f2e81",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_df.head()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6f42dd6d",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_df.shape\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "91d5f8b2",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_df.dtypes\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "852f16ac",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_df.describe()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "24431228",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(train_df.isnull().sum())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a6d08b2f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# გადავყაროთ missing values, რადგან დატასეტის მცირე ნაწილს შეადგენენ\n",
    "print('Old size: %d' % len(train_df))\n",
    "train_df = train_df.dropna(how = 'any', axis = 'rows')\n",
    "print('New size: %d' % len(train_df))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d93a21d9",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(len(train_df[train_df.fare_amount > 100]))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1ed0c52d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# გადავყაროთ არადადებითი თანხები და 100 მეტი თანხები\n",
    "print('Old size: %d' % len(train_df))\n",
    "train_df = train_df[(train_df.fare_amount>0) & (train_df.fare_amount<=100)]\n",
    "print('New size: %d' % len(train_df))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b3cd497c",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_df.describe()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d6cc68ea",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(len(train_df[train_df.passenger_count > 6]))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "91503407",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(len(train_df[train_df.passenger_count == 0]))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e4ac476e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# გადავყაროთ 6-ზე მეტ მგზავრიანი მონაცემები\n",
    "\n",
    "print('Old size: %d' % len(train_df))\n",
    "old_len = len(train_df)\n",
    "train_df = train_df[(train_df.passenger_count<=6) & (train_df.passenger_count>0)]\n",
    "print(f'New size: {len(train_df)}, removed: {old_len - len(train_df)}')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e1bba25e",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_df.describe()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "36177ac4",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.hist(train_df['fare_amount'], bins=10, color='skyblue', edgecolor='black')\n",
    "plt.title('Distribution of Fare Amounts')\n",
    "plt.xlabel('Fare Amount')\n",
    "plt.ylabel('Frequency')\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "993ddc20",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_df.describe()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2b08e3f1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ტესტსეტის მიხედვით ვიპოვოთ ნიუ-იორკის მიახლოებითი კოორდინატები\n",
    "# min_longitude = min(test_df['pickup_longitude'].min(), test_df['dropoff_longitude'].min())\n",
    "# max_longitude = max(test_df['pickup_longitude'].max(), test_df['dropoff_longitude'].max())\n",
    "\n",
    "# min_latitude = min(test_df['pickup_latitude'].min(), test_df['dropoff_latitude'].min())\n",
    "# max_latitude = max(test_df['pickup_latitude'].max(), test_df['dropoff_latitude'].max())\n",
    "\n",
    "# ნიუ იორკის მიახლოებითი კოორდინატები\n",
    "min_longitude = -74.5\n",
    "max_longitude = -72.8\n",
    "min_latitude = 40.5\n",
    "max_latitude = 41.8\n",
    "\n",
    "#-74.5, -72.8, 40.5, 41.8\n",
    "\n",
    "print(\"Minimum Longitude:\", min_longitude)\n",
    "print(\"Maximum Longitude:\", max_longitude)\n",
    "print(\"Minimum Latitude:\", min_latitude)\n",
    "print(\"Maximum Latitude:\", max_latitude)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cb1bf87c",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_df = train_df[\n",
    "    (train_df['pickup_longitude'] >= min_longitude) &\n",
    "    (train_df['pickup_longitude'] <= max_longitude) &\n",
    "    (train_df['pickup_latitude'] >= min_latitude) &\n",
    "    (train_df['pickup_latitude'] <= max_latitude)\n",
    "]\n",
    "\n",
    "train_df = train_df[\n",
    "    (train_df['dropoff_longitude'] >= min_longitude) &\n",
    "    (train_df['dropoff_longitude'] <= max_longitude) &\n",
    "    (train_df['dropoff_latitude'] >= min_latitude) &\n",
    "    (train_df['dropoff_latitude'] <= max_latitude)\n",
    "]\n",
    "\n",
    "train_df.describe()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4d1393fd",
   "metadata": {},
   "outputs": [],
   "source": [
    "from geopy.distance import geodesic\n",
    "\n",
    "from math import radians, sin, cos, sqrt, atan2\n",
    "\n",
    "# დავითვალოთ მანძილები და დავამატოთ ახალი ფიჩერის სახით\n",
    "\n",
    "def haversine_distance(lat1, lon1, lat2, lon2):\n",
    "    lat1, lon1, lat2, lon2 = map(radians, [lat1, lon1, lat2, lon2])\n",
    "    \n",
    "    dlat = lat2 - lat1\n",
    "    dlon = lon2 - lon1\n",
    "    a = sin(dlat / 2) ** 2 + cos(lat1) * cos(lat2) * sin(dlon / 2) ** 2\n",
    "    c = 2 * atan2(sqrt(a), sqrt(1 - a))\n",
    "    distance = 6371 * c  \n",
    "    \n",
    "    return distance\n",
    "\n",
    "distances = train_df.apply(lambda row: haversine_distance(\n",
    "                                row['pickup_latitude'], row['pickup_longitude'],\n",
    "                                row['dropoff_latitude'], row['dropoff_longitude']), axis=1)\n",
    "\n",
    "train_df['distance'] = distances\n",
    "\n",
    "plt.hist(list(filter(lambda x: x <= 30, distances)), bins=100, color='skyblue', edgecolor='black')\n",
    "plt.title('Distribution of Distances between Pickup and Dropoff Locations')\n",
    "plt.xlabel('Distance (km)')\n",
    "plt.ylabel('Frequency')\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "05e5c804",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_df.distance.describe()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3721ab6f",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_df['fare_per_km'] = train_df.distance/train_df.fare_amount\n",
    "train_df.fare_per_km.describe()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e4acafed",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_df = train_df[(train_df['fare_per_km'] <= 0.5) & (train_df['fare_per_km'] > 0)]\n",
    "plt.hist(train_df['fare_per_km'], bins=10, color='skyblue', edgecolor='black')\n",
    "plt.title('Fare per km distribuiton')\n",
    "plt.xlabel('Fare per km')\n",
    "plt.ylabel('Frequency')\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6c653092",
   "metadata": {},
   "outputs": [],
   "source": [
    "# დავამატოთ წელი, კვირის დღე და საათი ფიჩერებად\n",
    "pickup_datetime = pd.to_datetime(train_df['pickup_datetime'])\n",
    "train_df['year'] = pickup_datetime.apply(lambda t: t.year)\n",
    "train_df['weekday'] = pickup_datetime.apply(lambda t: t.weekday())\n",
    "train_df['hour'] = pickup_datetime.apply(lambda t: t.hour)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2952ed70",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.hist(train_df['weekday'], bins=10, color='skyblue', edgecolor='black')\n",
    "plt.title('Weekday distribution')\n",
    "plt.xlabel('Weekday')\n",
    "plt.ylabel('Frequency')\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f6377a9c",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.hist(train_df['hour'], bins=20, color='skyblue', edgecolor='black')\n",
    "plt.title('Hour distribution')\n",
    "plt.xlabel('Hour')\n",
    "plt.ylabel('Frequency')\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "58f37ca5",
   "metadata": {},
   "outputs": [],
   "source": [
    "hourly_fare_mean = train_df.groupby('hour')['fare_per_km'].mean()\n",
    "print(hourly_fare_mean)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bd26ca87",
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# Example Series hourly_fare_mean containing mean fare amount for each hour\n",
    "# Replace hourly_fare_mean with your actual Series\n",
    "\n",
    "# Plotting\n",
    "plt.figure(figsize=(10, 6))\n",
    "plt.plot(hourly_fare_mean.index, hourly_fare_mean.values, marker='o', linestyle='-')\n",
    "plt.title('Mean Fare per km by Hour')\n",
    "plt.xlabel('Hour')\n",
    "plt.ylabel('Mean Fare Amount')\n",
    "plt.xticks(hourly_fare_mean.index)  # Ensure ticks are at each hour\n",
    "plt.grid(True)\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "61e201c5",
   "metadata": {},
   "outputs": [],
   "source": [
    "weekday_fare_mean = train_df.groupby('weekday')['fare_per_km'].mean()\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# Example Series hourly_fare_mean containing mean fare amount for each hour\n",
    "# Replace hourly_fare_mean with your actual Series\n",
    "\n",
    "# Plotting\n",
    "plt.figure(figsize=(10, 6))\n",
    "plt.plot(weekday_fare_mean.index, weekday_fare_mean.values, marker='o', linestyle='-')\n",
    "plt.title('Mean Fare per km by weekday')\n",
    "plt.xlabel('Weekday')\n",
    "plt.ylabel('Mean Fare Amount')\n",
    "plt.xticks(weekday_fare_mean.index)  # Ensure ticks are at each hour\n",
    "plt.grid(True)\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "02d6019d",
   "metadata": {},
   "outputs": [],
   "source": [
    "yearly_fare_mean = train_df.groupby('year')['fare_per_km'].mean()\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# Example Series hourly_fare_mean containing mean fare amount for each hour\n",
    "# Replace hourly_fare_mean with your actual Series\n",
    "\n",
    "# Plotting\n",
    "plt.figure(figsize=(10, 6))\n",
    "plt.plot(yearly_fare_mean.index, yearly_fare_mean.values, marker='o', linestyle='-')\n",
    "plt.title('Mean Fare per km by year')\n",
    "plt.xlabel('year')\n",
    "plt.ylabel('Mean Fare Amount')\n",
    "plt.xticks(yearly_fare_mean.index)  # Ensure ticks are at each hour\n",
    "plt.grid(True)\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ac0e57d5",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_df['high_fare_days'] = train_df['weekday'].isin([0, 6, 5]).astype(int)\n",
    "train_df['low_fare_days'] = train_df['weekday'].isin([1, 2, 3, 4]).astype(int)\n",
    "\n",
    "train_df['low_fare_hours'] = ((train_df['hour'] >= 8) & (train_df['hour'] <= 19)).astype(int)\n",
    "train_df['high_fare_hours'] = ((train_df['hour'] < 8) | (train_df['hour'] > 19)).astype(int)\n",
    "\n",
    "train_df['high_fare_years'] = (train_df['year'] <= 2012).astype(int)\n",
    "train_df['low_fare_years'] = (train_df['year'] > 2012).astype(int)\n",
    "\n",
    "train_df['monday'] = (train_df['weekday'] == 0).astype(int)\n",
    "train_df['tuesday'] = (train_df['weekday'] == 1).astype(int)\n",
    "train_df['wednesday'] = (train_df['weekday'] == 2).astype(int)\n",
    "train_df['thursday'] = (train_df['weekday'] == 3).astype(int)\n",
    "train_df['friday'] = (train_df['weekday'] == 4).astype(int)\n",
    "train_df['saturday'] = (train_df['weekday'] == 5).astype(int)\n",
    "train_df['sunday'] = (train_df['weekday'] == 6).astype(int)\n",
    "train_df.describe()\n",
    "print(train_df['sunday'].sum())\n",
    "print(train_df['monday'].sum())\n",
    "print(train_df['friday'].sum())\n",
    "print(train_df['tuesday'].sum())\n",
    "print(train_df['wednesday'].sum())\n",
    "print(train_df['saturday'].sum())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b5d98084",
   "metadata": {},
   "outputs": [],
   "source": [
    "distances = test_df.apply(lambda row: haversine_distance(\n",
    "                                row['pickup_latitude'], row['pickup_longitude'],\n",
    "                                row['dropoff_latitude'], row['dropoff_longitude']), axis=1)\n",
    "\n",
    "test_df['distance'] = distances\n",
    "pickup_datetime = pd.to_datetime(test_df['pickup_datetime'])\n",
    "print(pickup_datetime)\n",
    "test_df['year'] = pickup_datetime.apply(lambda t: t.year)\n",
    "test_df['weekday'] = pickup_datetime.apply(lambda t: t.weekday())\n",
    "test_df['hour'] = pickup_datetime.apply(lambda t: t.hour)\n",
    "\n",
    "test_df['high_fare_days'] = test_df['weekday'].isin([0, 6, 5]).astype(int)\n",
    "test_df['low_fare_days'] = test_df['weekday'].isin([1, 2, 3, 4]).astype(int)\n",
    "\n",
    "test_df['low_fare_hours'] = ((test_df['hour'] >= 8) & (test_df['hour'] <= 19)).astype(int)\n",
    "test_df['high_fare_hours'] = ((test_df['hour'] < 8) | (test_df['hour'] > 19)).astype(int)\n",
    "\n",
    "test_df['high_fare_years'] = (test_df['year'] <= 2012).astype(int)\n",
    "test_df['low_fare_years'] = (test_df['year'] > 2012).astype(int)\n",
    "\n",
    "test_df['monday'] = (test_df['weekday'] == 0).astype(int)\n",
    "test_df['tuesday'] = (test_df['weekday'] == 1).astype(int)\n",
    "test_df['wednesday'] = (test_df['weekday'] == 2).astype(int)\n",
    "test_df['thursday'] = (test_df['weekday'] == 3).astype(int)\n",
    "test_df['friday'] = (test_df['weekday'] == 4).astype(int)\n",
    "test_df['saturday'] = (test_df['weekday'] == 5).astype(int)\n",
    "test_df['sunday'] = (test_df['weekday'] == 6).astype(int)\n",
    "test_df.describe()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e3086ac4",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.linear_model import LinearRegression\n",
    "from sklearn.metrics import mean_squared_error\n",
    "\n",
    "X = train_df[[\n",
    "    \"pickup_longitude\",\n",
    "    \"pickup_latitude\",\n",
    "    \"dropoff_longitude\",\n",
    "    \"dropoff_latitude\",\n",
    "    \"passenger_count\",\n",
    "    \"distance\",\n",
    "    \"year\",\n",
    "#    \"weekday\",\n",
    "    \"hour\",\n",
    "    \"monday\",\n",
    "    \"tuesday\",\n",
    "    \"wednesday\",\n",
    "    \"thursday\",\n",
    "    \"friday\",\n",
    "    \"saturday\",\n",
    "    \"sunday\",\n",
    "    \"high_fare_days\",\n",
    "    \"low_fare_days\",\n",
    "    \"high_fare_years\",\n",
    "    \"low_fare_years\",\n",
    "    \"high_fare_hours\",\n",
    "    \"low_fare_hours\",\n",
    "]]\n",
    "\n",
    "y = train_df[\"fare_amount\"]\n",
    "\n",
    "X_test = test_df.drop(columns=[\"key\", \"pickup_datetime\"])\n",
    "X_train, X_valid, y_train, y_valid = train_test_split(X, y, train_size=0.8, test_size=0.2, random_state=42, shuffle=True)\n",
    "\n",
    "# Instantiate the linear regression model\n",
    "model = LinearRegression()\n",
    "\n",
    "# Train the model on the training data\n",
    "model.fit(X_train, y_train)\n",
    "\n",
    "# Make predictions on the validation data\n",
    "y_pred_valid = model.predict(X_valid)\n",
    "\n",
    "# Evaluate model performance on validation data\n",
    "rmse_valid = mean_squared_error(y_valid, y_pred_valid, squared=False)\n",
    "print(\"Mean Squared Error on Validation Data:\", rmse_valid)\n",
    "\n",
    "# Make predictions on the test data\n",
    "#y_pred_test = model.predict(X_test)\n",
    "\n",
    "# # Evaluate model performance on test data (optional)\n",
    "#rmse_test = mean_squared_error(y_test, y_pred_test)\n",
    "#print(\"Mean Squared Error on Test Data:\", rmse_test)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e5b11003",
   "metadata": {},
   "outputs": [],
   "source": [
    "# from sklearn.model_selection import train_test_split\n",
    "# from sklearn.linear_model import LinearRegression\n",
    "# from sklearn.metrics import mean_squared_error\n",
    "\n",
    "# X = train_df.drop(columns=[\"key\", \"fare_amount\", \"pickup_datetime\", \"fare_per_km\"])\n",
    "\n",
    "# y = train_df[\"fare_amount\"]\n",
    "\n",
    "# X_test = test_df.drop(columns=[\"key\", \"pickup_datetime\"])\n",
    "# X_train, X_valid, y_train, y_valid = train_test_split(X, y, train_size=0.8, test_size=0.2, random_state=42, shuffle=True)\n",
    "\n",
    "# # Instantiate the linear regression model\n",
    "# model = LinearRegression()\n",
    "\n",
    "# # Train the model on the training data\n",
    "# model.fit(X_train, y_train)\n",
    "\n",
    "# # Make predictions on the validation data\n",
    "# y_pred_valid = model.predict(X_valid)\n",
    "\n",
    "# # Evaluate model performance on validation data\n",
    "# rmse_valid = mean_squared_error(y_valid, y_pred_valid, squared = False)\n",
    "# print(\"Mean Squared Error on Validation Data:\", rmse_valid)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4bf10e13",
   "metadata": {},
   "outputs": [],
   "source": [
    "# import xgboost as xgb\n",
    "# from sklearn.model_selection import train_test_split\n",
    "# from sklearn.metrics import mean_squared_error\n",
    "\n",
    "# X = train_df[[\n",
    "#     \"pickup_longitude\",\n",
    "#     \"pickup_latitude\",\n",
    "#     \"dropoff_longitude\",\n",
    "#     \"dropoff_latitude\",\n",
    "#     \"passenger_count\",\n",
    "#     \"distance\",\n",
    "#     \"year\",\n",
    "#     \"weekday\",\n",
    "#     \"hour\",\n",
    "#     \"monday\",\n",
    "#     \"tuesday\",\n",
    "#     \"wednesday\",\n",
    "#     \"thursday\",\n",
    "#     \"friday\",\n",
    "#     \"saturday\",\n",
    "#     \"sunday\",\n",
    "#     \"high_fare_days\",\n",
    "#     \"high_fare_years\",\n",
    "#     \"low_fare_hours\",\n",
    "# ]]\n",
    "\n",
    "# y = train_df[\"fare_amount\"]\n",
    "\n",
    "# X_train, X_valid, y_train, y_valid = train_test_split(X, y, random_state=42, shuffle=True)\n",
    "\n",
    "# dtrain = xgb.DMatrix(X_train, label=y_train)\n",
    "# dvalid = xgb.DMatrix(X_valid, label=y_valid)\n",
    "\n",
    "# params = {\n",
    "#     \"objective\": \"reg:squarederror\",  \n",
    "#     \"eval_metric\": \"rmse\",             \n",
    "#     \"random_state\": 42,\n",
    "#     'max_depth': 5,\n",
    "#     \"eta\": 0.1\n",
    "# }\n",
    "\n",
    "# num_rounds = 500 \n",
    "# model = xgb.train(params, dtrain, num_rounds, evals=[(dvalid, \"Validation\")], early_stopping_rounds=10, verbose_eval=True)\n",
    "\n",
    "# y_pred = model.predict(dvalid)\n",
    "\n",
    "# rmse = mean_squared_error(y_valid, y_pred, squared = False)\n",
    "# print(\"Mean Squared Error on Validation Set:\", rmse)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4d3e0aa7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# import xgboost as xgb        \n",
    "# from sklearn.model_selection import train_test_split\n",
    "# from sklearn.metrics import mean_squared_error\n",
    "\n",
    "# X = train_df[[\n",
    "#     \"pickup_longitude\",\n",
    "#     \"pickup_latitude\",\n",
    "#     \"dropoff_longitude\",\n",
    "#     \"dropoff_latitude\",\n",
    "#     \"passenger_count\",\n",
    "# #     \"distance\",\n",
    "# #     \"year\",\n",
    "# #     \"weekday\",\n",
    "# #     \"hour\",\n",
    "# #     \"monday\",\n",
    "# #     \"tuesday\",\n",
    "# #     \"wednesday\",\n",
    "# #     \"thursday\",\n",
    "# #     \"friday\",\n",
    "# #     \"saturday\",\n",
    "# #     \"sunday\",\n",
    "# #     \"high_fare_days\",\n",
    "# #     \"high_fare_years\",\n",
    "# #     \"low_fare_hours\",\n",
    "# ]]\n",
    "\n",
    "# y = train_df[\"fare_amount\"]\n",
    "\n",
    "# X_train, X_valid, y_train, y_valid = train_test_split(X, y, random_state=42, shuffle=True)\n",
    "\n",
    "# dtrain = xgb.DMatrix(X_train, label=y_train)\n",
    "# dvalid = xgb.DMatrix(X_valid, label=y_valid)\n",
    "\n",
    "# params = {\n",
    "#     \"objective\": \"reg:squarederror\",  \n",
    "#     \"eval_metric\": \"rmse\",             \n",
    "#     \"random_state\": 42,\n",
    "#     'max_depth': 6,\n",
    "#     \"eta\": 0.1\n",
    "# }\n",
    "\n",
    "# n_estimators = 500 \n",
    "# model = xgb.train(params, dtrain, n_estimators, evals=[(dvalid, \"Validation\")], early_stopping_rounds=5, verbose_eval=True)\n",
    "\n",
    "# y_pred = model.predict(dvalid)\n",
    "\n",
    "# rmse = mean_squared_error(y_valid, y_pred, squared = False)\n",
    "# print(\"Mean Squared Error on Validation Set:\", rmse)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "78b5fa76",
   "metadata": {},
   "outputs": [],
   "source": [
    "# import xgboost as xgb        \n",
    "# from sklearn.model_selection import train_test_split\n",
    "# from sklearn.metrics import mean_squared_error\n",
    "\n",
    "# X = train_df[[\n",
    "#     \"pickup_longitude\",\n",
    "#     \"pickup_latitude\",\n",
    "#     \"dropoff_longitude\",\n",
    "#     \"dropoff_latitude\",\n",
    "#     \"passenger_count\",\n",
    "#     \"distance\",\n",
    "#     \"year\",\n",
    "#     \"weekday\",\n",
    "#     \"hour\",\n",
    "# #     \"monday\",\n",
    "# #     \"tuesday\",\n",
    "# #     \"wednesday\",\n",
    "# #     \"thursday\",\n",
    "# #     \"friday\",\n",
    "# #     \"saturday\",\n",
    "# #     \"sunday\",\n",
    "# #     \"high_fare_days\",\n",
    "# #     \"high_fare_years\",\n",
    "# #     \"low_fare_hours\",\n",
    "# ]]\n",
    "\n",
    "# y = train_df[\"fare_amount\"]\n",
    "\n",
    "# X_train, X_valid, y_train, y_valid = train_test_split(X, y, random_state=42, shuffle=True)\n",
    "\n",
    "# dtrain = xgb.DMatrix(X_train, label=y_train)\n",
    "# dvalid = xgb.DMatrix(X_valid, label=y_valid)\n",
    "\n",
    "# params = {\n",
    "#     \"objective\": \"reg:squarederror\",  \n",
    "#     \"eval_metric\": \"rmse\",             \n",
    "#     \"random_state\": 42,\n",
    "#     'max_depth': 6,\n",
    "#     \"eta\": 0.1\n",
    "# }\n",
    "\n",
    "# n_estimators = 500 \n",
    "# model = xgb.train(params, dtrain, n_estimators, evals=[(dvalid, \"Validation\")], early_stopping_rounds=5, verbose_eval=True)\n",
    "\n",
    "# y_pred = model.predict(dvalid)\n",
    "\n",
    "# rmse = mean_squared_error(y_valid, y_pred, squared = False)\n",
    "# print(\"Mean Squared Error on Validation Set:\", rmse)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "29bc5317",
   "metadata": {},
   "outputs": [],
   "source": [
    "# import xgboost as xgb        \n",
    "# from sklearn.model_selection import train_test_split\n",
    "# from sklearn.metrics import mean_squared_error\n",
    "\n",
    "# X = train_df[[\n",
    "#     \"pickup_longitude\",\n",
    "#     \"pickup_latitude\",\n",
    "#     \"dropoff_longitude\",\n",
    "#     \"dropoff_latitude\",\n",
    "#     \"passenger_count\",\n",
    "#     \"distance\",\n",
    "#     \"year\",\n",
    "# #    \"weekday\",\n",
    "#     \"hour\",\n",
    "#     \"monday\",\n",
    "#     \"tuesday\",\n",
    "#     \"wednesday\",\n",
    "#     \"thursday\",\n",
    "#     \"friday\",\n",
    "#     \"saturday\",\n",
    "#     \"sunday\",\n",
    "# #     \"high_fare_days\",\n",
    "# #     \"high_fare_years\",\n",
    "# #     \"low_fare_hours\",\n",
    "# ]]\n",
    "\n",
    "# y = train_df[\"fare_amount\"]\n",
    "\n",
    "# X_train, X_valid, y_train, y_valid = train_test_split(X, y, random_state=42, shuffle=True)\n",
    "\n",
    "# dtrain = xgb.DMatrix(X_train, label=y_train)\n",
    "# dvalid = xgb.DMatrix(X_valid, label=y_valid)\n",
    "\n",
    "# params = {\n",
    "#     \"objective\": \"reg:squarederror\",  \n",
    "#     \"eval_metric\": \"rmse\",             \n",
    "#     \"random_state\": 42,\n",
    "#     'max_depth': 6,\n",
    "#     \"eta\": 0.1\n",
    "# }\n",
    "\n",
    "# n_estimators = 500 \n",
    "# model = xgb.train(params, dtrain, n_estimators, evals=[(dvalid, \"Validation\")], early_stopping_rounds=5, verbose_eval=True)\n",
    "\n",
    "# y_pred = model.predict(dvalid)\n",
    "\n",
    "# rmse = mean_squared_error(y_valid, y_pred, squared = False)\n",
    "# print(\"Mean Squared Error on Validation Set:\", rmse)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "aa8e23af",
   "metadata": {},
   "outputs": [],
   "source": [
    "# import xgboost as xgb        \n",
    "# from sklearn.model_selection import train_test_split\n",
    "# from sklearn.metrics import mean_squared_error\n",
    "\n",
    "# X = train_df[[\n",
    "#     \"pickup_longitude\",\n",
    "#     \"pickup_latitude\",\n",
    "#     \"dropoff_longitude\",\n",
    "#     \"dropoff_latitude\",\n",
    "#     \"passenger_count\",\n",
    "#     \"distance\",\n",
    "#     \"year\",\n",
    "# #    \"weekday\",\n",
    "#     \"hour\",\n",
    "#     \"monday\",\n",
    "#     \"tuesday\",\n",
    "#     \"wednesday\",\n",
    "#     \"thursday\",\n",
    "#     \"friday\",\n",
    "#     \"saturday\",\n",
    "#     \"sunday\",\n",
    "# #     \"high_fare_days\",\n",
    "# #     \"high_fare_years\",\n",
    "# #     \"low_fare_hours\",\n",
    "# ]]\n",
    "\n",
    "# y = train_df[\"fare_amount\"]\n",
    "\n",
    "# X_train, X_valid, y_train, y_valid = train_test_split(X, y, random_state=42, shuffle=True)\n",
    "\n",
    "# dtrain = xgb.DMatrix(X_train, label=y_train)\n",
    "# dvalid = xgb.DMatrix(X_valid, label=y_valid)\n",
    "\n",
    "# params = {\n",
    "#     \"objective\": \"reg:squarederror\",  \n",
    "#     \"eval_metric\": \"rmse\",             \n",
    "#     \"random_state\": 42,\n",
    "#     'max_depth': 6,\n",
    "#     \"eta\": 0.01\n",
    "# }\n",
    "\n",
    "# n_estimators = 1000 \n",
    "# model = xgb.train(params, dtrain, n_estimators, evals=[(dvalid, \"Validation\")], early_stopping_rounds=5, verbose_eval=True)\n",
    "\n",
    "# y_pred = model.predict(dvalid)\n",
    "\n",
    "# rmse = mean_squared_error(y_valid, y_pred, squared = False)\n",
    "# print(\"Mean Squared Error on Validation Set:\", rmse)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ede97a8d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# import xgboost as xgb        \n",
    "# from sklearn.model_selection import train_test_split\n",
    "# from sklearn.metrics import mean_squared_error\n",
    "\n",
    "# X = train_df[[\n",
    "#     \"pickup_longitude\",\n",
    "#     \"pickup_latitude\",\n",
    "#     \"dropoff_longitude\",\n",
    "#     \"dropoff_latitude\",\n",
    "#     \"passenger_count\",\n",
    "#     \"distance\",\n",
    "#     \"year\",\n",
    "# #    \"weekday\",\n",
    "#     \"hour\",\n",
    "#     \"monday\",\n",
    "#     \"tuesday\",\n",
    "#     \"wednesday\",\n",
    "#     \"thursday\",\n",
    "#     \"friday\",\n",
    "#     \"saturday\",\n",
    "#     \"sunday\",\n",
    "#     \"high_fare_days\",\n",
    "#     \"low_fare_days\",\n",
    "#     \"high_fare_years\",\n",
    "#     \"low_fare_years\",\n",
    "#     \"high_fare_hours\",\n",
    "#     \"low_fare_hours\",\n",
    "# ]]\n",
    "\n",
    "# y = train_df[\"fare_amount\"]\n",
    "\n",
    "# X_train, X_valid, y_train, y_valid = train_test_split(X, y, random_state=42, shuffle=True)\n",
    "\n",
    "# dtrain = xgb.DMatrix(X_train, label=y_train)\n",
    "# dvalid = xgb.DMatrix(X_valid, label=y_valid)\n",
    "\n",
    "# params = {\n",
    "#     \"objective\": \"reg:squarederror\",  \n",
    "#     \"eval_metric\": \"rmse\",             \n",
    "#     \"random_state\": 42,\n",
    "#     'max_depth': 6,\n",
    "#     \"eta\": 0.1\n",
    "# }\n",
    "\n",
    "# n_estimators = 500 \n",
    "# model = xgb.train(params, dtrain, n_estimators, evals=[(dvalid, \"Validation\")], early_stopping_rounds=5, verbose_eval=True)\n",
    "\n",
    "# y_pred = model.predict(dvalid)\n",
    "\n",
    "# rmse = mean_squared_error(y_valid, y_pred, squared = False)\n",
    "# print(\"Mean Squared Error on Validation Set:\", rmse)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "be6e5181",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_test = test_df[[\n",
    "    \"pickup_longitude\",\n",
    "    \"pickup_latitude\",\n",
    "    \"dropoff_longitude\",\n",
    "    \"dropoff_latitude\",\n",
    "    \"passenger_count\",\n",
    "    \"distance\",\n",
    "    \"year\",\n",
    "#    \"weekday\",\n",
    "    \"hour\",\n",
    "    \"monday\",\n",
    "    \"tuesday\",\n",
    "    \"wednesday\",\n",
    "    \"thursday\",\n",
    "    \"friday\",\n",
    "    \"saturday\",\n",
    "    \"sunday\",\n",
    "    \"high_fare_days\",\n",
    "    \"low_fare_days\",\n",
    "    \"high_fare_years\",\n",
    "    \"low_fare_years\",\n",
    "    \"high_fare_hours\",\n",
    "    \"low_fare_hours\",\n",
    "]]\n",
    "\n",
    "#dtest = xgb.DMatrix(X_test)\n",
    "# Make predictions on the test data\n",
    "y_pred_test = model.predict(X_test)\n",
    "submission = pd.DataFrame(\n",
    "    {'key': test_df.key, 'fare_amount': y_pred_test},\n",
    "    columns = ['key', 'fare_amount'])\n",
    "submission.to_csv('submission.csv', index = False)\n",
    "\n",
    "print(os.listdir('.'))\n"
   ]
  }
 ],
 "metadata": {},
 "nbformat": 4,
 "nbformat_minor": 5
}

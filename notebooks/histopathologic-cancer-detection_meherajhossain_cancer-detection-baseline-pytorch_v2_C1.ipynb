{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fc8749d6",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from pathlib import Path"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9042db57",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import cv2\n",
    "import copy\n",
    "import random\n",
    "import time\n",
    "from PIL import Image\n",
    "from PIL import Image, ImageDraw\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "import torch \n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "from torchvision import models\n",
    "import torchvision.transforms as transforms\n",
    "from torch.utils.data import TensorDataset, DataLoader, Dataset, random_split\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4eddabb4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Device configuration\n",
    "device = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n",
    "print(\"Using {} device\".format(device))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2f320eb7",
   "metadata": {},
   "outputs": [],
   "source": [
    "!pip install torchsummary\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1f3e45cc",
   "metadata": {},
   "outputs": [],
   "source": [
    "N_EPOCHS = 10\n",
    "BATCH_SIZE = 128\n",
    "# IMG_HEIGHT = 96\n",
    "# IMG_WIDTH = 96\n",
    "SEED = 1234\n",
    "\n",
    "## For normalization required by pretrained models in torchvision.models\n",
    "MEAN = [0.485, 0.456, 0.406]\n",
    "STD = [0.229, 0.224, 0.225]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4a859350",
   "metadata": {},
   "outputs": [],
   "source": [
    "def seed_everything(seed):\n",
    "    random.seed(seed)\n",
    "    os.environ['PYTHONHASHSEED'] = str(seed)\n",
    "    np.random.seed(seed)\n",
    "    torch.manual_seed(seed)\n",
    "    torch.cuda.manual_seed(seed)\n",
    "#     torch.backends.cudnn.deterministic = True\n",
    "\n",
    "seed_everything(SEED)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bc442aeb",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_dir = '../input/histopathologic-cancer-detection/train'\n",
    "test_dir = '../input/histopathologic-cancer-detection/test'\n",
    "train_labels = pd.read_csv('../input/histopathologic-cancer-detection/train_labels.csv')\n",
    "submission = pd.read_csv('../input/histopathologic-cancer-detection/sample_submission.csv')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d161a173",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_size = len(os.listdir(train_dir))\n",
    "test_size = len(os.listdir(test_dir))\n",
    "\n",
    "print(train_size,test_size)\n",
    "print(train_labels.shape)\n",
    "print(submission.shape)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2b5632bf",
   "metadata": {},
   "outputs": [],
   "source": [
    "display(train_labels.head())\n",
    "display(submission.head())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f6f26ff2",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_labels['label'].value_counts()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b53c15b1",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(13, 6))\n",
    "train_labels['label'].value_counts().plot(kind='bar')\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2aaadbeb",
   "metadata": {},
   "outputs": [],
   "source": [
    "# get the ids of cancer cases\n",
    "cancer = train_labels.loc[train_labels['label']==1]['id'].to_numpy() \n",
    "\n",
    "# get the ids of the normal cases\n",
    "normal = train_labels.loc[train_labels['label']==0]['id'].to_numpy()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cae28635",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.rcParams['figure.figsize'] = (15, 6)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "eca6ac07",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Visualize cancer cases\n",
    "\n",
    "nrows, ncols= 6, 15\n",
    "plt.subplots_adjust(wspace=0, hspace=0) \n",
    "\n",
    "for i, image_id in enumerate(cancer[: nrows * ncols]):\n",
    "    img_path = os.path.join(train_dir , image_id +'.tif')\n",
    "    img = Image.open(img_path)\n",
    "    idcol = ImageDraw.Draw(img)\n",
    "    idcol.rectangle(((0,0),(95,95)),outline='red')\n",
    "    plt.subplot(nrows, ncols, i+1) \n",
    "    plt.imshow(np.array(img))\n",
    "    plt.axis('off')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ef4b45e6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Visualize Normal Cases\n",
    "\n",
    "nrows, ncols= 6, 15\n",
    "plt.subplots_adjust(wspace=0, hspace=0) \n",
    "\n",
    "for i, image_id in enumerate(normal[: nrows * ncols]):\n",
    "    img_path = os.path.join(train_dir , image_id +'.tif')\n",
    "    img = Image.open(img_path)\n",
    "    idcol = ImageDraw.Draw(img)\n",
    "    idcol.rectangle(((0,0),(95,95)),outline='green')\n",
    "    plt.subplot(nrows, ncols, i+1) \n",
    "    plt.imshow(np.array(img))\n",
    "    plt.axis('off')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6871f50c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# class CustomDataset(Dataset):\n",
    "    \n",
    "#     def __init__(self, labels, img_dir, transform=None, target_transform=None):\n",
    "#         self.img_labels = labels\n",
    "#         self.img_dir = img_dir\n",
    "#         self.transform = transform\n",
    "#         self.target_transform = target_transform\n",
    "\n",
    "#     def __len__(self):\n",
    "#         return len(self.img_labels)\n",
    "\n",
    "#     def __getitem__(self, idx):\n",
    "#         img_name, label = self.img_labels.iloc[idx]\n",
    "#         img_path = os.path.join(self.img_dir, img_name + '.tif')\n",
    "#         image =  Image.open(img_path)\n",
    "\n",
    "#         if self.transform is not None:\n",
    "#             image = self.transform(image)\n",
    "#         if self.target_transform is not None:\n",
    "#             label = self.target_transform(label)\n",
    "            \n",
    "#         return image, label\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b5d14e35",
   "metadata": {},
   "outputs": [],
   "source": [
    "class CustomDataset(Dataset):\n",
    "    \n",
    "    def __init__(self, labels, img_dir, dataset_type = 'train', transform=None, target_transform=None):\n",
    "        self.img_labels = labels\n",
    "        self.img_dir = img_dir\n",
    "        self.transform = transform\n",
    "        self.target_transform = target_transform\n",
    "        self.dataset_type = dataset_type\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.img_labels)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        img_id = self.img_labels.loc[idx, 'id']\n",
    "        img_path = os.path.join(self.img_dir, img_id + '.tif')\n",
    "        image =  Image.open(img_path)\n",
    "\n",
    "        if self.transform is not None:\n",
    "            image = self.transform(image)\n",
    "            \n",
    "        # For Test Dataset, we don't have class label.\n",
    "        # So for Test Dataset, we will return the image 'id' as label\n",
    "        label = 0\n",
    "        \n",
    "        if self.dataset_type == 'train':\n",
    "            label = self.img_labels.loc[idx, 'label']\n",
    "            \n",
    "            if self.target_transform is not None:\n",
    "                label = self.target_transform(label)\n",
    "        \n",
    "        elif self.dataset_type == 'test':\n",
    "            label = img_id\n",
    "            \n",
    "        return image, label\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "25ece1b4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define transformation that converts a PIL image into PyTorch tensors.\n",
    "import torchvision.transforms as transforms\n",
    "data_transformer = transforms.Compose([transforms.ToTensor()])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a5345015",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define an instance of the custom dataset for the train folder.\n",
    "dataset = CustomDataset(train_labels, train_dir, transform = data_transformer)\n",
    "\n",
    "img, label = dataset[24]\n",
    "print(img.shape, torch.min(img), torch.max(img))\n",
    "print(label)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3e22cff8",
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset_size = len(dataset)\n",
    "train_size = int(0.8 * dataset_size)\n",
    "valid_size = dataset_size - train_size\n",
    "\n",
    "# Split Pytorch tensor\n",
    "train_dataset, valid_dataset = random_split(dataset, [train_size, valid_size]) # random split 80/20\n",
    "\n",
    "print(\"train dataset size:\", len(train_dataset))\n",
    "print(\"validation dataset size:\", len(valid_dataset))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f3c8649c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define the following transformations for the training dataset\n",
    "train_transformer = transforms.Compose([\n",
    "    transforms.RandomHorizontalFlip(p=0.5), \n",
    "    transforms.RandomVerticalFlip(p=0.5),  \n",
    "    transforms.RandomRotation(20),         \n",
    "#     transforms.RandomResizedCrop(96, scale=(0.8,1.0),ratio=(1.0,1.0)),\n",
    "    transforms.ToTensor()]\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "25dc95e4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# For the validation dataset, we don't need any augmentation; simply convert images into tensors\n",
    "valid_transformer = transforms.Compose([\n",
    "    transforms.ToTensor()]\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "05413d5c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# After defining the transformations, overwrite the transform functions of train_ts, val_ts\n",
    "train_dataset.transform = train_transformer\n",
    "valid_dataset.transform = valid_transformer\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bb5d23ac",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define two dataloaders for the datasets\n",
    "\n",
    "train_dataloader = DataLoader(train_dataset, batch_size = BATCH_SIZE, shuffle=True)\n",
    "valid_dataloader = DataLoader(valid_dataset, batch_size = BATCH_SIZE, shuffle=False)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ccd0d5fd",
   "metadata": {},
   "outputs": [],
   "source": [
    "for batch, (X, y) in enumerate(train_dataloader):\n",
    "    print(\"Batch : {}\".format(batch))\n",
    "    print(X.shape)\n",
    "    print(y.shape)\n",
    "    \n",
    "    if batch == 4:\n",
    "        break\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4f70e0f2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# model = models.densenet169(pretrained=True)\n",
    "# model\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9eb47b3e",
   "metadata": {},
   "outputs": [],
   "source": [
    "class BasicCNN(nn.Module):\n",
    "    \n",
    "    def __init__(self):\n",
    "        super(BasicCNN, self).__init__()\n",
    "        \n",
    "        self.layer1 = nn.Sequential(\n",
    "            nn.Conv2d(3, 32, kernel_size=3, padding=1, stride=1),\n",
    "            nn.BatchNorm2d(32),\n",
    "            nn.ReLU(),\n",
    "            nn.MaxPool2d(kernel_size = 2, stride = 2)\n",
    "        )\n",
    "        \n",
    "        self.layer2 = nn.Sequential(\n",
    "            nn.Conv2d(32, 64, kernel_size=3, padding=1, stride=1),\n",
    "            nn.BatchNorm2d(64),\n",
    "            nn.ReLU(),\n",
    "            nn.MaxPool2d(kernel_size = 2, stride = 2)\n",
    "        )\n",
    "        \n",
    "        self.layer3 = nn.Sequential(\n",
    "            nn.Conv2d(64, 128, kernel_size=3, padding=1, stride=1),\n",
    "            nn.BatchNorm2d(128),\n",
    "            nn.ReLU(),\n",
    "            nn.MaxPool2d(kernel_size = 2, stride = 2)\n",
    "        )\n",
    "        \n",
    "        self.layer4 = nn.Sequential(\n",
    "            nn.Conv2d(128, 256, kernel_size=3, padding=1, stride=1),\n",
    "            nn.BatchNorm2d(256),\n",
    "            nn.ReLU(),\n",
    "            nn.MaxPool2d(kernel_size = 2, stride = 2)\n",
    "        )\n",
    "        \n",
    "        self.layer5 = nn.Sequential(\n",
    "            nn.Conv2d(256, 512, kernel_size=3, padding=1, stride=1),\n",
    "            nn.BatchNorm2d(512),\n",
    "            nn.ReLU(),\n",
    "            nn.MaxPool2d(kernel_size = 2, stride = 2)\n",
    "        )\n",
    "        \n",
    "        self.avg_pool = nn.AvgPool2d(kernel_size = 3)\n",
    "        \n",
    "        self.fc1 = nn.Linear(1*1*512, 32)\n",
    "        self.dropout = nn.Dropout(0.5)\n",
    "        self.fc2 = nn.Linear(32, 2)\n",
    "        self.relu = nn.ReLU()\n",
    "        \n",
    "        \n",
    "    def forward(self,x):\n",
    "        x = self.layer1(x)\n",
    "        x = self.layer2(x)\n",
    "        x = self.layer3(x)\n",
    "        x = self.layer4(x)\n",
    "        x = self.layer5(x)\n",
    "#         print(x.shape)\n",
    "        x = self.avg_pool(x)\n",
    "#         print(x.shape)\n",
    "        x = x.view(-1, 1 * 1 * 512)\n",
    "#         print(x.shape)\n",
    "        x = self.relu(self.fc1(x))\n",
    "        x = self.dropout(x)\n",
    "        x = self.fc2(x)\n",
    "#         x = F.softmax(x)\n",
    "        return x\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "00d50b40",
   "metadata": {},
   "outputs": [],
   "source": [
    "# If we need to move a model to GPU via .cuda(), \n",
    "# we must do it before constructing optimizers for it. \n",
    "# Parameters of a model after .cuda() will be different objects with those before the call.\n",
    "\n",
    "# In general, we should make sure that optimized parameters live in consistent locations \n",
    "# when optimizers are constructed and used.\n",
    "\n",
    "model = BasicCNN().to(device)\n",
    "model\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ec87884a",
   "metadata": {},
   "outputs": [],
   "source": [
    "from torchsummary import summary\n",
    "summary(model, input_size=(3,96,96))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c64bbddf",
   "metadata": {},
   "outputs": [],
   "source": [
    "LEARNING_RATE = 0.001\n",
    "optimizer = torch.optim.Adam(params = model.parameters(),lr=LEARNING_RATE)\n",
    "criterion = nn.CrossEntropyLoss(reduction='mean')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1c93693d",
   "metadata": {},
   "outputs": [],
   "source": [
    "def train(dataloader, model, loss_fn, optimizer):\n",
    "    ds_size = len(dataloader.dataset)\n",
    "    num_batch = len(dataloader)\n",
    "    \n",
    "    total_accurate_preds = 0.0\n",
    "    total_loss = 0.0\n",
    "    \n",
    "    model.train()\n",
    "    for batch_idx, (X, y) in enumerate(dataloader):\n",
    "        X, y = X.to(device), y.to(device)\n",
    "\n",
    "        # Compute prediction error\n",
    "        logits = model(X)\n",
    "        loss = loss_fn(logits, y) # average loss per batch \n",
    "        preds = logits.argmax(dim=1)\n",
    "        num_accurate_preds = (preds == y).float().sum() # number of correct predictions for a single batch\n",
    "        \n",
    "        total_loss += loss.item()\n",
    "        total_accurate_preds += num_accurate_preds.item()\n",
    "    \n",
    "        # Backpropagation\n",
    "        optimizer.zero_grad()\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "\n",
    "        if batch_idx % 100 == 0:\n",
    "            current = batch_idx * len(X)\n",
    "            print(f\"loss: {loss.item():>7f}  [{current}/{ds_size}]\")\n",
    "\n",
    "    accuracy = total_accurate_preds/ ds_size\n",
    "    avg_loss = total_loss/ num_batch\n",
    "\n",
    "    return  accuracy, avg_loss\n",
    "\n",
    "# train(train_dataloader, model, criterion, optimizer)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "de37b3b7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# model.eval() will notify all your layers that we are in eval mode, that way, \n",
    "# batchnorm or dropout layers will work in eval mode instead of training mode.\n",
    "\n",
    "# torch.no_grad() impacts the autograd engine and deactivate it. \n",
    "# It will reduce memory usage and speed up computations \n",
    "# but we won’t be able to backprop (which we don’t want in an eval mode).\n",
    "\n",
    "def evaluate(dataloader, model, loss_fn):\n",
    "    ds_size = len(dataloader.dataset)\n",
    "    num_batch = len(dataloader)\n",
    "    \n",
    "    total_accurate_preds = 0\n",
    "    total_loss = 0.0\n",
    "    \n",
    "    model.eval()\n",
    "    with torch.no_grad():\n",
    "        for X, y in dataloader:\n",
    "            X, y = X.to(device), y.to(device)\n",
    "            \n",
    "            # Compute prediction error\n",
    "            logits = model(X)\n",
    "            loss = loss_fn(logits, y) # average loss per batch \n",
    "            preds = logits.argmax(dim=1)\n",
    "            num_accurate_preds = (preds == y).float().sum() # number of correct predictions for a single batch\n",
    "    \n",
    "            total_loss += loss.item()\n",
    "            total_accurate_preds += num_accurate_preds.item()\n",
    "    \n",
    "    accuracy = total_accurate_preds/ ds_size\n",
    "    avg_loss = total_loss/ num_batch\n",
    "\n",
    "    #     print(f\"Validation Error: \\n Accuracy: {(100*accuracy):>0.1f}%, Avg loss: {avg_loss:>8f} \\n\")\n",
    "    \n",
    "    return  accuracy, avg_loss\n",
    "\n",
    "# evaluate(valid_dataloader, model, criterion)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "67e72d40",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_history = {\"loss\": [],\"accuracy\": []} # history of accuracy and loss for train set in each epoch\n",
    "validation_history = {\"loss\": [],\"accuracy\": []} # history of accuracy and loss for validation set in each epoch\n",
    "best_model_weights = copy.deepcopy(model.state_dict()) # a deep copy of weights for the best performing model\n",
    "best_loss = float('inf') # initialize best loss to a large value\n",
    "\n",
    "for epoch in range(N_EPOCHS):\n",
    "    print(f\"Epoch {epoch+1}/{N_EPOCHS}\\n-------------------------------\")\n",
    "    \n",
    "    start = time.time()\n",
    "    train_accuracy, train_loss = train(train_dataloader, model, criterion, optimizer)\n",
    "    train_history['loss'].append(train_loss)\n",
    "    train_history['accuracy'].append(train_accuracy)\n",
    "    print('Train accuracy : {}, Train loss : {}'.format(train_accuracy, train_loss))\n",
    "    \n",
    "    validation_accuracy, validation_loss = evaluate(valid_dataloader, model, criterion)\n",
    "    validation_history['loss'].append(validation_loss)\n",
    "    validation_history['accuracy'].append(validation_accuracy)\n",
    "    print('Validation accuracy : {}, Validation loss : {}'.format(validation_accuracy,validation_loss))\n",
    "    \n",
    "    print(\"Execution time for an Epoch : {}\".format(time.time() - start))\n",
    "    \n",
    "    # store best model\n",
    "    if validation_loss < best_loss:\n",
    "        best_loss = validation_loss\n",
    "        best_model_weights = copy.deepcopy(model.state_dict())\n",
    "\n",
    "        ## store weights into a local file\n",
    "        # torch.save(model.state_dict(), weight_path)\n",
    "    \n",
    "print(\"Done!\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7a572151",
   "metadata": {},
   "outputs": [],
   "source": [
    "weight_save_path = './model.pt'\n",
    "torch.save(best_model_weights, weight_save_path)\n",
    "print(\"Saved PyTorch Best Model State to model.pt\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2855ef01",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define transformation that converts a PIL image into PyTorch tensors.\n",
    "test_transformer = transforms.Compose([transforms.ToTensor()])\n",
    "\n",
    "# Define an instance of the custom dataset for the train folder.\n",
    "test_dataset = CustomDataset(submission, test_dir, dataset_type = 'test', transform = test_transformer)\n",
    "\n",
    "img, img_id = test_dataset[24]\n",
    "print(img.shape, torch.min(img), torch.max(img))\n",
    "print(img_id)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7845d57b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define a Dataloader for test dataset\n",
    "test_dataloader = DataLoader(test_dataset, batch_size = BATCH_SIZE, shuffle=False)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4dbfa2cb",
   "metadata": {},
   "outputs": [],
   "source": [
    "# configure model with best model weights \n",
    "\n",
    "# model = BasicCNN().to(device)\n",
    "# model.load_state_dict(torch.load(\"model.pth\", map_location=device))\n",
    "\n",
    "model.load_state_dict(best_model_weights)\n",
    "# print(model.state_dict())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e44b1820",
   "metadata": {},
   "outputs": [],
   "source": [
    "test_ds_size = len(test_dataloader.dataset)\n",
    "cancer_probs = []\n",
    "\n",
    "model.eval()\n",
    "with torch.no_grad():\n",
    "    for batch_idx, (images, image_ids) in enumerate(test_dataloader):\n",
    "        images = images.to(device)\n",
    "        logits = model(images)\n",
    "        preds = F.softmax(logits, dim=1)[:, 1]\n",
    "        preds = torch.flatten(preds).detach().cpu().numpy()\n",
    "        cancer_probs += list(zip(list(image_ids), preds))\n",
    "        \n",
    "        if batch_idx % 100 == 0:\n",
    "            current = batch_idx * len(images)\n",
    "            print(f\"Prediction Done:  [{current}/{test_ds_size}]\")    \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "98d94739",
   "metadata": {},
   "outputs": [],
   "source": [
    "idx = list(map(lambda x: x[0], cancer_probs))\n",
    "prob = list(map(lambda x: x[1], cancer_probs))\n",
    "submission = pd.DataFrame({'id':idx, 'label':prob})\n",
    "\n",
    "submission.to_csv('submission.csv',index=False)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4c1e3603",
   "metadata": {},
   "outputs": [],
   "source": [
    " \n"
   ]
  }
 ],
 "metadata": {},
 "nbformat": 4,
 "nbformat_minor": 5
}

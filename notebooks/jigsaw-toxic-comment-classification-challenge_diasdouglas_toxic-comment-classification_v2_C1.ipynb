{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "173c1e42",
      "metadata": {},
      "outputs": [],
      "source": [
        "import pandas as pd\n",
        "from pathlib import Path"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "90ea0e4f",
      "metadata": {},
      "outputs": [],
      "source": [
        "import numpy as np # linear algebra\n",
        "import pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\n",
        "from sklearn import feature_extraction, linear_model, model_selection, preprocessing\n",
        "from sklearn.ensemble import RandomForestClassifier\n",
        "from sklearn.naive_bayes import MultinomialNB\n",
        "import spacy\n",
        "\n",
        "train_df = pd.read_csv(\"/kaggle/input/jigsaw-toxic-comment-classification-challenge/train.csv.zip\")\n",
        "test_df = pd.read_csv(\"/kaggle/input/jigsaw-toxic-comment-classification-challenge/test.csv.zip\")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "214761bd",
      "metadata": {},
      "outputs": [],
      "source": [
        "train_df.head()\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "a8effd87",
      "metadata": {},
      "outputs": [],
      "source": [
        "test_df.head()\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "d7284723",
      "metadata": {},
      "outputs": [],
      "source": [
        "count_vectorizer = feature_extraction.text.CountVectorizer()\n",
        "\n",
        "example_train_vectors = count_vectorizer.fit_transform(train_df[\"comment_text\"][0:5])\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "33cdd951",
      "metadata": {},
      "outputs": [],
      "source": [
        "print(example_train_vectors[0].todense().shape)\n",
        "print(example_train_vectors[0].todense())\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "1e267181",
      "metadata": {},
      "outputs": [],
      "source": [
        "train_vectors = count_vectorizer.fit_transform(train_df[\"comment_text\"])\n",
        "\n",
        "test_vectors = count_vectorizer.transform(test_df[\"comment_text\"])\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "3661b048",
      "metadata": {},
      "outputs": [],
      "source": [
        "clf = MultinomialNB()\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "efdf105b",
      "metadata": {},
      "outputs": [],
      "source": [
        "scores_toxic = model_selection.cross_val_score(clf, train_vectors, train_df[\"toxic\"], cv=3, scoring=\"roc_auc\")\n",
        "scores_severeToxic = model_selection.cross_val_score(clf, train_vectors, train_df[\"severe_toxic\"], cv=3, scoring=\"roc_auc\")\n",
        "scores_obscene = model_selection.cross_val_score(clf, train_vectors, train_df[\"obscene\"], cv=3, scoring=\"roc_auc\")\n",
        "scores_threat = model_selection.cross_val_score(clf, train_vectors, train_df[\"threat\"], cv=3, scoring=\"roc_auc\")\n",
        "scores_insult = model_selection.cross_val_score(clf, train_vectors, train_df[\"insult\"], cv=3, scoring=\"roc_auc\")\n",
        "scores_identityHate = model_selection.cross_val_score(clf, train_vectors, train_df[\"identity_hate\"], cv=3, scoring=\"roc_auc\")\n",
        "\n",
        "print(scores_toxic)\n",
        "print(scores_severeToxic)\n",
        "print(scores_obscene)\n",
        "print(scores_threat)\n",
        "print(scores_insult)\n",
        "print(scores_identityHate)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "450a9188",
      "metadata": {},
      "outputs": [],
      "source": [
        "def getProbabilities(predicts):\n",
        "    probabilities = []\n",
        "    for probability in predicts:\n",
        "        probabilities.append(probability[1])\n",
        "\n",
        "    return probabilities\n",
        "\n",
        "clf.fit(train_vectors, train_df[\"toxic\"])\n",
        "probsToxic = clf.predict_proba(test_vectors) \n",
        "predToxic = pd.Series(getProbabilities(probsToxic)).apply(lambda x: float(x))\n",
        "\n",
        "clf.fit(train_vectors, train_df[\"severe_toxic\"])\n",
        "probsSevereToxic = clf.predict_proba(test_vectors)\n",
        "predSevereToxic = pd.Series(getProbabilities(probsSevereToxic)).apply(lambda x: float(x))\n",
        "\n",
        "clf.fit(train_vectors, train_df[\"obscene\"])\n",
        "probsObscene = clf.predict_proba(test_vectors)\n",
        "predObscene = pd.Series(getProbabilities(probsObscene)).apply(lambda x: float(x))\n",
        "\n",
        "clf.fit(train_vectors, train_df[\"threat\"])\n",
        "probsThreat = clf.predict_proba(test_vectors)\n",
        "predThreat = pd.Series(getProbabilities(probsThreat)).apply(lambda x: float(x))\n",
        "\n",
        "clf.fit(train_vectors, train_df[\"insult\"])\n",
        "probsInsult = clf.predict_proba(test_vectors)\n",
        "predInsult = pd.Series(getProbabilities(probsInsult)).apply(lambda x: float(x))\n",
        "\n",
        "clf.fit(train_vectors, train_df[\"identity_hate\"])\n",
        "probsIdentityHate = clf.predict_proba(test_vectors)\n",
        "predIdentityHate = pd.Series(getProbabilities(probsIdentityHate)).apply(lambda x: float(x))\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "527c1278",
      "metadata": {},
      "outputs": [],
      "source": [
        "result = pd.read_csv('../input/jigsaw-toxic-comment-classification-challenge/sample_submission.csv.zip')\n",
        "\n",
        "result['toxic'] = predToxic\n",
        "result['severe_toxic'] = predSevereToxic\n",
        "result['obscene'] = predObscene\n",
        "result['threat'] = predThreat\n",
        "result['insult'] = predInsult\n",
        "result['identity_hate'] = predIdentityHate\n",
        "\n",
        "result.to_csv('submission.csv', index=False)\n"
      ]
    }
  ],
  "metadata": {},
  "nbformat": 4,
  "nbformat_minor": 5
}
{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "faddfecd",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from pathlib import Path"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "03a004b2",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "from matplotlib import pyplot as plt\n",
    "%matplotlib inline\n",
    "import re\n",
    "import gensim \n",
    "from gensim.models import Word2Vec\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "90611b5b",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_df = pd.read_csv('../input/train.csv')\n",
    "test_df = pd.read_csv('../input/test.csv')\n",
    "print(train_df.shape, test_df.shape)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "37c1df67",
   "metadata": {},
   "outputs": [],
   "source": [
    "def clean_text(text):\n",
    "    \"\"\"\n",
    "    Convert all to lowercase and remove punctuations\n",
    "    \"\"\"\n",
    "    text = text.lower()\n",
    "    text = re.sub(r'[^\\w\\s]', '', text) # remove everything that isn't word or space\n",
    "    text = re.sub(r'\\_', '', text)      # remove underscore\n",
    "    return text\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b7406370",
   "metadata": {},
   "outputs": [],
   "source": [
    "# clean train_df['text']\n",
    "train_df['text'] = train_df['text'].map(lambda x: clean_text(x))\n",
    "train_df['text'] = train_df['text'].map(lambda x: x.strip().split())\n",
    "train_df.head()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "85d07551",
   "metadata": {},
   "outputs": [],
   "source": [
    "# clean test_df['text']\n",
    "test_df['text'] = test_df['text'].map(lambda x: clean_text(x))\n",
    "test_df['text'] = test_df['text'].map(lambda x: x.strip().split())\n",
    "test_df.head()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a09c8dae",
   "metadata": {},
   "outputs": [],
   "source": [
    "data = []  \n",
    "# iterate through each row in train_df \n",
    "for i in range(len(train_df)):\n",
    "    data.append(train_df['text'][i])\n",
    "for j in range(len(test_df)):\n",
    "    data.append(test_df['text'][j])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e62e817b",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(len(data))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "203e0514",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create Word2Vec model using CBOW (sg=0)\n",
    "# Set min_count to 1 so as to include all words\n",
    "embedding = gensim.models.Word2Vec(data, size=50, window=10, min_count=1, sg=0)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "16a256e5",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(embedding)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c451088c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# train & generate the embeddings\n",
    "embedding.train(data,total_examples=len(data),epochs=30)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7edf9030",
   "metadata": {},
   "outputs": [],
   "source": [
    "words = list(embedding.wv.vocab)\n",
    "print(len(words))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "33ebc988",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(embedding['capered'])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f13959bc",
   "metadata": {},
   "outputs": [],
   "source": [
    "embedding.most_similar('dark', topn=5)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c098cdbf",
   "metadata": {},
   "outputs": [],
   "source": [
    "embedding.most_similar('shocked', topn=5)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d99779ab",
   "metadata": {},
   "outputs": [],
   "source": [
    "embedding.most_similar('sprang', topn=5)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b6ca0e3e",
   "metadata": {},
   "outputs": [],
   "source": [
    "embedding.most_similar('pride', topn=5)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ab42537d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# convert author labels into one-hot encodings\n",
    "train_df['author'] = pd.Categorical(train_df['author'])\n",
    "df_Dummies = pd.get_dummies(train_df['author'], prefix='author')\n",
    "train_df = pd.concat([train_df, df_Dummies], axis=1)\n",
    "# Check the conversion\n",
    "train_df.head()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "05bd3a49",
   "metadata": {},
   "outputs": [],
   "source": [
    "X = train_df['text'].str[:50]\n",
    "Y = train_df[['author_EAP', 'author_HPL', 'author_MWS']].values\n",
    "print(X.shape, X[0], Y.shape, Y[0])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3ace869f",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_test = test_df['text'].str[:50]\n",
    "print(X_test.shape, X_test[0])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "76b17809",
   "metadata": {},
   "outputs": [],
   "source": [
    "def text_to_avg(text):\n",
    "    \"\"\"\n",
    "    Given a list of words, extract the respective GloVe representations\n",
    "    and average the values into a single vector encoding the text meaning.\n",
    "    \"\"\"\n",
    "    # initialize the average word vector\n",
    "    avg = np.zeros((50,))\n",
    "    # average the word vector by looping over the words in text\n",
    "    for w in text:\n",
    "        avg += embedding[w]\n",
    "    avg = avg/len(text)\n",
    "    return avg\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "21f2d8bd",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_avg = np.zeros((X.shape[0], 50)) # initialize X_avg\n",
    "for i in range(X.shape[0]):\n",
    "    X_avg[i] = text_to_avg(X[i])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "81593e4e",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(X_avg.shape)\n",
    "print(X_avg[0])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "053fc941",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_test_avg = np.zeros((X_test.shape[0], 50)) # initialize X_test_avg\n",
    "for i in range(X_test.shape[0]):\n",
    "    X_test_avg[i] = text_to_avg(X_test[i])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d76af169",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(X_test_avg.shape)\n",
    "print(X_test_avg[0])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2cc1dac6",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "X_train, X_dev, Y_train, Y_dev = train_test_split(X_avg, Y, test_size=0.2, random_state=123)\n",
    "print(X_train.shape, Y_train.shape, X_dev.shape, Y_dev.shape)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fa4a41fe",
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras import models\n",
    "from keras import layers\n",
    "\n",
    "model = models.Sequential()\n",
    "model.add(layers.Dense(64, activation='relu', input_shape=(50,)))\n",
    "model.add(layers.Dense(64, activation='relu'))\n",
    "model.add(layers.Dense(3, activation='softmax'))\n",
    "\n",
    "model.summary()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b82516c7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# compile the model\n",
    "model.compile(optimizer='adam', loss='categorical_crossentropy', metrics=['accuracy'])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "97baceea",
   "metadata": {},
   "outputs": [],
   "source": [
    "# train and validate the model\n",
    "epochs = 50\n",
    "history = model.fit(X_train, Y_train, epochs=epochs, batch_size=128, validation_data=(X_dev, Y_dev))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9c0e9e35",
   "metadata": {},
   "outputs": [],
   "source": [
    "# plot and visualise the training and validation losses\n",
    "loss = history.history['loss']\n",
    "dev_loss = history.history['val_loss']\n",
    "epochs = range(1, len(loss) + 1)\n",
    "plt.plot(epochs, loss, 'bo', label='training loss')\n",
    "plt.plot(epochs, dev_loss, 'b', label='validation loss')\n",
    "plt.title('Training and Validation Loss')\n",
    "plt.xlabel('Epochs')\n",
    "plt.ylabel('Loss')\n",
    "plt.legend()\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3f036c94",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = models.Sequential()\n",
    "model.add(layers.Dense(64, activation='relu', input_shape=(50,)))\n",
    "model.add(layers.Dense(64, activation='relu'))\n",
    "model.add(layers.Dense(3, activation='softmax'))\n",
    "# compile the model\n",
    "model.compile(optimizer='adam', loss='categorical_crossentropy', metrics=['accuracy'])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3c5e5d7d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# train the model\n",
    "epochs = 10\n",
    "model.fit(X_avg, Y, epochs=epochs, batch_size=128)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "884b8da5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# predict on test set\n",
    "preds = model.predict(X_test_avg)\n",
    "print(preds.shape)\n",
    "print(preds[7])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1e318452",
   "metadata": {},
   "outputs": [],
   "source": [
    "# set the predicted labels to be the one with the highest probability\n",
    "pred_labels = []\n",
    "for i in range(len(X_test_avg)):\n",
    "    pred_label = np.argmax(preds[i])\n",
    "    pred_labels.append(pred_label)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "08b08ba2",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(pred_labels[7])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f30e9d3d",
   "metadata": {},
   "outputs": [],
   "source": [
    "result = pd.DataFrame(preds, columns=['EAP','HPL','MWS'])\n",
    "result.insert(0, 'id', test_df['id'])\n",
    "result.head()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7545673c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Generate submission file in csv format\n",
    "result.to_csv('submission.csv', index=False, float_format='%.20f')\n"
   ]
  }
 ],
 "metadata": {},
 "nbformat": 4,
 "nbformat_minor": 5
}

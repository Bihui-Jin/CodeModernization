{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c92238fb",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from pathlib import Path"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dc67632b",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import os\n",
    "import cv2\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib.patches as patches\n",
    "import random\n",
    "from sklearn.utils import shuffle\n",
    "from tqdm import tqdm_notebook\n",
    "#https://pythonhosted.org/keras-tqdm/\n",
    "import math\n",
    "from keras_preprocessing.image import ImageDataGenerator\n",
    "import keras\n",
    "from keras.models import Sequential\n",
    "from keras.layers import *\n",
    "from keras.optimizers import RMSprop,Adam\n",
    "import shutil\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a56ed6bf",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_path = \"../input/histopathologic-cancer-detection/train/\"\n",
    "test_path = \"../input/histopathologic-cancer-detection/test/\"\n",
    "\n",
    "print('Training Images:', len(os.listdir(train_path)))\n",
    "print('Testing Images: ', len(os.listdir(test_path)))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b0cb954a",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_data = pd.read_csv('/kaggle/input/histopathologic-cancer-detection/train_labels.csv')\n",
    "train_data['label'].value_counts()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "75f1d4aa",
   "metadata": {},
   "outputs": [],
   "source": [
    "test_data = pd.read_csv(\"../input/histopathologic-cancer-detection/sample_submission.csv\", dtype=str)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3fabcc08",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_data.info()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d4317ded",
   "metadata": {},
   "outputs": [],
   "source": [
    "test_data.info()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e6e98a0b",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_data.head()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2a43f102",
   "metadata": {},
   "outputs": [],
   "source": [
    "test_data.head()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8da449e4",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_data.id = train_data.id + '.tif'\n",
    "test_data.id = test_data.id + '.tif'\n",
    "print(train_data.head())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bdf8b687",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(test_data.head())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "77e40ab5",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_data.shape\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5b47653d",
   "metadata": {},
   "outputs": [],
   "source": [
    "SAMPLE_SIZE = 10000\n",
    "df_normal = train_data[train_data['label'] == 0].sample(SAMPLE_SIZE, random_state = 42)\n",
    "df_cancer = train_data[train_data['label'] == 1].sample(SAMPLE_SIZE, random_state = 42)\n",
    "\n",
    "# Join the two data frame, so that both cancer and normal got in one data frame, \n",
    "## Remember to shuffle the data set , to avaoid biasing\n",
    "df_subset = pd.concat([df_normal, df_cancer], axis=0).reset_index(drop=True)\n",
    "\n",
    "#shuffle the dataframe using shuffle \n",
    "from sklearn.utils import shuffle\n",
    "train_data_subset = shuffle(df_subset)\n",
    "\n",
    "train_data_subset.head()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8d847546",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_data_subset.info()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1dbff211",
   "metadata": {},
   "outputs": [],
   "source": [
    "####We can now split the dataset in trian and spllit####\n",
    "\n",
    "### Here we are split the data into TRAIN and VALIDATION ###\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "def split_data(df_train):\n",
    "        df_train, df_valid = train_test_split(df_train, test_size=0.02, random_state=42,\n",
    "                                     stratify=df_train['label'])\n",
    "        \n",
    "        # We have to set the iindex as 'id', otherwise was giving trouble while uploadiung\n",
    "        train_data_subset.set_index('id', inplace=True)\n",
    "        \n",
    "        train_list = list(df_train['id'])\n",
    "        valid_list = list(df_valid['id'])\n",
    "        \n",
    "        return df_train, df_valid, train_list, valid_list\n",
    "#Lets split it now###\n",
    "df_train, df_valid, train_list, valid_list = split_data(train_data_subset)\n",
    "print('df_train_shape', df_train.shape)\n",
    "print('df_validation_shape', df_valid.shape)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "14243c66",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_train=df_train.astype(str)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "abdadde6",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_valid=df_valid.astype(str)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6e060765",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_valid.info()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2a77b95a",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_train.info()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c0931dd0",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_datagen = ImageDataGenerator(\n",
    "       horizontal_flip=True,\n",
    "       vertical_flip=True,\n",
    "       brightness_range=[0.5, 1.5],\n",
    "       fill_mode='reflect',                               \n",
    "        rotation_range=15,\n",
    "        rescale=1./255,\n",
    "        shear_range=0.2,\n",
    "        zoom_range=0.2)\n",
    "        #validation_split=0.15)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6d81b6fd",
   "metadata": {},
   "outputs": [],
   "source": [
    "validation_datagen = ImageDataGenerator(\n",
    "    rescale=1./255)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1c82b2e2",
   "metadata": {},
   "outputs": [],
   "source": [
    "test_datagen = ImageDataGenerator(\n",
    "       #horizontal_flip=True,\n",
    "       #vertical_flip=True,\n",
    "       #brightness_range=[0.5, 1.5],\n",
    "       #fill_mode='reflect',                               \n",
    "        #rotation_range=15,\n",
    "        rescale=1./255)\n",
    "        #shear_range=0.2,\n",
    "        #zoom_range=0.2)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "77fbb804",
   "metadata": {},
   "outputs": [],
   "source": [
    "tr_size = 19600\n",
    "va_size = 400\n",
    "bs = 64\n",
    "\n",
    "tr_steps = math.ceil(tr_size / bs)\n",
    "va_steps = math.ceil(va_size / bs)\n",
    "\n",
    "#math.ceil() function returns the smallest integral value greater than the number. \n",
    "#If number is already integer, same number is returned.\n",
    "\n",
    "train_generator = train_datagen.flow_from_dataframe(\n",
    "    dataframe = df_train,\n",
    "    directory = train_path,\n",
    "    x_col = \"id\",\n",
    "    y_col = \"label\",\n",
    "    #subset = \"training\",\n",
    "    batch_size = bs,\n",
    "    seed = 1,\n",
    "    shuffle = True,\n",
    "    class_mode = \"categorical\",\n",
    "    target_size = (96,96))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "faa3f7d7",
   "metadata": {},
   "outputs": [],
   "source": [
    "valid_generator = validation_datagen.flow_from_dataframe(\n",
    "    dataframe = df_valid,\n",
    "    directory = train_path,\n",
    "    x_col = \"id\",\n",
    "    y_col = \"label\",\n",
    "    #subset = \"validation\",\n",
    "    batch_size = bs,\n",
    "    seed = 1,\n",
    "    shuffle = True,\n",
    "    class_mode = \"categorical\",\n",
    "    target_size = (96,96))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "eabcec33",
   "metadata": {},
   "outputs": [],
   "source": [
    "test_generator = test_datagen.flow_from_dataframe(\n",
    "    dataframe = test_data,\n",
    "    directory = test_path,\n",
    "    x_col = \"id\",\n",
    "    y_col = None,\n",
    "    batch_size = 32,\n",
    "    seed = 1,\n",
    "    shuffle = False,\n",
    "    class_mode = None,\n",
    "    target_size = (96,96))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "be2e0211",
   "metadata": {},
   "outputs": [],
   "source": [
    "def training_images(seed):\n",
    "    np.random.seed(seed)\n",
    "    train_generator.reset()\n",
    "    imgs, labels = next(train_generator)\n",
    "    tr_labels = np.argmax(labels, axis=1)\n",
    "    \n",
    "    plt.figure(figsize=(12,12))\n",
    "    for i in range(16):\n",
    "        text_class = labels[i]\n",
    "        plt.subplot(4,4,i+1)\n",
    "        plt.imshow(imgs[i,:,:,:])\n",
    "        if(text_class[0] == 0):\n",
    "            plt.text(0, -5, 'Positive', color='r')\n",
    "        else:\n",
    "            plt.text(0, -5, 'Negative', color='b')\n",
    "        plt.axis('off')\n",
    "    plt.show()\n",
    "\n",
    "training_images(1)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "85ed13d3",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = Sequential()\n",
    "model.add(Conv2D(filters = 16, kernel_size = 3, padding = 'same', activation = 'relu', input_shape = (96, 96, 3)))\n",
    "model.add(Conv2D(filters = 16, kernel_size = 3, padding = 'same', activation = 'relu'))\n",
    "model.add(Conv2D(filters = 16, kernel_size = 3, padding = 'same', activation = 'relu'))\n",
    "model.add(Dropout(0.2))\n",
    "model.add(MaxPooling2D(pool_size = 3))\n",
    "model.add(BatchNormalization())\n",
    "\n",
    "model.add(Conv2D(filters = 32, kernel_size = 3, padding = 'same', activation = 'relu'))\n",
    "model.add(Conv2D(filters = 32, kernel_size = 3, padding = 'same', activation = 'relu'))\n",
    "model.add(Conv2D(filters = 32, kernel_size = 3, padding = 'same', activation = 'relu'))\n",
    "model.add(Dropout(0.2))\n",
    "model.add(MaxPooling2D(pool_size = 3))\n",
    "model.add(BatchNormalization())\n",
    "\n",
    "model.add(Conv2D(filters = 64, kernel_size = 3, padding = 'same', activation = 'relu'))\n",
    "model.add(Conv2D(filters = 64, kernel_size = 3, padding = 'same', activation = 'relu'))\n",
    "model.add(Conv2D(filters = 64, kernel_size = 3, padding = 'same', activation = 'relu'))\n",
    "model.add(Dropout(0.2))\n",
    "model.add(MaxPooling2D(pool_size = 3))\n",
    "model.add(BatchNormalization())\n",
    "\n",
    "model.add(Conv2D(filters = 128, kernel_size = 3, padding = 'same', activation = 'relu'))\n",
    "model.add(Conv2D(filters = 128, kernel_size = 3, padding = 'same', activation = 'relu'))\n",
    "model.add(Conv2D(filters = 128, kernel_size = 3, padding = 'same', activation = 'relu'))\n",
    "model.add(Dropout(0.3))\n",
    "model.add(BatchNormalization())\n",
    "\n",
    "\n",
    "model.add(Flatten())\n",
    "model.add(Dense(128, activation='relu'))\n",
    "model.add(Dropout(0.2))\n",
    "model.add(Dense(2, activation = 'sigmoid'))\n",
    "model.summary()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "58eb0bfe",
   "metadata": {},
   "outputs": [],
   "source": [
    " \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1bebb693",
   "metadata": {},
   "outputs": [],
   "source": [
    "epochs = 5\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7a240c70",
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "\n",
    "optimizer=Adam(learning_rate=0.000001,beta_1=0.9,beta_2=0.999,epsilon=1e-08)\n",
    "\n",
    "model.compile(optimizer=optimizer,loss=['binary_crossentropy'],metrics=['accuracy'])\n",
    "\n",
    "h4 = model.fit_generator(train_generator, steps_per_epoch=tr_steps, epochs=5, validation_data=valid_generator, validation_steps=va_steps, verbose=1)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a2ba18e1",
   "metadata": {},
   "outputs": [],
   "source": [
    "model.save('cnn_v01.h4')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4cf1f68c",
   "metadata": {},
   "outputs": [],
   "source": [
    "test_pred = model.predict_generator(test_generator)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "669070af",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(test_pred[:5])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ddc0432e",
   "metadata": {},
   "outputs": [],
   "source": [
    "test_filenames = test_generator.filenames\n",
    "test_filenames[ :5]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f8c742d9",
   "metadata": {},
   "outputs": [],
   "source": [
    "test_filenames = [x.split(\".\")[0] for x in test_filenames]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "267b7c4f",
   "metadata": {},
   "outputs": [],
   "source": [
    "test_filenames[ :5]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "02282317",
   "metadata": {},
   "outputs": [],
   "source": [
    "len(test_filenames)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "13590869",
   "metadata": {},
   "outputs": [],
   "source": [
    "classes = list(np.argmax(test_pred, axis=1))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4b43699f",
   "metadata": {},
   "outputs": [],
   "source": [
    "classes[:5]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a7350bec",
   "metadata": {},
   "outputs": [],
   "source": [
    "submission = pd.DataFrame({'id':test_filenames,\n",
    "     'label':classes\n",
    "    })\n",
    "submission.head()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dbc6ef94",
   "metadata": {},
   "outputs": [],
   "source": [
    "submission.to_csv(\"submission.csv\", index = False)\n"
   ]
  }
 ],
 "metadata": {},
 "nbformat": 4,
 "nbformat_minor": 5
}

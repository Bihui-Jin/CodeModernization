{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "7a1266c3",
      "metadata": {},
      "outputs": [],
      "source": [
        "import pandas as pd\n",
        "from pathlib import Path"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "b86bc7bb",
      "metadata": {},
      "outputs": [],
      "source": [
        "##from INTERNET import everything xxxxD/\n",
        "import numpy as np # linear algebra\n",
        "import pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\n",
        "import pandas as pd       \n",
        "import matplotlib as mat\n",
        "import matplotlib.pyplot as plt    \n",
        "import seaborn as sns\n",
        "import random\n",
        "import os\n",
        "import gc\n",
        "from sklearn.pipeline import Pipeline\n",
        "from sklearn.model_selection import cross_val_score\n",
        "from sklearn.model_selection import StratifiedKFold\n",
        "from sklearn.metrics import log_loss , accuracy_score\n",
        "from sklearn.preprocessing import StandardScaler ,LabelEncoder, RobustScaler ,QuantileTransformer ,MinMaxScaler\n",
        "import tensorflow as tf \n",
        "from tensorflow import keras\n",
        "import tensorflow_addons as tfa\n",
        "import tensorflow.keras.backend as K \n",
        "from tensorflow.keras import layers\n",
        "from tensorflow.keras.utils import to_categorical ,plot_model\n",
        "from tensorflow.keras import callbacks\n",
        "from tensorflow.keras.layers import Dense, Dropout, Input, InputLayer, Flatten, LayerNormalization, BatchNormalization\n",
        "from tensorflow.random import set_seed\n",
        "set_seed(42)\n",
        "import warnings\n",
        "warnings.filterwarnings('ignore')\n",
        "sns.set_style(\"whitegrid\")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "aee7eca1",
      "metadata": {},
      "outputs": [],
      "source": [
        "train_data = pd.read_csv(\"../input/tabular-playground-series-dec-2021/train.csv\")\n",
        "test_data= pd.read_csv(\"../input/tabular-playground-series-dec-2021/test.csv\")\n",
        "sample = pd.read_csv(\"../input/tabular-playground-series-dec-2021/sample_submission.csv\")\n",
        "train_data =train_data[train_data.Cover_Type != 5] # drop class 5 \n",
        "train= train_data.drop('Id', axis=1) # drop unused id \n",
        "test= test_data.drop('Id', axis=1)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "2e6dc162",
      "metadata": {},
      "outputs": [],
      "source": [
        "train.head(3)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "2e5dfb34",
      "metadata": {},
      "outputs": [],
      "source": [
        "train.describe().style.background_gradient(cmap='RdPu')\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "9bd49981",
      "metadata": {},
      "outputs": [],
      "source": [
        "# variables variaition   \n",
        "df_var=train.var().reset_index()\n",
        "df_var.columns =['feature', 'variation']\n",
        "df_var.sort_values(\"variation\",ascending = True)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "d8a2f2b3",
      "metadata": {},
      "outputs": [],
      "source": [
        "# Correlation matrix\n",
        "corrMatrix =train.corr(method='pearson', min_periods=1)\n",
        "corrMatrix.style.background_gradient(axis=None)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "7a48ba9b",
      "metadata": {},
      "outputs": [],
      "source": [
        "cor_targ = train.corrwith(train[\"Cover_Type\"]).reset_index()\n",
        "cor_targ.columns =['feature', 'CorrelatioWithTarget']\n",
        "cor_targ.sort_values('CorrelatioWithTarget',ascending = False)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "18dabcac",
      "metadata": {},
      "outputs": [],
      "source": [
        "ax = plt.figure(figsize=(12, 6))\n",
        "cover_type= train['Cover_Type'].value_counts().sort_index()\n",
        "sns.barplot(x=cover_type.index, y=cover_type,palette=\"BuPu_r\")\n",
        "plt.show()\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "1f9fc4a6",
      "metadata": {},
      "outputs": [],
      "source": [
        "test.head(3)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "580470cc",
      "metadata": {},
      "outputs": [],
      "source": [
        "test.describe().style.background_gradient(axis =1)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "f8f0cac1",
      "metadata": {},
      "outputs": [],
      "source": [
        "plt.figure(figsize=(15,8))\n",
        "features = train.columns.values[0:54]\n",
        "sns.distplot(train[features].mean(axis=1),color=\"red\", kde=True,bins=120, label='train')\n",
        "sns.distplot(test[features].mean(axis=1),color=\"darkblue\", kde=True,bins=120, label='test')\n",
        "plt.title(\"Distribution of mean values per row in the train and test data\")\n",
        "plt.legend()\n",
        "plt.show()\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "241f9f23",
      "metadata": {},
      "outputs": [],
      "source": [
        "plt.figure(figsize=(15,5))\n",
        "sns.distplot(train[features].mean(axis=0),color=\"orange\",kde=True,bins=120, label='train')\n",
        "sns.distplot(test[features].mean(axis=0),color=\"blue\", kde=True,bins=120, label='test')\n",
        "plt.title(\"Distribution of mean values per column in the train and test set\")\n",
        "plt.legend()\n",
        "plt.show()\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "f9219a60",
      "metadata": {},
      "outputs": [],
      "source": [
        "plt.figure(figsize=(15,5))\n",
        "sns.distplot(train[features].std(axis=1),color=\"#2F4F4F\", kde=True,bins=120, label='train')\n",
        "sns.distplot(test[features].std(axis=1),color=\"#FF6347\", kde=True,bins=120, label='test')\n",
        "plt.title(\"Distribution of std per row in the train and test data \")\n",
        "plt.legend()\n",
        "plt.show()\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "eb8f8d2e",
      "metadata": {},
      "outputs": [],
      "source": [
        "plt.figure(figsize=(15,5))\n",
        "sns.distplot(train[features].std(axis=0),color=\"#778899\",kde=True,bins=120, label='train')\n",
        "sns.distplot(test[features].std(axis=0),color=\"#800080\", kde=True,bins=120, label='test')\n",
        "plt.title(\"Distribution of std per column in the train and test data\")\n",
        "plt.legend()\n",
        "plt.show()\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "94734b2f",
      "metadata": {},
      "outputs": [],
      "source": [
        "i = 1\n",
        "plt.figure()\n",
        "fig, ax = plt.subplots(figsize=(30, 30))\n",
        "for feature in features:\n",
        "    plt.subplot(14,4,i)\n",
        "    sns.distplot(train[feature],color=\"blue\", kde=True,bins=120, label='train')\n",
        "    sns.distplot(test[feature],color=\"orange\", kde=True,bins=120, label='test')\n",
        "    i += 1\n",
        "plt.title(\"Feature Distribution in train and test data\")  \n",
        "plt.legend()\n",
        "plt.show()\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "782668cf",
      "metadata": {},
      "outputs": [],
      "source": [
        "# remove unuseful features\n",
        "train = train.drop([ 'Soil_Type7', 'Soil_Type15','Soil_Type1'], axis=1)\n",
        "test= test.drop(['Soil_Type7', 'Soil_Type15','Soil_Type1'], axis=1)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "983a8390",
      "metadata": {},
      "outputs": [],
      "source": [
        "y_target = train[\"Cover_Type\"].copy() ##target variable \n",
        "X_train = train.copy().drop(\"Cover_Type\",axis = 1) ##train data \n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "bd88c273",
      "metadata": {},
      "outputs": [],
      "source": [
        "def reduce_mem_usage(df, verbose=True):\n",
        "    numerics = ['int16', 'int32', 'int64', 'float16', 'float32', 'float64']\n",
        "    start_mem = df.memory_usage().sum() / 1024**2\n",
        "\n",
        "    for col in df.columns:\n",
        "        col_type = df[col].dtypes\n",
        "\n",
        "        if col_type in numerics:\n",
        "            c_min = df[col].min()\n",
        "            c_max = df[col].max()\n",
        "\n",
        "            if str(col_type)[:3] == 'int':\n",
        "                if c_min > np.iinfo(np.int8).min and c_max < np.iinfo(np.int8).max:\n",
        "                    df[col] = df[col].astype(np.int8)\n",
        "                elif c_min > np.iinfo(np.int16).min and c_max < np.iinfo(np.int16).max:\n",
        "                    df[col] = df[col].astype(np.int16)\n",
        "                elif c_min > np.iinfo(np.int32).min and c_max < np.iinfo(np.int32).max:\n",
        "                    df[col] = df[col].astype(np.int32)\n",
        "                elif c_min > np.iinfo(np.int64).min and c_max < np.iinfo(np.int64).max:\n",
        "                    df[col] = df[col].astype(np.int64)  \n",
        "            else:\n",
        "                if c_min > np.finfo(np.float32).min and c_max < np.finfo(np.float32).max:\n",
        "                    df[col] = df[col].astype(np.float32)\n",
        "                else:\n",
        "                    df[col] = df[col].astype(np.float64)\n",
        "\n",
        "    end_mem = df.memory_usage().sum() / 1024**2\n",
        "\n",
        "    if verbose:\n",
        "        print('Mem. usage decreased to {:5.2f} Mb ({:.1f}% reduction)'.format(end_mem, 100 * (start_mem - end_mem) / start_mem))\n",
        " \n",
        "    return df\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "d7cfd0a4",
      "metadata": {},
      "outputs": [],
      "source": [
        "%%time\n",
        "train_df = reduce_mem_usage(X_train)\n",
        "test_df = reduce_mem_usage(test)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "9c45902f",
      "metadata": {},
      "outputs": [],
      "source": [
        "def stat_features(df):\n",
        "    #df['f_mean'] = df.mean(axis=1)\n",
        "    #df['f_std']  = df.std(axis=1)\n",
        "    df['f_skew'] = df.skew(axis=1)\n",
        "    df['r_sum'] = df.sum(axis=1)\n",
        "    return df\n",
        "\n",
        "X_train = stat_features(train_df)\n",
        "test = stat_features(test_df)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "f104f3e9",
      "metadata": {},
      "outputs": [],
      "source": [
        "### delet it \n",
        "del train_data \n",
        "del test_data \n",
        "del test_df \n",
        "del train_df \n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "0d4fd1f0",
      "metadata": {},
      "outputs": [],
      "source": [
        "num_cols = [\n",
        "    \"Elevation\",\n",
        "    \"Aspect\",\n",
        "    \"Slope\",\n",
        "    \"Horizontal_Distance_To_Hydrology\",\n",
        "    \"Vertical_Distance_To_Hydrology\",\n",
        "     \"Horizontal_Distance_To_Roadways\",\n",
        "    \"Hillshade_9am\",\n",
        "    \"Hillshade_Noon\",\n",
        "    \"Hillshade_3pm\",\n",
        "    \"Horizontal_Distance_To_Fire_Points\",\n",
        "    \"f_skew\" ,\n",
        "    \"r_sum\"   \n",
        "]\n",
        "scaler =  MinMaxScaler(feature_range=(0, 150))\n",
        "X_train[num_cols] = scaler.fit_transform(X_train[num_cols])\n",
        "test[num_cols]= scaler.transform(test[num_cols])\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "a485cc99",
      "metadata": {},
      "outputs": [],
      "source": [
        "### label encoder for target \n",
        "label_encod = LabelEncoder()\n",
        "y_encoded =label_encod.fit_transform(y_target)\n",
        "# categorical transofrm for target\n",
        "#y_cat =to_categorical(y_encoded)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "47fc0ffb",
      "metadata": {},
      "outputs": [],
      "source": [
        "print(y_encoded.shape,y_target.shape,X_train.shape,test.shape )\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "0954746a",
      "metadata": {},
      "outputs": [],
      "source": [
        "n_classes = 6\n",
        "def get_model(X_train):\n",
        "    inputs = layers.Input(shape = (X_train.shape[1],))\n",
        "    embed = layers.Embedding(151,6)(inputs)\n",
        "    embed = layers.Flatten()(embed)\n",
        "    dropout = layers.AlphaDropout(0.2)(embed)\n",
        "    dense = layers.Dense(units=350, kernel_initializer=\"lecun_normal\", activation=\"selu\")(dropout)\n",
        "    hidden = tfa.layers.WeightNormalization(layers.Dense(units=254, activation='selu', kernel_initializer=\"lecun_normal\"))(dense)    \n",
        "    dropout1= layers.AlphaDropout(0.2)(hidden)\n",
        "    hidden1 = tfa.layers.WeightNormalization(layers.Dense(units=128, activation='selu'))(dropout1)\n",
        "    dropout2 = layers.AlphaDropout(0.3)(layers.Concatenate()([hidden1, dropout1]))\n",
        "    hidden2 = tfa.layers.WeightNormalization(layers.Dense(units=64, activation='elu'))(layers.Concatenate()([dropout2, hidden]))\n",
        "    dropout3 =layers.AlphaDropout(0.3)(layers.Concatenate()([hidden2, hidden1]))\n",
        "    hidden3 = tfa.layers.WeightNormalization(layers.Dense(units=32, activation='elu'))(layers.Concatenate()([dropout3, hidden2]))\n",
        "    hideen4 = tfa.layers.WeightNormalization(layers.Dense(units=32, activation='elu'))(layers.Concatenate()([hidden3, dropout3]))\n",
        "    output = layers.Dense(units=n_classes, activation = 'softmax')(hidden3)\n",
        "\n",
        "    model = keras.Model(inputs=inputs, outputs=output, name=\"resnet_model\")\n",
        "\n",
        "    return model\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "af2a99d9",
      "metadata": {},
      "outputs": [],
      "source": [
        "##model parameters\n",
        "early_stopping = callbacks.EarlyStopping(patience=5, min_delta=1e-4, restore_best_weights=True)\n",
        "reduce_lr = callbacks.ReduceLROnPlateau(factor = 0.5, patience = 5, verbose = 0) \n",
        "optimizer = keras.optimizers.Adam(learning_rate=0.03)\n",
        "metrics=['acc']\n",
        "loss= \"sparse_categorical_crossentropy\"\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "c2f1651c",
      "metadata": {},
      "outputs": [],
      "source": [
        "model = get_model(X_train)\n",
        "model.compile(loss=loss, optimizer = optimizer, metrics=metrics)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "9d74d4a8",
      "metadata": {},
      "outputs": [],
      "source": [
        "plot_model(\n",
        "    model,\n",
        "    show_shapes=True,\n",
        "    show_layer_names=True\n",
        ")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "310a610b",
      "metadata": {},
      "outputs": [],
      "source": [
        "model.summary()\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "0ca9f425",
      "metadata": {},
      "outputs": [],
      "source": [
        "X_train= X_train.values\n",
        "epoch = 150\n",
        "batch_size = 2048\n",
        "val_score = []\n",
        "test_pred = np.zeros((1, 1))\n",
        "N_F = 5  #use 5 fols\n",
        "SKF= StratifiedKFold(n_splits=N_F, shuffle=True, random_state=42)\n",
        "for fold, (idx_train, idx_valid) in enumerate(SKF.split(X_train,y_encoded)):\n",
        "        X_tr, y_tr = X_train[idx_train], y_encoded[idx_train]\n",
        "        X_val, y_val = X_train[idx_valid], y_encoded[idx_valid]\n",
        "        K.clear_session()\n",
        "        model = get_model(X_tr)\n",
        "        model.compile(loss=loss, optimizer = optimizer, metrics=metrics)\n",
        "        model.fit(X_tr, y_tr,\n",
        "              batch_size = batch_size, epochs =epoch,\n",
        "              validation_data=(X_val, y_val),\n",
        "              callbacks=[early_stopping, reduce_lr], verbose=0)\n",
        "        val_pred = np.argmax(model.predict(X_val), axis=1)\n",
        "        score = accuracy_score(y_val, val_pred)\n",
        "        val_score.append(score)\n",
        "        test_pred = test_pred + model.predict(test)\n",
        "        print(f\"FOLD {fold:d}: validation accuracy is {score:.6f}\")\n",
        "        _ = gc.collect()\n",
        "print (\"**************************************************\")\n",
        "print(f\"Mean Validation Accuracy is : {np.mean(val_score)}\")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "d3714932",
      "metadata": {},
      "outputs": [],
      "source": [
        "predictions = np.argmax(test_pred, axis=1)\n",
        "predictions = label_encod.inverse_transform(predictions)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "c659acf8",
      "metadata": {},
      "outputs": [],
      "source": [
        "sample['Cover_Type'] = predictions\n",
        "sample.to_csv('resnet.csv', index=False)\n",
        "sample\n"
      ]
    }
  ],
  "metadata": {},
  "nbformat": 4,
  "nbformat_minor": 5
}
{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "59ebcf7a",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from pathlib import Path"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b082a562",
   "metadata": {},
   "outputs": [],
   "source": [
    "import time\n",
    "from datetime import datetime\n",
    "\n",
    "#measure notebook running time\n",
    "start_time = time.time()\n",
    "\n",
    "%matplotlib inline\n",
    "\n",
    "import os, warnings\n",
    "import numpy as np \n",
    "from numpy.random import seed\n",
    "import pandas as pd \n",
    "from matplotlib import pyplot as plt\n",
    "import seaborn as sns\n",
    "\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense, Input, Dropout, BatchNormalization\n",
    "from keras.callbacks import EarlyStopping, ModelCheckpoint\n",
    "from keras import metrics\n",
    "import tensorflow as tf\n",
    "import xgboost as xgb\n",
    "import lightgbm as lgb\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.ensemble import RandomForestClassifier, AdaBoostClassifier, GradientBoostingClassifier, ExtraTreesClassifier\n",
    "from sklearn.linear_model import LogisticRegression, SGDClassifier\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.cluster import KMeans\n",
    "from sklearn.model_selection import RandomizedSearchCV, GridSearchCV, cross_val_score\n",
    "from sklearn.preprocessing import StandardScaler, MinMaxScaler\n",
    "from sklearn.compose import ColumnTransformer\n",
    "from sklearn.ensemble import VotingClassifier\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import confusion_matrix, ConfusionMatrixDisplay, plot_confusion_matrix, precision_score,recall_score, f1_score, classification_report, accuracy_score\n",
    "from sklearn.decomposition import PCA\n",
    "from sklearn.manifold import TSNE\n",
    "from category_encoders import MEstimateEncoder\n",
    "\n",
    "sns.set(style='white', context='notebook', palette='deep', rc={'figure.figsize':(10,8)})\n",
    "print(\"loaded ...\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fd1bb3a9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Reproducibility\n",
    "def set_seed(sd):\n",
    "    seed(sd)\n",
    "    np.random.seed(sd)\n",
    "    tf.random.set_seed(sd)\n",
    "    os.environ['PYTHONHASHSEED'] = str(sd)\n",
    "    os.environ['TF_DETERMINISTIC_OPS'] = '1'\n",
    "RandomSeed = 13\n",
    "set_seed(RandomSeed)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3a15cd53",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_data = pd.read_csv('/kaggle/input/tabular-playground-series-may-2022/train.csv')\n",
    "test_data = pd.read_csv('/kaggle/input/tabular-playground-series-may-2022/test.csv')\n",
    "test_data['target'] = -1\n",
    "train_data['Set'] = \"Train\"\n",
    "test_data['Set'] = \"Test\"\n",
    "DATA = train_data.append(test_data)\n",
    "DATA.reset_index(inplace=True)\n",
    "DATA.info()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7de4877f",
   "metadata": {},
   "outputs": [],
   "source": [
    "features = [f for f in DATA.columns if \"f_\" in f]\n",
    "float_features = [f for f in features if DATA[f].dtype == \"float64\"]\n",
    "int_features = [f for f in features if DATA[f].dtype == \"int64\"]\n",
    "str_features = [f for f in features if DATA[f].dtype == \"object\"]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c34f1034",
   "metadata": {},
   "outputs": [],
   "source": [
    "DATA[int_features].describe()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b8f21afc",
   "metadata": {},
   "outputs": [],
   "source": [
    "DATA[float_features].describe()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "381aa7d0",
   "metadata": {},
   "outputs": [],
   "source": [
    "scaler = MinMaxScaler()\n",
    "DATA[[*float_features,*int_features]] = scaler.fit_transform(DATA[[*float_features,*int_features]])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9d0c143d",
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_hist(features, title):\n",
    "    N_cols = 4\n",
    "    col_width = 8\n",
    "    N_rows = round(len(features) / N_cols + 0.49)\n",
    "    fig, axs = plt.subplots(nrows = N_rows, ncols=N_cols, figsize=(col_width * N_cols, N_rows * col_width))\n",
    "    for i,f in enumerate(features):\n",
    "        axs[i//N_cols, i%N_cols].hist(DATA[DATA.Set == 'Train'][f], bins=20);\n",
    "        axs[i//N_cols, i%N_cols].set_title(f)\n",
    "        axs[i//N_cols, i%N_cols].legend();\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9d321717",
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "plot_hist(float_features, 'float_features')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fe785395",
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "plot_hist(int_features, 'int_features')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "903a2515",
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, ax = plt.subplots(figsize=(20,20)) \n",
    "ax = sns.heatmap(DATA[DATA.Set == 'Train'][[*int_features,'target']].corr(),annot=True, fmt = \".2f\", cmap = \"coolwarm\");\n",
    "ax.set_title(\"Target -  correlation to int features\");\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bf18c355",
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, ax = plt.subplots(figsize=(20,20)) \n",
    "ax = sns.heatmap(DATA[DATA.Set == 'Train'][[*float_features,'target']].corr(),annot=True, fmt = \".2f\", cmap = \"coolwarm\");\n",
    "ax.set_title(\"Target -  correlation to float features\");\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6aed4a6d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# pca = PCA(2)\n",
    "# X_PCA = pca.fit_transform(DATA.loc[:, [*float_features, *int_features]])\n",
    "# PCA_component_names = [f\"PC{i+1}\" for i in range(X_PCA.shape[1])]\n",
    "# X_PCA = pd.DataFrame(X_PCA, columns=PCA_component_names)\n",
    "# X_PCA.head()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cdb038b3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# DATA_PCA = X_PCA.copy()\n",
    "# DATA_PCA['target'] = DATA['target']\n",
    "# DATA_PCA=DATA_PCA[DATA_PCA['target'] != -1]\n",
    "# pca.explained_variance_ratio_\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ca9502b6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# %%time\n",
    "# sns.scatterplot(data = DATA_PCA, x = \"PC1\", y= \"PC2\", hue = 'target');\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3a561faf",
   "metadata": {},
   "outputs": [],
   "source": [
    "# fig, axs = plt.subplots(1, 2)\n",
    "# n = pca.n_components_\n",
    "# grid = np.arange(1, n + 1)\n",
    "# # Explained variance\n",
    "# evr = pca.explained_variance_ratio_\n",
    "# axs[0].bar(grid, evr)\n",
    "# axs[0].set(xlabel=\"Component\", title=\"% Explained Variance\", ylim=(0.0, 1.0))\n",
    "# # Cumulative Variance\n",
    "# cv = np.cumsum(evr)\n",
    "# axs[1].plot(np.r_[0, grid], np.r_[0, cv], \"o-\")\n",
    "# axs[1].set(xlabel=\"Component\", title=\"% Cumulative Variance\", ylim=(0.0, 1.0))\n",
    "# # Set up figure\n",
    "# fig.set(figwidth=8, dpi=100);\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "00295177",
   "metadata": {},
   "outputs": [],
   "source": [
    "# loadings = pd.DataFrame(\n",
    "#         pca.components_.T,  # transpose the matrix of loadings\n",
    "#         columns=PCA_component_names,  # so the columns are the principal components\n",
    "#         index=DATA.loc[:, [*float_features, *int_features]].columns,  # and the rows are the original features\n",
    "#     )\n",
    "# loadings\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "87acb7f1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# MELT = pd.melt(DATA[DATA.Set == 'Train'][[*float_features,*int_features,'target']], value_vars = [*float_features,*int_features],id_vars= 'target')\n",
    "# MELT.head()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d3e37b62",
   "metadata": {},
   "outputs": [],
   "source": [
    "# %%time\n",
    "# ax = sns.displot(MELT, x='value', hue='target', col='variable', kind='kde',col_wrap= 5);\n",
    "# ax.set(xlim = (-10,10), ylim = (0, 0.05));\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "eda03dc9",
   "metadata": {},
   "outputs": [],
   "source": [
    "DATA[str_features].head()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cb92e41a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# EXPLORE = pd.DataFrame()\n",
    "# EXPLORE['String'] = DATA[str_features].copy()\n",
    "# EXPLORE['len'] = EXPLORE['String'].apply(len)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0ba33220",
   "metadata": {},
   "outputs": [],
   "source": [
    "TRAIN = DATA[DATA.Set == 'Train']\n",
    "TEST = DATA[DATA.Set == 'Test'][[*float_features, *int_features]]\n",
    "X = TRAIN[[*float_features, *int_features]]\n",
    "y = TRAIN.target\n",
    "X_train, X_test, y_train, y_test = train_test_split(X,y, test_size = 0.25, random_state = RandomSeed, stratify=y)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "daadcb41",
   "metadata": {},
   "outputs": [],
   "source": [
    "def CM(y_test, val_pred, title):\n",
    "    labels = [0,1]\n",
    "    cm = confusion_matrix(y_test, val_pred, normalize = 'pred')\n",
    "    cm_train = confusion_matrix(y_train, train_pred, normalize = 'pred')\n",
    "    fig, (ax1, ax2) = plt.subplots(1, 2, figsize=(14,8))\n",
    "    disp_train = ConfusionMatrixDisplay(confusion_matrix=cm_train, display_labels= labels);\n",
    "    disp_train.plot(ax=ax1, values_format='.1%', xticks_rotation='horizontal');\n",
    "    disp_train.ax_.set_title('Train set', {'fontsize':20});\n",
    "\n",
    "    disp_test = ConfusionMatrixDisplay(confusion_matrix=cm, display_labels= labels);\n",
    "    disp_test.plot(ax=ax2, values_format='.1%', xticks_rotation='horizontal');\n",
    "    disp_test.ax_.set_title('Validation set',{'fontsize':20});\n",
    "    fig.suptitle(title, fontsize=16);\n",
    "    \n",
    "def IMP(model, label, columns = X_train.columns):\n",
    "    features = {}\n",
    "    for feature, importance in zip(columns, model.feature_importances_):\n",
    "        features[feature] = importance\n",
    "\n",
    "    importances = pd.DataFrame({label:features})\n",
    "    importances.sort_values(label, ascending = True, inplace=True)\n",
    "    importances[:10].plot.barh()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "691019a8",
   "metadata": {},
   "outputs": [],
   "source": [
    "rf_params = {\n",
    "    'n_jobs':-1,\n",
    "    'random_state': RandomSeed,\n",
    "    'n_estimators': 100,\n",
    "    'max_depth': None,\n",
    "    'min_samples_split': 2,\n",
    "    'min_samples_leaf': 1,\n",
    "    'max_features': 'auto',\n",
    "    'max_samples': None\n",
    "}\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ae433bae",
   "metadata": {},
   "outputs": [],
   "source": [
    "rf_grid = {\n",
    "    'max_depth': [None],\n",
    "    'min_samples_split': [2],\n",
    "    'min_samples_leaf':[1],\n",
    "    'max_features': ['auto'],\n",
    "    'max_samples': [None, 0.9],\n",
    "    'n_estimators': [100],\n",
    "}\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "02065166",
   "metadata": {},
   "outputs": [],
   "source": [
    "# %%time\n",
    "# rf_clf = RandomForestClassifier(**rf_params)\n",
    "# rf_grid_clf = GridSearchCV(rf_clf, rf_grid, cv=3, scoring= \"f1_micro\")\n",
    "# rf_grid_clf.fit(X_train, y_train)\n",
    "# print(rf_grid_clf.best_estimator_)\n",
    "# print(rf_grid_clf.best_params_)\n",
    "# print(rf_grid_clf.best_score_)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "190ad21a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# print(\"Reference score:\",0.8214888888888888, \n",
    "#       \"{'max_depth': None, 'max_features': 'auto', 'max_samples': None, 'min_samples_leaf': 1, 'min_samples_split': 2, 'n_estimators': 100}\",\n",
    "#       \"\\n\")\n",
    "\n",
    "# rf_scores = pd.DataFrame(rf_grid_clf.cv_results_['params'])\n",
    "# rf_scores['results'] = rf_grid_clf.cv_results_['mean_test_score']\n",
    "# rf_scores['std'] = rf_grid_clf.cv_results_['std_test_score']\n",
    "# rf_scores = rf_scores.sort_values('results', ascending=False)\n",
    "# rf_scores\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dce7048b",
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "rf_model = RandomForestClassifier(**rf_params)\n",
    "rf_model.fit(X_train, y_train)\n",
    "rf_train_score = rf_model.score(X_train, y_train)\n",
    "rf_accuracy = rf_model.score(X_test, y_test)\n",
    "print(\"Train: {:.2f} %\".format(rf_train_score * 100))\n",
    "print(\"Test: {:.2f} %\".format(rf_accuracy*100))\n",
    "print('Overfit: {:.2f} %'.format((rf_train_score-rf_accuracy)*100))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7fb3b11b",
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "train_pred = rf_model.predict(X_train)\n",
    "val_pred = rf_model.predict(X_test)\n",
    "print(classification_report(y_test, val_pred))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a32fc165",
   "metadata": {},
   "outputs": [],
   "source": [
    "CM(y_test, val_pred, 'Random Forest Classifier')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7e9da7c2",
   "metadata": {},
   "outputs": [],
   "source": [
    "IMP(rf_model, \"RF\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cb86a374",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"Accuracy Scores:\")\n",
    "print(\"==========================================================\")\n",
    "# print(\"DNN: {:.3f}\".format(dnn_accuracy))\n",
    "print(\"RandomForest: {:.3f}\".format(rf_accuracy))\n",
    "# print(\"XGBoost classifier: {:.3f}\".format(xgb_accuracy))\n",
    "# print(\"SVM classifier: {:.3f}\".format(SVM_accuracy))\n",
    "# print(\"LR classifier: {:.3f}\".format(LR_accuracy))\n",
    "# print(\"KNN classifier: {:.3f}\".format(KNN_accuracy))\n",
    "# print(\"ADA Boost classifier: {:.3f}\".format(ADA_accuracy))\n",
    "# print(\"Extra Tree classifier: {:.3f}\".format(ETC_accuracy))\n",
    "# print(\"Gradient Boosting classifier: {:.3f}\".format(GBC_accuracy))\n",
    "# print(\"Stochastic Gradient descent: {:.3f}\".format(SGD_accuracy))\n",
    "# print(\"Decision Tree classifier: {:.3f}\".format(DT_accuracy))\n",
    "# print(\"LGBM classifier: {:.3f}\".format(LGBM_accuracy))\n",
    "#print(\"FLAML classifier: {:.3f}\".format(flaml_accuracy))\n",
    "print(\"==========================================================\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "66605312",
   "metadata": {},
   "outputs": [],
   "source": [
    "models = [rf_model]\n",
    "model_names = [\"RF\"]\n",
    "print(\"using\", len(models), \"classifiers\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a5730cc0",
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "SVC_ALL_PREDICTIONS = pd.DataFrame({'id': DATA[DATA.Set == 'Test']['id']})\n",
    "for i, m in enumerate(models):\n",
    "    SVC_ALL_PREDICTIONS[model_names[i]] = m.predict_proba(TEST)[:,1]\n",
    "SVC_ALL_PREDICTIONS['MedianVote'] = SVC_ALL_PREDICTIONS[model_names].median(axis=1)\n",
    "SVC_ALL_PREDICTIONS['SoftVote'] = SVC_ALL_PREDICTIONS[model_names].mean(axis=1)\n",
    "#SVC_ALL_PREDICTIONS['Predict'] = SVC_ALL_PREDICTIONS.SoftVote.apply(lambda row: 1 if row > TRESHOLD else 0)\n",
    "svc_predictions = SVC_ALL_PREDICTIONS.SoftVote\n",
    "SVC_ALL_PREDICTIONS.head(10)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "474fd376",
   "metadata": {},
   "outputs": [],
   "source": [
    "# fig, ax = plt.subplots(figsize=(12,12))  \n",
    "# g= sns.heatmap(SVC_ALL_PREDICTIONS[model_names].corr(),annot=True, cmap = \"coolwarm\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e6f36762",
   "metadata": {},
   "outputs": [],
   "source": [
    "output = pd.DataFrame({'id': DATA[DATA.Set == 'Test']['id'], 'target': svc_predictions})\n",
    "output.head(10)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ebc75fec",
   "metadata": {},
   "outputs": [],
   "source": [
    "#output\n",
    "output.to_csv('submission.csv', index=False)\n",
    "print(\"Submission was successfully saved!\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "39806bec",
   "metadata": {},
   "outputs": [],
   "source": [
    "end_time = time.time()\n",
    "print(\"Notebook run time: {:.1f} seconds. Finished at {}\".format(end_time - start_time, datetime.now()) )\n"
   ]
  }
 ],
 "metadata": {},
 "nbformat": 4,
 "nbformat_minor": 5
}

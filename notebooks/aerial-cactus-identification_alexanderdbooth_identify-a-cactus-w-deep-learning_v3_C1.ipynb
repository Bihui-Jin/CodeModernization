{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d8b78f61",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from pathlib import Path"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "60540102",
   "metadata": {},
   "outputs": [],
   "source": [
    "# This Python 3 environment comes with many helpful analytics libraries installed\n",
    "# It is defined by the kaggle/python docker image: https://github.com/kaggle/docker-python\n",
    "# For example, here's several helpful packages to load in \n",
    "\n",
    "import numpy as np # linear algebra\n",
    "import pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\n",
    "\n",
    "# Input data files are available in the \"../input/\" directory.\n",
    "# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n",
    "\n",
    "import os\n",
    "# for dirname, _, filenames in os.walk('/kaggle/input'):\n",
    "#     for filename in filenames:\n",
    "#         print(os.path.join(dirname, filename))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "43a30159",
   "metadata": {},
   "outputs": [],
   "source": [
    "train = pd.read_csv(\"../input/train.csv\")\n",
    "train.head()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7ba1df5f",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "from tensorflow import keras\n",
    "\n",
    "X_train, X_val, Y_train, Y_val = train_test_split(train.id, train.has_cactus, test_size=0.2)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "04b954b5",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "from os.path import join\n",
    "\n",
    "#load training images\n",
    "catctus_dir = '../input/train/train'\n",
    "\n",
    "#get full image paths for train/val\n",
    "train_paths = [join(catctus_dir,filename) for filename in X_train]\n",
    "val_paths = [join(catctus_dir,filename) for filename in X_val]\n",
    "\n",
    "train_paths[0:5]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "412baf9d",
   "metadata": {},
   "outputs": [],
   "source": [
    "from IPython.display import Image, display\n",
    "for i, img_path in enumerate(train_paths[0:5]):\n",
    "    display(Image(img_path))\n",
    "#yup, those are cacti\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "74b6416b",
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras.preprocessing.image import load_img, img_to_array\n",
    "\n",
    "#image size\n",
    "img_rows, img_cols, image_size = 32, 32, 32\n",
    "\n",
    "def read_and_prep_images(img_paths, img_height=image_size, img_width=image_size):\n",
    "    imgs = [load_img(img_path, target_size=(img_height, img_width)) for img_path in img_paths]\n",
    "    img_array = np.array([img_to_array(img) for img in imgs])\n",
    "    output = prep_data(img_array)\n",
    "    return(output)\n",
    "\n",
    "#training data has its labels already split out\n",
    "def prep_data(raw):\n",
    "    x = raw[:,0:]\n",
    "    num_images = raw.shape[0]\n",
    "    out_x = x.reshape(num_images, img_rows, img_cols, 3)\n",
    "    out_x = out_x / 255\n",
    "    return out_x\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ac3e749d",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_data = read_and_prep_images(train_paths)\n",
    "val_data = read_and_prep_images(val_paths)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7f6d8a0b",
   "metadata": {},
   "outputs": [],
   "source": [
    "np.shape(train_data) #14000 train images, 3,500 val images\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2cd16903",
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow import keras\n",
    "#cactus or no\n",
    "num_classes = 2\n",
    "\n",
    "train_labels = keras.utils.to_categorical(Y_train, num_classes)\n",
    "val_labels = keras.utils.to_categorical(Y_val, num_classes)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4713a348",
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "\n",
    "#view a couple of the training images\n",
    "for i in range(1,13):\n",
    "    plt.subplot(3,4,i)\n",
    "    plt.imshow(train_data[i-1])\n",
    "#moar cacti\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2042996d",
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Dense, Flatten, Conv2D\n",
    "\n",
    "#build the model\n",
    "cactus_model = Sequential()\n",
    "cactus_model.add(Conv2D(12, kernel_size=(3, 3),\n",
    "                 activation='relu',\n",
    "                 input_shape=(img_rows, img_cols, 3))) #activation layer\n",
    "\n",
    "#additional learning layers\n",
    "cactus_model.add(Conv2D(20, kernel_size=(3, 3), padding='valid', activation='relu'))\n",
    "cactus_model.add(Conv2D(20, kernel_size=(3, 3), padding='valid', activation='relu'))\n",
    "cactus_model.add(Conv2D(20, kernel_size=(3, 3), padding='valid', activation='relu'))\n",
    "cactus_model.add(Conv2D(20, kernel_size=(3, 3), padding='valid', activation='relu'))\n",
    "\n",
    "#final prediction layers\n",
    "cactus_model.add(Flatten())\n",
    "cactus_model.add(Dense(100, activation='relu'))\n",
    "cactus_model.add(Dense(num_classes, activation='softmax'))\n",
    "\n",
    "#compile the model\n",
    "cactus_model.compile(loss=keras.losses.categorical_crossentropy,\n",
    "              optimizer='adam',\n",
    "              metrics=['accuracy'])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "50ed00c7",
   "metadata": {},
   "outputs": [],
   "source": [
    "#initial fit with validation\n",
    "history = cactus_model.fit(train_data, train_labels,\n",
    "          batch_size=100,\n",
    "          epochs=10,\n",
    "          validation_data = (val_data, val_labels))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f160cbb3",
   "metadata": {},
   "outputs": [],
   "source": [
    "#https://www.kaggle.com/pheaboo/simple-cnn-trained-from-scratch\n",
    "plt.figure(figsize=(15,5))\n",
    "\n",
    "plt.subplot(141)\n",
    "plt.plot(history.history['loss'], label='training')\n",
    "plt.plot(history.history['val_loss'], label='validation')\n",
    "plt.xlabel('# Epochs')\n",
    "plt.legend()\n",
    "plt.ylabel(\"Loss - Binary Cross Entropy\")\n",
    "plt.title('Loss Evolution')\n",
    "\n",
    "plt.subplot(142)\n",
    "plt.plot(history.history['loss'], label='training')\n",
    "plt.plot(history.history['val_loss'], label='validation')\n",
    "plt.ylim(0,0.3)\n",
    "plt.xlabel('# Epochs')\n",
    "plt.legend()\n",
    "plt.ylabel(\"Loss - Binary Cross Entropy\")\n",
    "plt.title('Zoom Near Zero - Loss Evolution')\n",
    "\n",
    "plt.subplot(143)\n",
    "plt.plot(history.history['acc'], label='training')\n",
    "plt.plot(history.history['val_acc'], label='validation')\n",
    "plt.xlabel('# Epochs')\n",
    "plt.ylabel(\"Accuracy\")\n",
    "plt.legend()\n",
    "plt.title('Accuracy Evolution')\n",
    "\n",
    "plt.subplot(144)\n",
    "plt.plot(history.history['acc'], label='training')\n",
    "plt.plot(history.history['val_acc'], label='validation')\n",
    "plt.ylim(0.9,1)\n",
    "plt.xlabel('# Epochs')\n",
    "plt.ylabel(\"Accuracy\")\n",
    "plt.legend()\n",
    "plt.title('Zoom Near One - Accuracy Evolution')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "631ca01d",
   "metadata": {},
   "outputs": [],
   "source": [
    "#build the model, same as above\n",
    "cactus_model_aug = Sequential()\n",
    "cactus_model_aug.add(Conv2D(12, kernel_size=(3, 3),\n",
    "                 activation='relu',\n",
    "                 input_shape=(img_rows, img_cols, 3))) #activation layer\n",
    "\n",
    "#additional learning layers\n",
    "cactus_model_aug.add(Conv2D(20, kernel_size=(3, 3), activation='relu'))\n",
    "cactus_model_aug.add(Conv2D(20, kernel_size=(3, 3), activation='relu'))\n",
    "cactus_model_aug.add(Conv2D(20, kernel_size=(3, 3), activation='relu'))\n",
    "cactus_model_aug.add(Conv2D(20, kernel_size=(3, 3), activation='relu'))\n",
    "\n",
    "#final prediction layers\n",
    "cactus_model_aug.add(Flatten())\n",
    "cactus_model_aug.add(Dense(100, activation='relu'))\n",
    "cactus_model_aug.add(Dense(num_classes, activation='softmax'))\n",
    "\n",
    "#compile the model\n",
    "cactus_model_aug.compile(loss=keras.losses.categorical_crossentropy,\n",
    "              optimizer='adam',\n",
    "              metrics=['accuracy'])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "97e17bcd",
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras.preprocessing.image import ImageDataGenerator\n",
    "datagen = ImageDataGenerator(featurewise_center=False,  # set input mean to 0 over the dataset\n",
    "        samplewise_center=False,  # set each sample mean to 0\n",
    "        featurewise_std_normalization=False,  # divide inputs by std of the dataset\n",
    "        samplewise_std_normalization=False,  # divide each input by its std\n",
    "        zca_whitening=False,  # apply ZCA whitening\n",
    "        rotation_range=10,  # randomly rotate images in the range (degrees, 0 to 180)\n",
    "        zoom_range = 0.1, # Randomly zoom image \n",
    "        width_shift_range=0.1,  # randomly shift images horizontally (fraction of total width)\n",
    "        height_shift_range=0.1,  # randomly shift images vertically (fraction of total height)\n",
    "        horizontal_flip=True,  # randomly flip images\n",
    "        vertical_flip=True)  # randomly flip images\n",
    "\n",
    "datagen.fit(train_data)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "878c0274",
   "metadata": {},
   "outputs": [],
   "source": [
    "cactus_model_aug.fit_generator(datagen.flow(train_data,train_labels),\n",
    "                              epochs = 15, validation_data = (val_data,val_labels), steps_per_epoch=20)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "298904a2",
   "metadata": {},
   "outputs": [],
   "source": [
    "#aug was NOT better\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "24709cf4",
   "metadata": {},
   "outputs": [],
   "source": [
    "test_dir = '../input/test/test'\n",
    "test_paths = [join(test_dir,filename) for filename in os.listdir(test_dir)]\n",
    "test_paths[0:5]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "943128da",
   "metadata": {},
   "outputs": [],
   "source": [
    "len(os.listdir(test_dir))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a4476194",
   "metadata": {},
   "outputs": [],
   "source": [
    "from IPython.display import Image, display\n",
    "for i, img_path in enumerate(test_paths[0:5]):\n",
    "    display(Image(img_path))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ba51ee98",
   "metadata": {},
   "outputs": [],
   "source": [
    "test_data = read_and_prep_images(test_paths)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e571fa0a",
   "metadata": {},
   "outputs": [],
   "source": [
    "np.shape(test_data)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4a03aebf",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Get predictions\n",
    "preds_test = cactus_model.predict(test_data)\n",
    "\n",
    "# #the model returns a list of probabilities for each outcome. \n",
    "realPreds = preds_test[:,0]\n",
    "realPreds[0:12]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "743824f4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Save test predictions to file\n",
    "# no aug performed better\n",
    "output = pd.DataFrame({'id': os.listdir(test_dir),\n",
    "                       'has_cactus': realPreds})\n",
    "output.to_csv('submission.csv', index=False)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d7bfa421",
   "metadata": {},
   "outputs": [],
   "source": [
    " \n"
   ]
  }
 ],
 "metadata": {},
 "nbformat": 4,
 "nbformat_minor": 5
}

{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f120c789",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from pathlib import Path"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0f3719f1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# libraries\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import os\n",
    "import cv2\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import roc_auc_score\n",
    "import torch\n",
    "from torch.utils.data import TensorDataset, DataLoader,Dataset, random_split\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import torchvision\n",
    "import torchvision.transforms as transforms\n",
    "import torch.optim as optim\n",
    "from torch.optim import lr_scheduler\n",
    "import time \n",
    "from PIL import Image\n",
    "train_on_gpu = True\n",
    "from torch.utils.data.sampler import SubsetRandomSampler\n",
    "from torch.optim.lr_scheduler import StepLR, ReduceLROnPlateau, CosineAnnealingLR\n",
    "\n",
    "!pip install torchsummary\n",
    "from torchsummary import summary\n",
    "\n",
    "import copy\n",
    "\n",
    "torch.manual_seed(0)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "86e920d9",
   "metadata": {},
   "outputs": [],
   "source": [
    "path2labels = \"/kaggle/input/histopathologic-cancer-detection/train_labels.csv\"\n",
    "labels_df = pd.read_csv(path2labels)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "116b40c5",
   "metadata": {},
   "outputs": [],
   "source": [
    "labels_df.head()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6b2835ea",
   "metadata": {},
   "outputs": [],
   "source": [
    "labels_df.shape\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "993ef4a9",
   "metadata": {},
   "outputs": [],
   "source": [
    "labels_df['label'].value_counts()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dd324f51",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(f'The dataset has {sum(labels_df.duplicated())} duplicates')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "076b4280",
   "metadata": {},
   "outputs": [],
   "source": [
    "fig = plt.figure(figsize=(25, 4))\n",
    "path2data = \"/kaggle/input/histopathologic-cancer-detection/train\"\n",
    "train_imgs = os.listdir(path2data)\n",
    "for idx, img in enumerate(np.random.choice(train_imgs, 20)):\n",
    "    ax = fig.add_subplot(2, 20//2, idx+1)\n",
    "    im = Image.open(path2data + \"/\" + img)\n",
    "    plt.imshow(im)\n",
    "    lab = labels_df.loc[labels_df[\"id\"] == img.split('.')[0], 'label'].values[0]\n",
    "    ax.set_title(f'Label: {lab}')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "336e6199",
   "metadata": {},
   "outputs": [],
   "source": [
    "class cancer_dataset(Dataset):\n",
    "    def __init__(self, data_dir, transform, data_type=\"train\"):\n",
    "        # path to images\n",
    "        path2data = os.path.join(data_dir, data_type)\n",
    "        \n",
    "        # list of images in directory\n",
    "        filenames = os.listdir(path2data)\n",
    "        \n",
    "        # get full path to images\n",
    "        self.full_filenames = [os.path.join(path2data, f) for f in filenames]\n",
    "        \n",
    "        # get labels\n",
    "        path2labels = os.path.join(data_dir, \"train_labels.csv\")\n",
    "        labels_df = pd.read_csv(path2labels)\n",
    "        \n",
    "        # seg dataframe index to id\n",
    "        labels_df.set_index(\"id\", inplace=True)\n",
    "        \n",
    "        # obtain labels from df\n",
    "        self.labels = [labels_df.loc[filename[:-4]].values[0] for filename in filenames]\n",
    "        \n",
    "        self.transform = transform\n",
    "        \n",
    "        \n",
    "    def __len__(self):\n",
    "        # return size of dataset\n",
    "        return len(self.full_filenames)\n",
    "    \n",
    "    def __getitem__(self, idx):\n",
    "        # open image, apply transforms and return with label\n",
    "        img = Image.open(self.full_filenames[idx]) # PIL image\n",
    "        img = self.transform(img)\n",
    "        return img, self.labels[idx]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "62e3505d",
   "metadata": {},
   "outputs": [],
   "source": [
    "data_transformer = transforms.Compose([transforms.ToTensor(),\n",
    "                                       transforms.Resize((46,46))])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "69f47980",
   "metadata": {},
   "outputs": [],
   "source": [
    "data_dir = \"/kaggle/input/histopathologic-cancer-detection\"\n",
    "img_dataset = cancer_dataset(data_dir, data_transformer, \"train\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "836071f2",
   "metadata": {},
   "outputs": [],
   "source": [
    "img, label = img_dataset[19]\n",
    "print(img.shape, torch.min(img), torch.max(img))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4d2e5479",
   "metadata": {},
   "outputs": [],
   "source": [
    "len_dataset = len(img_dataset)\n",
    "len_train = int(0.8 * len_dataset)\n",
    "len_val = len_dataset - len_train\n",
    "\n",
    "train_ds, val_ds = random_split(img_dataset, [len_train, len_val])\n",
    "\n",
    "print(f'train dataset length: {len(train_ds)}')\n",
    "print(f'validation dataset length: {len(val_ds)}')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "60f19756",
   "metadata": {},
   "outputs": [],
   "source": [
    "i = 0\n",
    "for x, y in train_ds:\n",
    "    print(x.shape, y)\n",
    "    i += 1\n",
    "    if i > 5:\n",
    "        break\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ca75b3fc",
   "metadata": {},
   "outputs": [],
   "source": [
    "# transformer for trainging dataset\n",
    "train_transf = transforms.Compose([\n",
    "    transforms.RandomHorizontalFlip(p=0.5),\n",
    "    transforms.RandomVerticalFlip(p=0.5),\n",
    "    transforms.RandomRotation(45),\n",
    "    transforms.RandomResizedCrop(96, scale=(0.8, 1.0), ratio=(1.0, 1.0)),\n",
    "#     transforms.Normalize((0.5, 0.5, 0.5), (0.5, 0.5, 0.5)),\n",
    "    transforms.ToTensor()\n",
    "    ])\n",
    "\n",
    "# No augmentation for validation dataset\n",
    "val_transf = transforms.Compose([\n",
    "#     transforms.Normalize((0.5, 0.5, 0.5), (0.5, 0.5, 0.5)),\n",
    "    transforms.ToTensor()\n",
    "    ])\n",
    "\n",
    "# Overwrite the transforms functions\n",
    "train_ds.transform = train_transf\n",
    "val_ds.transform = val_transf\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "83d6335c",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_ds.transform\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3e893a53",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_dl = DataLoader(train_ds, batch_size=32, shuffle=True)\n",
    "val_dl = DataLoader(val_ds, batch_size=32, shuffle=False)\n",
    "\n",
    "# check batches\n",
    "for x, y in train_dl:\n",
    "    print(x.shape)\n",
    "    print(y.shape)\n",
    "    break\n",
    "    \n",
    "for x, y in val_dl:\n",
    "    print(x.shape)\n",
    "    print(y.shape)\n",
    "    break\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "22fbb124",
   "metadata": {},
   "outputs": [],
   "source": [
    "class Network(nn.Module):\n",
    "    \n",
    "    def __init__(self):\n",
    "        \n",
    "        super(Network, self).__init__()\n",
    "        self.conv1 = nn.Conv2d(3, 8, kernel_size=3)\n",
    "        self.conv2 = nn.Conv2d(8, 16, kernel_size=3)\n",
    "        self.conv3 = nn.Conv2d(16, 32, kernel_size=3)\n",
    "        self.conv4 = nn.Conv2d(32, 64, kernel_size=3)\n",
    "        \n",
    "        self.dropout_rate = 0.25\n",
    "        self.pool = nn.MaxPool2d(2, 2)\n",
    "        self.fc1 = nn.Linear(1*1*64, 100)\n",
    "        self.fc2 = nn.Linear(100, 2)\n",
    "        \n",
    "    def forward(self, X):\n",
    "        \n",
    "        x = self.pool(F.relu(self.conv1(X)))\n",
    "        x = self.pool(F.relu(self.conv2(x)))\n",
    "        x = self.pool(F.relu(self.conv3(x)))\n",
    "        x = self.pool(F.relu(self.conv4(x)))\n",
    "        # flatten\n",
    "        x = x.view(-1, 1*1*64)\n",
    "        \n",
    "        x = F.relu(self.fc1(x))\n",
    "        x = F.dropout(x, self.dropout_rate)\n",
    "        x = self.fc2(x)\n",
    "        return F.log_softmax(x, dim=1)\n",
    "    \n",
    "    \n",
    "# create instant of model\n",
    "cnn_model = Network()\n",
    "\n",
    "# define hardware\n",
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "model = cnn_model.to(device)\n",
    "print(device)\n",
    "\n",
    "summary(cnn_model, input_size=(3, 46, 46), device=device.type)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "51bc4f70",
   "metadata": {},
   "outputs": [],
   "source": [
    "loss_func = nn.NLLLoss(reduction=\"sum\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5f4d518f",
   "metadata": {},
   "outputs": [],
   "source": [
    "opt = optim.Adam(cnn_model.parameters(), lr=3e-4)\n",
    "lr_scheduler = ReduceLROnPlateau(opt, mode='min', factor=0.5, patience=20, verbose=0)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ec85dc32",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Function to get the learning rate\n",
    "def get_lr(opt):\n",
    "    for param_group in opt.param_groups:\n",
    "        return param_group['lr']\n",
    "\n",
    "# Function to compute the loss value per batch of data\n",
    "def loss_batch(loss_func, output, target, opt=None):\n",
    "    \n",
    "    loss = loss_func(output, target) # get loss\n",
    "    pred = output.argmax(dim=1, keepdim=True) # Get Output Class\n",
    "    metric_b=pred.eq(target.view_as(pred)).sum().item() # get performance metric\n",
    "    \n",
    "    if opt is not None:\n",
    "        opt.zero_grad()\n",
    "        loss.backward()\n",
    "        opt.step()\n",
    "\n",
    "    return loss.item(), metric_b\n",
    "\n",
    "# Compute the loss value & performance metric for the entire dataset (epoch)\n",
    "def loss_epoch(model,loss_func,dataset_dl,opt=None):\n",
    "    \n",
    "    run_loss=0.0 \n",
    "    t_metric=0.0\n",
    "    len_data=len(dataset_dl.dataset)\n",
    "\n",
    "    # internal loop over dataset\n",
    "    for xb, yb in tqdm(dataset_dl, leave=False):\n",
    "        # move batch to device\n",
    "        xb=xb.to(device)\n",
    "        yb=yb.to(device)\n",
    "        output=model(xb) # get model output\n",
    "        loss_b,metric_b=loss_batch(loss_func, output, yb, opt) # get loss per batch\n",
    "        run_loss+=loss_b        # update running loss\n",
    "\n",
    "        if metric_b is not None: # update running metric\n",
    "            t_metric+=metric_b    \n",
    "    \n",
    "    loss=run_loss/float(len_data)  # average loss value\n",
    "    metric=t_metric/float(len_data) # average metric value\n",
    "    \n",
    "    return loss, metric\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6a255cb5",
   "metadata": {},
   "outputs": [],
   "source": [
    "from tqdm.notebook import trange, tqdm\n",
    "\n",
    "def train_val(model, params, verbose=False):\n",
    "    \n",
    "    # Get parameters\n",
    "    epochs = params[\"epochs\"]\n",
    "    opt = params[\"optimiser\"]\n",
    "    loss_func = params[\"f_loss\"]\n",
    "    train_dl = params[\"train\"]\n",
    "    val_dl = params[\"val\"]\n",
    "    lr_scheduler = params[\"lr_change\"]\n",
    "    weight_path = params[\"weight_path\"]\n",
    "    \n",
    "    # history of loss and metric values in each epoch\n",
    "    loss_history = {\"train\": [], \"val\": []}\n",
    "    metric_history = {\"train\": [], \"val\": []}\n",
    "    \n",
    "    # a deep copy of weights for the best model\n",
    "    best_model_wts = copy.deepcopy(model.state_dict())\n",
    "    \n",
    "    best_loss = float('inf')      # init loss\n",
    "    \n",
    "    # Train loop\n",
    "    for epoch in tqdm(range(epochs), leave=False):\n",
    "        \n",
    "        # get lr\n",
    "        current_lr = get_lr(opt)\n",
    "        if(verbose):\n",
    "            print(f'Epoch {epoch +1}/{epochs}, current lr={current_lr}')\n",
    "        \n",
    "        # train model\n",
    "        model.train()\n",
    "        train_loss, train_metric = loss_epoch(model, loss_func, train_dl, opt)\n",
    "        \n",
    "        loss_history[\"train\"].append(train_loss)\n",
    "        metric_history[\"train\"].append(train_metric)\n",
    "        \n",
    "        # evaluate model\n",
    "        model.eval()\n",
    "        with torch.no_grad():\n",
    "            val_loss, val_metric = loss_epoch(model, loss_func, val_dl)\n",
    "        \n",
    "        # store best model\n",
    "        if val_loss < best_loss:\n",
    "            best_loss = val_loss\n",
    "            best_model_wts = copy.deepcopy(model.state_dict())\n",
    "            \n",
    "            # save weights in a local file\n",
    "            torch.save(model.state_dict(), weight_path)\n",
    "            if verbose:\n",
    "                print(\"Saved best model weights\")\n",
    "            \n",
    "        loss_history[\"val\"].append(val_loss)\n",
    "        metric_history[\"val\"].append(val_metric)\n",
    "        \n",
    "        # lr schedule\n",
    "        lr_scheduler.step(val_loss)\n",
    "        if current_lr != get_lr(opt):\n",
    "            if verbose:\n",
    "                print(\"Loading best model weights\")\n",
    "            model.load_state_dict(best_model_wts)\n",
    "            \n",
    "        if verbose:\n",
    "            print(f\"train loss: {train_loss:.6f}, dev loss: {val_loss:.6f}, accuracy: {100*val_metric:.2f}\")\n",
    "            print(\"-\"*20)\n",
    "            \n",
    "    model.load_state_dict(best_model_wts)\n",
    "    \n",
    "    return model, loss_history, metric_history\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5b99b186",
   "metadata": {},
   "outputs": [],
   "source": [
    "params_train={\n",
    " \"train\": train_dl,\"val\": val_dl,\n",
    " \"epochs\": 50,\n",
    " \"optimiser\": opt,\n",
    " \"lr_change\": lr_scheduler,\n",
    " \"f_loss\": loss_func,\n",
    " \"weight_path\": \"weights.pt\",\n",
    "}\n",
    "\n",
    "# Train model\n",
    "\n",
    "model, loss_hist, metric_hist = train_val(model, params_train, verbose=True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bfac2eea",
   "metadata": {},
   "outputs": [],
   "source": [
    "import seaborn as sns; sns.set(style='whitegrid')\n",
    "\n",
    "epochs=params_train[\"epochs\"]\n",
    "\n",
    "fig,ax = plt.subplots(1,2,figsize=(12,5))\n",
    "\n",
    "sns.lineplot(x=[*range(1,epochs+1)],y=loss_hist[\"train\"],ax=ax[0],label='loss_hist[\"train\"]')\n",
    "sns.lineplot(x=[*range(1,epochs+1)],y=loss_hist[\"val\"],ax=ax[0],label='loss_hist[\"val\"]')\n",
    "sns.lineplot(x=[*range(1,epochs+1)],y=metric_hist[\"train\"],ax=ax[1],label='metric_hist[\"train\"]')\n",
    "sns.lineplot(x=[*range(1,epochs+1)],y=metric_hist[\"val\"],ax=ax[1],label='metric_hist[\"val\"]')\n",
    "plt.title('Convergence History')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f3908991",
   "metadata": {},
   "outputs": [],
   "source": [
    "class cancerdata_test(Dataset):\n",
    "    \n",
    "    def __init__(self, data_dir, transform,data_type=\"train\"):\n",
    "        \n",
    "        path2data = os.path.join(data_dir,data_type)\n",
    "        filenames = os.listdir(path2data)\n",
    "        self.full_filenames = [os.path.join(path2data, f) for f in filenames]\n",
    "        \n",
    "        # labels are in a csv file named train_labels.csv\n",
    "        csv_filename=\"sample_submission.csv\"\n",
    "        path2csvLabels=os.path.join(data_dir,csv_filename)\n",
    "        labels_df=pd.read_csv(path2csvLabels)\n",
    "        \n",
    "        # set data frame index to id\n",
    "        labels_df.set_index(\"id\", inplace=True)\n",
    "        \n",
    "        # obtain labels from data frame\n",
    "        self.labels = [labels_df.loc[filename[:-4]].values[0] for filename in filenames]\n",
    "        self.transform = transform       \n",
    "        \n",
    "    def __len__(self):\n",
    "        # return size of dataset\n",
    "        return len(self.full_filenames)\n",
    "    \n",
    "    def __getitem__(self, idx):\n",
    "        # open image, apply transforms and return with label\n",
    "        image = Image.open(self.full_filenames[idx]) # PIL image\n",
    "        image = self.transform(image)\n",
    "        return image, self.labels[idx]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "921cf3b9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# load any model weights for the model\n",
    "model.load_state_dict(torch.load('weights.pt'))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e5c0537a",
   "metadata": {},
   "outputs": [],
   "source": [
    "path2sub = \"/kaggle/input/histopathologic-cancer-detection/sample_submission.csv\"\n",
    "labels_df = pd.read_csv(path2sub)\n",
    "data_dir = '/kaggle/input/histopathologic-cancer-detection/'\n",
    "\n",
    "data_transformer = transforms.Compose([transforms.ToTensor(),\n",
    "                                       transforms.Resize((46,46))])\n",
    "\n",
    "img_dataset_test = cancerdata_test(data_dir,data_transformer,data_type=\"test\")\n",
    "print(len(img_dataset_test), 'samples found')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "294cd906",
   "metadata": {},
   "outputs": [],
   "source": [
    "def inference(model,dataset,device,num_classes=2):\n",
    "    \n",
    "    len_data=len(dataset)\n",
    "    y_out=torch.zeros(len_data,num_classes) # initialize output tensor on CPU\n",
    "    y_gt=np.zeros((len_data),dtype=\"uint8\") # initialize ground truth on CPU\n",
    "    model=model.to(device) # move model to device\n",
    "    model.eval()\n",
    "    \n",
    "    with torch.no_grad():\n",
    "        for i in tqdm(range(len_data)):\n",
    "            x,y=dataset[i]\n",
    "            y_gt[i]=y\n",
    "            y_out[i]=model(x.unsqueeze(0).to(device))\n",
    "\n",
    "    return y_out.numpy(),y_gt           \n",
    "\n",
    "y_test_out,_ = inference(model,img_dataset_test, device)  \n",
    "y_test_pred=np.argmax(y_test_out,axis=1)\n",
    "\n",
    "test_ids = [name.split('/')[-1].split('.')[0] for name in img_dataset_test.full_filenames]\n",
    "test_preds = pd.DataFrame({\"img\": test_ids, \"preds\": y_test_pred})\n",
    "submission = pd.merge(labels_df, test_preds, left_on='id', right_on='img')\n",
    "submission = submission[['id', 'preds']]\n",
    "submission.columns = ['id', 'label']\n",
    "submission.head()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a7fb9d57",
   "metadata": {},
   "outputs": [],
   "source": [
    "submission.to_csv('submission.csv', index=False)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0e2c7b24",
   "metadata": {},
   "outputs": [],
   "source": [
    " \n"
   ]
  }
 ],
 "metadata": {},
 "nbformat": 4,
 "nbformat_minor": 5
}

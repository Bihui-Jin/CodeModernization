{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "90836f57",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from pathlib import Path"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "82a6bbc2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# import the tools we need\n",
    "import os \n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "from PIL import Image\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "import torch\n",
    "import torch.nn.functional as F\n",
    "import torchvision\n",
    "from torchvision import transforms\n",
    "from torch.utils.data.dataset import Dataset\n",
    "from torch.utils.data import DataLoader\n",
    "from pytorch_lightning import metrics\n",
    "from sklearn.preprocessing impbort LabelEncoder\n",
    "from sklearn.model_selection import train_test_splitb\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "615f4e24",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Read the csv files\n",
    "comp_df = pd.read_csv('../input/dog-breed-identification/labels.csv')\n",
    "test_df = pd.read_csv('../input/dog-breed-identification/sample_submission.csv')\n",
    "\n",
    "# How many number of images in Training set and test set?\n",
    "print('Training set: {}, Test set: {}'.format(comp_df.shape[0],test_df.shape[0]))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cba0bc76",
   "metadata": {},
   "outputs": [],
   "source": [
    "# how may dog breed in training set? \n",
    "comp_df.breed.value_counts()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b82301dd",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Encode the breed into digits\n",
    "comp_df['label'] = LabelEncoder().fit_transform(comp_df.breed)\n",
    "\n",
    "# Create a breed-2-index dictionary\n",
    "dict_df = comp_df[['label','breed']].copy()\n",
    "dict_df.drop_duplicates(inplace=True)\n",
    "dict_df.set_index('label',drop=True,inplace=True)\n",
    "index_to_breed = dict_df.to_dict()['breed']\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "18808fb0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Change the id to full file path\n",
    "train_dir = '../input/dog-breed-identification/train'\n",
    "comp_df.id = comp_df.id.apply(lambda x: x+'.jpg')\n",
    "comp_df.id = comp_df.id.apply(lambda x:train_dir+'/'+x)\n",
    "\n",
    "# Drop the breed column\n",
    "comp_df.pop('breed')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3eea4446",
   "metadata": {},
   "outputs": [],
   "source": [
    "def show_images(df,img_num):\n",
    "    sample = df.sample(img_num)\n",
    "    paths = sample.id.tolist()\n",
    "    for path in paths:\n",
    "        plt.figure(figsize=(3,3))\n",
    "        img = plt.imread(path)\n",
    "        plt.imshow(img)\n",
    "        plt.axis('off')\n",
    "        plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ffeaf12d",
   "metadata": {},
   "outputs": [],
   "source": [
    "show_images(comp_df,4)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a98f2cef",
   "metadata": {},
   "outputs": [],
   "source": [
    "class img_dataset(Dataset):\n",
    "    def __init__(self,dataframe,transform=None,test=False):\n",
    "        self.dataframe = dataframe\n",
    "        self.transform = transform\n",
    "        self.test = test\n",
    "        \n",
    "    def __getitem__(self,index):\n",
    "        x = Image.open(self.dataframe.iloc[index,0])\n",
    "        if self.transform:\n",
    "            x = self.transform(x)\n",
    "        if self.test:\n",
    "            return x\n",
    "        else:\n",
    "            y = self.dataframe.iloc[index,1]\n",
    "            return x,y\n",
    "        \n",
    "    def __len__(self):\n",
    "        return self.dataframe.shape[0]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a38ff6bf",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Creat transfomers\n",
    "train_transformer = transforms.Compose([transforms.RandomResizedCrop(224),\n",
    "                                        transforms.RandomRotation(15),\n",
    "                                        transforms.RandomHorizontalFlip(),\n",
    "                                        transforms.ToTensor(),\n",
    "                                        transforms.Normalize([0.485, 0.456, 0.406], [0.229, 0.224, 0.225])])\n",
    "\n",
    "val_transformer = transforms.Compose([transforms.Resize(256),\n",
    "                                      transforms.CenterCrop(224),\n",
    "                                      transforms.ToTensor(),\n",
    "                                      transforms.Normalize([0.485, 0.456, 0.406], [0.229, 0.224, 0.225])])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "09d5ea4b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Print the result of 1 epoch\n",
    "def print_epoch_result(train_loss,train_acc,val_loss,val_acc):\n",
    "    print('loss: {:.3f}, acc: {:.3f}, val_loss: {:.3f}, val_acc: {:.3f}'.format(train_loss,\n",
    "                                                                              train_acc,\n",
    "                                                                              val_loss,\n",
    "                                                                              val_acc))\n",
    "# Main Training function\n",
    "def train_model(model, cost_function, optimizer,num_epochs=5):\n",
    "    train_losses = []\n",
    "    val_losses = []\n",
    "    train_acc = []\n",
    "    val_acc = []\n",
    "    \n",
    "    # Metrics object\n",
    "    train_acc_object = metrics.Accuracy(compute_on_step=False)\n",
    "    val_acc_object = metrics.Accuracy(compute_on_step=False)\n",
    "    \n",
    "    for epoch in range(num_epochs):\n",
    "        \"\"\"\n",
    "        On epoch start\n",
    "        \"\"\"\n",
    "        print('-'*15)\n",
    "        print('Start training {}/{}'.format(epoch+1, num_epochs))\n",
    "        print('-'*15)\n",
    "        \n",
    "        # Training\n",
    "        train_sub_losses = []\n",
    "        model.train()\n",
    "        for x,y in train_loader:\n",
    "            optimizer.zero_grad()\n",
    "            x,y = x.to(device),y.to(device)\n",
    "            y_hat = model(x)\n",
    "            loss = cost_function(y_hat,y)\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "            #lr_scheduler.step()\n",
    "            # update loss sublist\n",
    "            train_sub_losses.append(loss.item())\n",
    "            # update accuracy object\n",
    "            train_acc_object(y_hat.cpu(),y.cpu())\n",
    "            \n",
    "        # Validation\n",
    "        val_sub_losses = []\n",
    "        model.eval()\n",
    "        for x,y in val_loader:\n",
    "            x,y = x.to(device),y.to(device)\n",
    "            y_hat = model(x)\n",
    "            loss = cost_function(y_hat,y)\n",
    "            val_sub_losses.append(loss.item())\n",
    "            val_acc_object(y_hat.cpu(),y.cpu())\n",
    "            \n",
    "        \"\"\"\n",
    "        On epoch end\n",
    "        \"\"\"\n",
    "        # Update the loss list\n",
    "        train_losses.append(np.mean(train_sub_losses))\n",
    "        val_losses.append(np.mean(val_sub_losses))\n",
    "        \n",
    "        # Update the accuracy list and reset the metrics object \n",
    "        train_epoch_acc = train_acc_object.compute()\n",
    "        val_epoch_acc = val_acc_object.compute()\n",
    "        train_acc.append(train_epoch_acc)\n",
    "        val_acc.append(val_epoch_acc)\n",
    "        train_acc_object.reset()\n",
    "        val_acc_object.reset()\n",
    "        \n",
    "        # print the result of epoch\n",
    "        print_epoch_result(np.mean(train_sub_losses),train_epoch_acc,np.mean(val_sub_losses),val_epoch_acc)\n",
    "        \n",
    "    print('Finish Training.')\n",
    "    return train_losses, train_acc, val_losses, val_acc\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b5efe0af",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Setting up gpu\n",
    "device = torch.device('cuda:0' if torch.cuda.is_available else 'cpu')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b538a0d1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Parameters for dataset\n",
    "training_samples = comp_df.shape[0] # Use small number first to test whether the model is doing well, then change back to full dataset\n",
    "test_size=0.05\n",
    "batch_size = 64\n",
    "\n",
    "# Reduce the number of samples\n",
    "sample_df = comp_df.sample(training_samples)\n",
    "\n",
    "# Split the comp_df into training set and validation set\n",
    "x_train,x_val,_,_ = train_test_split(sample_df,sample_df,test_size=test_size)\n",
    "\n",
    "# Create dataloaders form datasets\n",
    "train_set = img_dataset(x_train, transform=train_transformer)\n",
    "val_set = img_dataset(x_val, transform=val_transformer)\n",
    "train_loader = DataLoader(train_set, batch_size=batch_size, shuffle=True)\n",
    "val_loader = DataLoader(val_set , batch_size=batch_size, shuffle=True)\n",
    "\n",
    "# How many images in training set and val set?\n",
    "print('Training set: {}, Validation set: {}'.format(x_train.shape[0],x_val.shape[0]))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "60cecf2e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Use resnet-50 as a base model\n",
    "class net(torch.nn.Module):\n",
    "    def __init__(self, base_model, base_out_features, num_classes):\n",
    "        super(net,self).__init__()\n",
    "        self.base_model=base_model\n",
    "        self.linear1 = torch.nn.Linear(base_out_features, 512)\n",
    "        self.output = torch.nn.Linear(512,num_classes)\n",
    "    def forward(self,x):\n",
    "        x = F.relu(self.base_model(x))\n",
    "        x = F.relu(self.linear1(x))\n",
    "        x = self.output(x)\n",
    "        return x\n",
    "\n",
    "res = torchvision.models.resnet50(pretrained=True)\n",
    "for param in res.parameters():\n",
    "    param.requires_grad=False\n",
    "\n",
    "model_final = net(base_model=res, base_out_features=res.fc.out_features, num_classes=120)\n",
    "model_final = model_final.to(device)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ceec5368",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Cost function and optimzier\n",
    "cost_function = torch.nn.CrossEntropyLoss()\n",
    "optimizer = torch.optim.Adam([param for param in model_final.parameters() if param.requires_grad], lr=0.0003)\n",
    "\n",
    "# Learning rate scheduler\n",
    "#lr_scheduler = torch.optim.lr_scheduler.ExponentialLR(optimizer=optimizer, gamma=0.1)\n",
    "\n",
    "# Epoch \n",
    "EPOCHS = 30\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1eba415e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Start Training\n",
    "train_losses, train_acc, val_losses, val_acc = train_model(model=model_final, \n",
    "                                                           cost_function=cost_function, \n",
    "                                                           optimizer=optimizer,\n",
    "                                                           num_epochs=EPOCHS)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "762a9b19",
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_result(train_loss,val_loss,train_acc,val_acc):\n",
    "    plt.style.use('ggplot')\n",
    "    fig, (ax1,ax2) = plt.subplots(2,1,figsize=(10,8))\n",
    "    ax1.plot(train_loss,label='loss')\n",
    "    ax1.plot(val_loss,label='val_loss')\n",
    "    ax1.legend()\n",
    "    ax1.set_xlabel('epoch')\n",
    "    ax1.set_xticks(range(0,EPOCHS+1))\n",
    "    ax2.plot(train_acc, label='acc')\n",
    "    ax2.plot(val_acc,label='val_acc')\n",
    "    ax2.legend()\n",
    "    ax2.set_xlabel('epoch')\n",
    "    ax2.set_xticks(range(0,EPOCHS+1))\n",
    "    plt.show()\n",
    "plot_result(train_losses,val_losses, train_acc,  val_acc)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "65ac1ca4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Prepare for test data dataframe\n",
    "#test_df = pd.read_csv('../input/dog-breed-identification/sample_submission.csv')\n",
    "test_dir = '../input/dog-breed-identification/test'\n",
    "test_df = test_df[['id']]\n",
    "test_df.id = test_df.id.apply(lambda x: x+'.jpg')\n",
    "test_df.id = test_df.id.apply(lambda x : test_dir+'/'+x)\n",
    "test_set = img_dataset(test_df,transform=val_transformer, test=True)\n",
    "test_loader = DataLoader(test_set, batch_size=batch_size, shuffle=False)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ae32a512",
   "metadata": {},
   "outputs": [],
   "source": [
    "model_final.eval()\n",
    "predictions = torch.tensor([])\n",
    "print('Start predicting....')\n",
    "for x in test_loader:\n",
    "    x = x.to(device)\n",
    "    y_hat = model_final(x)\n",
    "    predictions = torch.cat([predictions, y_hat.cpu()])\n",
    "print('Finish prediction.')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cc0b7cd4",
   "metadata": {},
   "outputs": [],
   "source": [
    "predictions = F.softmax(predictions,dim=1).detach().numpy()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "889337f1",
   "metadata": {},
   "outputs": [],
   "source": [
    "answer_id = pd.read_csv('../input/dog-breed-identification/sample_submission.csv').id.tolist()\n",
    "predictions_df = pd.DataFrame(predictions, index=answer_id)\n",
    "predictions_df.columns = predictions_df.columns.map(index_to_breed)\n",
    "predictions_df.rename_axis('id', inplace=True)\n",
    "predictions_df.to_csv('submission.csv')\n"
   ]
  }
 ],
 "metadata": {},
 "nbformat": 4,
 "nbformat_minor": 5
}

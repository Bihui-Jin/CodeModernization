{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ca629d2f",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from pathlib import Path"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6cfd8e78",
   "metadata": {},
   "outputs": [],
   "source": [
    "# This Python 3 environment comes with many helpful analytics libraries installed\n",
    "# It is defined by the kaggle/python Docker image: https://github.com/kaggle/docker-python\n",
    "# For example, here's several helpful packages to load\n",
    "\n",
    "import numpy as np # linear algebra\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import re\n",
    "import string\n",
    "from nltk.stem.wordnet import WordNetLemmatizer\n",
    "from nltk.corpus import stopwords\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.naive_bayes import MultinomialNB\n",
    "from sklearn.svm import LinearSVC\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "\n",
    "from sklearn.metrics import accuracy_score, f1_score, recall_score, precision_score, roc_auc_score, roc_curve\n",
    "from sklearn.metrics import confusion_matrix\n",
    "from sklearn.model_selection import cross_val_score\n",
    "from sklearn.metrics import fbeta_score\n",
    "from statistics import mean\n",
    "from sklearn.metrics import hamming_loss\n",
    "from sklearn.model_selection import StratifiedKFold\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "from sklearn.model_selection import ShuffleSplit\n",
    "from sklearn.model_selection import learning_curve\n",
    "\n",
    "from sklearn.metrics import roc_auc_score, confusion_matrix\n",
    "import statistics\n",
    "from sklearn.metrics import recall_score\n",
    "\n",
    "from wordcloud import WordCloud\n",
    "from collections import Counter\n",
    "\n",
    "from sklearn.ensemble import AdaBoostClassifier\n",
    "from sklearn.ensemble import BaggingClassifier\n",
    "from sklearn.ensemble import GradientBoostingClassifier\n",
    "from sklearn.ensemble import VotingClassifier\n",
    "import xgboost as xgb\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "# Input data files are available in the read-only \"../input/\" directory\n",
    "# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n",
    "\n",
    "import os\n",
    "for dirname, _, filenames in os.walk('/kaggle/input'):\n",
    "    for filename in filenames:\n",
    "        print(os.path.join(dirname, filename))\n",
    "\n",
    "# You can write up to 20GB to the current directory (/kaggle/working/) that gets preserved as output when you create a version using \"Save & Run All\" \n",
    "# You can also write temporary files to /kaggle/temp/, but they won't be saved outside of the current session\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ab73646e",
   "metadata": {},
   "outputs": [],
   "source": [
    "train = pd.read_csv(\"/kaggle/input/jigsaw-toxic-comment-classification-challenge/train.csv.zip\")\n",
    "test = pd.read_csv(\"/kaggle/input/jigsaw-toxic-comment-classification-challenge/test.csv.zip\")\n",
    "train.head(3)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "83ff4db5",
   "metadata": {},
   "outputs": [],
   "source": [
    "class_names = ['toxic', 'severe_toxic', 'obscene', 'threat', 'insult', 'identity_hate']\n",
    "train[class_names].apply(lambda x: x.value_counts())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a16c9132",
   "metadata": {},
   "outputs": [],
   "source": [
    "train[class_names].apply(lambda x: x.value_counts(normalize=True))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "90929a01",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(12,4))\n",
    "sns.countplot(x=\"variable\", hue=\"value\", data=pd.melt(train[class_names]))\n",
    "\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4afe6fa7",
   "metadata": {},
   "outputs": [],
   "source": [
    "toxic_df = train[train[\"toxic\"] == 1]\n",
    "toxic_df = toxic_df[\"comment_text\"].reset_index(drop=True)\n",
    "\n",
    "toxic_text = \"\"\n",
    "\n",
    "for i in range(len(toxic_df)):\n",
    "    toxic_text += \" \" + toxic_df[i]\n",
    "    \n",
    "toxic_text[:100]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "30a6bdbe",
   "metadata": {},
   "outputs": [],
   "source": [
    "tokens = re.findall(r'\\w+', toxic_text)\n",
    "print(\"Number of toxic tokens = \"+\"{:,}\\n\".format(len(tokens)))\n",
    "print(tokens[:50])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fa3b44a4",
   "metadata": {},
   "outputs": [],
   "source": [
    "import nltk\n",
    "nltk.download('stopwords')\n",
    "stop_words = nltk.corpus.stopwords.words('english') # All English Stopwords\n",
    "#stop_words = set(stopwords.words('english'))\n",
    "\n",
    "tokens = [t.lower() for t in tokens if t.lower() not in stop_words]\n",
    "print(Counter(tokens).most_common(50))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "43337d8a",
   "metadata": {},
   "outputs": [],
   "source": [
    "text_wordcloud = \" \".join(tokens)\n",
    "cloud = WordCloud(background_color=\"white\", width=640, height=480, collocations = False).generate(text_wordcloud)\n",
    "\n",
    "plt.imshow(cloud)\n",
    "plt.axis(\"off\")\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2b4f372b",
   "metadata": {},
   "outputs": [],
   "source": [
    "s_toxic_df = train[train[\"severe_toxic\"] == 1]\n",
    "s_toxic_df = s_toxic_df[\"comment_text\"].reset_index(drop=True)\n",
    "s_toxic_text = \"\"\n",
    "for i in range(len(toxic_df)):\n",
    "    s_toxic_text += \" \" + toxic_df[i]\n",
    "\n",
    "\n",
    "some_frac_total_text = toxic_text + s_toxic_text \n",
    "print(\"Characters = \"+\"{:,}\".format(len(some_frac_total_text)))\n",
    "print(\"Words = \"+\"{:,}\".format(len(some_frac_total_text.split())))\n",
    "print(\"Unique words from first two = \"+\"{:,}\".format(len(set(some_frac_total_text.split()))))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5c777c77",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_text = train['comment_text']\n",
    "test_text = test['comment_text']\n",
    "all_text = pd.concat([train_text, test_text])\n",
    "all_text.head()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "937d34d4",
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "# To simplify our tasks, we will use TfidfVectorizer which is equivalent to CountVectorizer \n",
    "# followed by TfidfTransformer to convert a collection of text comments to a matrix of TF-IDF \n",
    "# features.\n",
    "# learn vocabulary and idf from all the text data \n",
    "word_vectorizer = TfidfVectorizer(\n",
    "    sublinear_tf=True,\n",
    "    strip_accents='unicode',\n",
    "    analyzer='word',\n",
    "    token_pattern=r'\\w{1,}',\n",
    "    stop_words='english',\n",
    "    ngram_range=(1, 1),\n",
    "    max_features=10000)\n",
    "\n",
    "word_vectorizer.fit(all_text)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8a11e1d7",
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "# transform words to document-term matrix\n",
    "train_features = word_vectorizer.transform(train_text)\n",
    "test_features = word_vectorizer.transform(test_text)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "41f296ec",
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "scores = []\n",
    "submission = pd.DataFrame.from_dict({'id': test['id']})\n",
    "for class_name in class_names: # We have six of these\n",
    "    train_target = train[class_name]\n",
    "    classifier = LogisticRegression(C=1, solver='sag')\n",
    "\n",
    "    cv_score = np.mean(cross_val_score(classifier, train_features, train_target, cv=3, scoring='roc_auc'))\n",
    "    scores.append(cv_score)\n",
    "    print('CV score for class {} is {}'.format(class_name, cv_score))\n",
    "\n",
    "    classifier.fit(train_features, train_target)\n",
    "    submission[class_name] = classifier.predict_proba(test_features)[:, 1]\n",
    "    \n",
    "\n",
    "print('Total CV score is {}'.format(np.mean(scores)))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d8648072",
   "metadata": {},
   "outputs": [],
   "source": [
    "train.drop('id', axis=1, inplace=True)\n",
    "\n",
    "labels = ['toxic', 'severe_toxic', 'obscene', 'threat', 'insult', 'identity_hate']\n",
    "bigX = train.drop(labels,axis=1)\n",
    "bigX = bigX.to_numpy().reshape(-1,) # It has only comment_text\n",
    "bigy = train[labels].to_numpy()\n",
    "bigX.shape, bigy.shape\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bd0a92f5",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "X_train_dev, X_test, y_train_dev, y_test = train_test_split(bigX, bigy,\n",
    "                                                    test_size=0.2)\n",
    "\n",
    "X_train, X_val, y_train, y_val = train_test_split(X_train_dev, y_train_dev,\n",
    "                                                    test_size=0.2)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a08b698a",
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras.preprocessing.text import Tokenizer\n",
    "from keras.preprocessing import sequence\n",
    "from keras.utils import pad_sequences\n",
    "max_words = 2000\n",
    "max_len = 200\n",
    "tok = Tokenizer(num_words=max_words)\n",
    "tok.fit_on_texts(bigX)\n",
    "sequences = tok.texts_to_sequences(X_train)\n",
    "sequences_matrix_train = pad_sequences(sequences,maxlen=max_len)\n",
    "sequences = tok.texts_to_sequences(X_test)\n",
    "sequences_matrix_test = pad_sequences(sequences,maxlen=max_len)\n",
    "sequences = tok.texts_to_sequences(X_val)\n",
    "sequences_matrix_val = pad_sequences(sequences,maxlen=max_len)\n",
    "sequences = tok.texts_to_sequences(bigX)\n",
    "sequences_matrix_big = pad_sequences(sequences,maxlen=max_len)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bd9f92e8",
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras import models\n",
    "from tensorflow.keras import layers\n",
    "\n",
    "model = models.Sequential()\n",
    "model.add(layers.Embedding(max_words,50,input_length=max_len, input_shape=[max_len]))\n",
    "model.add(layers.LSTM(64, dropout=0.2))\n",
    "model.add(layers.Dense(256, activation='relu'))\n",
    "model.add(layers.Dense(6, activation='sigmoid'))\n",
    "\n",
    "model.summary()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8e847f46",
   "metadata": {},
   "outputs": [],
   "source": [
    "model.compile(optimizer='rmsprop',\n",
    "              loss='binary_crossentropy',\n",
    "              metrics=['accuracy'])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "43f8c9d6",
   "metadata": {},
   "outputs": [],
   "source": [
    "history = model.fit(sequences_matrix_train,\n",
    "                    y_train,\n",
    "                    epochs=75,\n",
    "                    batch_size=512,\n",
    "                    validation_data=(sequences_matrix_val, y_val))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a8702f0f",
   "metadata": {},
   "outputs": [],
   "source": [
    "history_df = pd.DataFrame(history.history)\n",
    "history_df.head()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1947b8f5",
   "metadata": {},
   "outputs": [],
   "source": [
    "model.evaluate(sequences_matrix_test, y_test)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c968b7df",
   "metadata": {},
   "outputs": [],
   "source": [
    "id_col = test['id']\n",
    "test = test.drop('id', axis=1).to_numpy().reshape(-1,)\n",
    "sequences = tok.texts_to_sequences(test)\n",
    "sequences_matrix_test_final = pad_sequences(sequences,maxlen=max_len)\n",
    "y_pred = model.predict(sequences_matrix_test_final)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "43bfb238",
   "metadata": {},
   "outputs": [],
   "source": [
    "prediction_df = pd.DataFrame()\n",
    "prediction_df['id'] = id_col\n",
    "prediction_df[labels] = y_pred\n",
    "prediction_df\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "850b154b",
   "metadata": {},
   "outputs": [],
   "source": [
    "prediction_df.to_csv('submission.csv', index=False)\n"
   ]
  }
 ],
 "metadata": {},
 "nbformat": 4,
 "nbformat_minor": 5
}

{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2593f9e3",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from pathlib import Path"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "14c8aef0",
   "metadata": {},
   "outputs": [],
   "source": [
    "TRAIN_DATA_PATH = \"../input/tabular-playground-series-may-2022/train.csv\"\n",
    "TEST_DATA_PATH  = \"../input/tabular-playground-series-may-2022/test.csv\"\n",
    "fIG_SIZE = (8, 5)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "376d07b0",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "pd.set_option('display.max_colwidth', None)\n",
    "\n",
    "\n",
    "train = pd.read_csv(TRAIN_DATA_PATH) \n",
    "test = pd.read_csv(TEST_DATA_PATH) \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fdfd7070",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "\n",
    "\n",
    "def display_data_info(dict_df):\n",
    "    '''\n",
    "        Show how many rows and cols, \n",
    "        number of missing rows,\n",
    "        number of columns withs missing values,\n",
    "        number of duplicates\n",
    "    '''\n",
    "    \n",
    "    # Table column names\n",
    "    index = [\n",
    "        'No. rows'          , \n",
    "        'No. cols'          , \n",
    "        'No. null cols'     , \n",
    "        'No. missing values', \n",
    "        'No. duplicate rows', \n",
    "        'Float columns'     ,\n",
    "        'Int columns'       ,\n",
    "        'Object columns'    ,\n",
    "    ]\n",
    "    \n",
    "    # empty data\n",
    "    data = {}\n",
    "    \n",
    "    # looping over each dataframe\n",
    "    for name, df in dict_df.items():\n",
    "        \n",
    "        # getting dataframe info\n",
    "        num_rows, num_cols = df.shape                  # no. of rows , no. cols\n",
    "        num_null_cols      = np.sum(df.isna().sum()>0) # No. null cols\n",
    "        num_null_rows      = df.isna().sum().sum()     # no. missing values\n",
    "        num_duplic_rows    = np.sum(df.duplicated()>0) # no. duplicated rows\n",
    "        data_types         = df.dtypes.to_dict()       # data types\n",
    "        \n",
    "        # getting column of each type\n",
    "        float_cols         = []\n",
    "        int_cols           = []\n",
    "        obj_cols           = []\n",
    "        for col, t in data_types.items():\n",
    "            if t == 'float64' : float_cols.append(col)\n",
    "            elif t == 'int64' : int_cols.append(col)\n",
    "            else              : obj_cols.append(col)\n",
    "            \n",
    "        data[name] = [\n",
    "            num_rows        , \n",
    "            num_cols        , \n",
    "            num_null_cols   , \n",
    "            num_null_rows   , \n",
    "            num_duplic_rows , \n",
    "            float_cols      ,\n",
    "            int_cols        ,\n",
    "            obj_cols        ,\n",
    "        ]\n",
    "        \n",
    "    new_df = pd.DataFrame(data=data, index=index)\n",
    "    \n",
    "    display(new_df)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2324c425",
   "metadata": {},
   "outputs": [],
   "source": [
    "display_data_info({'train': train, 'test': test})\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7685b4a2",
   "metadata": {},
   "outputs": [],
   "source": [
    "def barchart(df, column):\n",
    "    '''draws a barchart based on the column name'''\n",
    "    ax = df[column].value_counts().head(10).plot.bar(figsize=fIG_SIZE)\n",
    "    ax.bar_label(ax.containers[0])\n",
    "    display(ax)\n",
    "    \n",
    "def pie(df, column):\n",
    "    '''draws a pie based on the column name'''\n",
    "    display(df[column].value_counts().head(10).plot(kind='pie', autopct='%1.1f%%', figsize=fIG_SIZE))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8b8d9af8",
   "metadata": {},
   "outputs": [],
   "source": [
    "barchart(train, 'target')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "45b262d7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# int columns\n",
    "train.hist(column=[\n",
    "    'f_07', 'f_08', \n",
    "    'f_09', 'f_10', \n",
    "    'f_11', 'f_12', \n",
    "    'f_13', 'f_14', \n",
    "    'f_15', 'f_16', \n",
    "    'f_17', 'f_18', \n",
    "    'f_29', 'f_30'\n",
    "], figsize=(20,15), bins=25);\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9ede65f6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# float columns\n",
    "train.hist(column=[\n",
    "    'f_00', 'f_01', \n",
    "    'f_02', 'f_03', \n",
    "    'f_04', 'f_05', \n",
    "    'f_06', 'f_19', \n",
    "    'f_20', 'f_21', \n",
    "    'f_22', 'f_23', \n",
    "    'f_24', 'f_25', \n",
    "    'f_26', 'f_28'\n",
    "], figsize=(20,15), bins=25);\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c4560db3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# object columns \n",
    "barchart(train, 'f_27')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "32ce01a0",
   "metadata": {},
   "outputs": [],
   "source": [
    "relevent_features = train.columns\n",
    "relevent_features\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1427e67c",
   "metadata": {},
   "outputs": [],
   "source": [
    "from collections import Counter\n",
    "\n",
    "def encode(df):\n",
    "    index = [\n",
    "        'A','B','C','D','E','F',\n",
    "        'G','H','I','J','K','L',\n",
    "        'M','N','O','P','Q','R',\n",
    "        'S','T',                       \n",
    "    ]\n",
    "    for col in index:\n",
    "        df[col] = 0\n",
    "    \n",
    "    for k, v in df['f_27'].iteritems():\n",
    "        alpha_count = Counter(v)\n",
    "        for l, c in alpha_count.items():\n",
    "            df.at[k, l] = c\n",
    "    \n",
    "    display(df.head())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ba2e9c4a",
   "metadata": {},
   "outputs": [],
   "source": [
    "relevent_train = train\n",
    "encode(relevent_train)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3e1079d2",
   "metadata": {},
   "outputs": [],
   "source": [
    "relevent_train = relevent_train.drop('f_27', axis=1)\n",
    "relevent_train = relevent_train.drop('id', axis=1)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "15b9bce3",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "\n",
    "y = relevent_train['target']\n",
    "X = relevent_train.drop('target', axis=1)\n",
    "\n",
    "X_train, X_valid, y_train, y_valid = train_test_split(\n",
    "    X, y, \n",
    "    test_size=0.2,\n",
    "    train_size=0.8, \n",
    "    shuffle=True,\n",
    "    random_state=42)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2a2cd17c",
   "metadata": {},
   "outputs": [],
   "source": [
    "pd.options.mode.chained_assignment = None\n",
    "\n",
    "f = [x for x in X_train.columns.values if x[0]==\"f\"]\n",
    "\n",
    "X_train['abs_sum'] = X_train.loc[:,f].abs().sum(axis=1)\n",
    "X_train['median']  = X_train.loc[:,f].median(axis=1)\n",
    "X_train['std']     = X_train.loc[:,f].std(axis=1)\n",
    "X_train['mean']    = X_train.loc[:,f].mean(axis=1)\n",
    "\n",
    "X_train.head()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "51c08e89",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_valid['abs_sum'] = X_valid.loc[:,f].abs().sum(axis=1)\n",
    "X_valid['median']  = X_valid.loc[:,f].median(axis=1)\n",
    "X_valid['std']     = X_valid.loc[:,f].std(axis=1)\n",
    "X_valid['mean']    = X_valid.loc[:,f].mean(axis=1)\n",
    "\n",
    "\n",
    "pd.options.mode.chained_assignment = 'warn'\n",
    "X_valid.head()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d27eaf4d",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import RobustScaler\n",
    "\n",
    "def robust_scale(X_t, X_v):\n",
    "    scaler = RobustScaler()\n",
    "    \n",
    "    return pd.DataFrame(scaler.fit_transform(X_t)), pd.DataFrame(scaler.transform(X_v))\n",
    "\n",
    "X_train_st, X_val_st = robust_scale(X_train, X_valid)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d222a3c5",
   "metadata": {},
   "outputs": [],
   "source": [
    "display_data_info({'train': X_train_st, 'test': X_val_st})\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f2804118",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "\n",
    "\n",
    "class Network(nn.Module):\n",
    "    def __init__(self, in_feature):\n",
    "        super().__init__()\n",
    "        \n",
    "        self.main = nn.Sequential(\n",
    "            nn.Linear(in_feature, 512),\n",
    "            nn.LeakyReLU(0.2, inplace=True),\n",
    "            nn.Dropout(0.3),\n",
    "            \n",
    "            nn.Linear(512, 256),\n",
    "            nn.LeakyReLU(0.2, inplace=True),\n",
    "            nn.Linear(256, 128),\n",
    "            nn.LeakyReLU(0.2, inplace=True),\n",
    "            nn.Linear(128, 128),\n",
    "            nn.LeakyReLU(0.2, inplace=True),\n",
    "            nn.Dropout(0.3),\n",
    "            \n",
    "            nn.Linear(128, 64),\n",
    "            nn.LeakyReLU(0.2, inplace=True),\n",
    "            nn.Dropout(0.3),\n",
    "\n",
    "            nn.Linear(64, 1),\n",
    "            nn.Sigmoid()\n",
    "        )\n",
    "        \n",
    "    \n",
    "    def forward(self, x):\n",
    "        x = self.main(x)\n",
    "        return x.view(-1) \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "796c6b87",
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch import optim\n",
    "\n",
    "device         = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "in_feature     = X_train.shape[1]\n",
    "\n",
    "model          = Network(in_feature)\n",
    "model.to(device)\n",
    "\n",
    "epochs         = 50\n",
    "batch_size     = 1024\n",
    "\n",
    "loss_function  = nn.BCELoss()\n",
    "optimizer      = optim.Adam(model.parameters(), lr=0.001, weight_decay=1e-10)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "427fc51a",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import StandardScaler\n",
    "\n",
    "class TPS2022(torch.utils.data.Dataset):\n",
    "    def __init__(self, X, Y):\n",
    "        self.X = torch.tensor(X.values,dtype=torch.float)\n",
    "        self.Y = torch.tensor(Y.values,dtype=torch.float)\n",
    "        \n",
    "    def __len__(self):\n",
    "        return len(self.Y)\n",
    "    \n",
    "    def __getitem__(self, idx):\n",
    "        return self.X[idx], self.Y[idx]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "919dfe1c",
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch.utils.data import DataLoader\n",
    "\n",
    "train_dataset = TPS2022(X_train_st, y_train)\n",
    "valid_dataset = TPS2022(X_val_st, y_valid)\n",
    "\n",
    "train_loader  = DataLoader(train_dataset, batch_size=batch_size, shuffle=True)\n",
    "valid_loader  = DataLoader(valid_dataset, batch_size=batch_size, shuffle=False)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d1279011",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_losses, valid_losses = [], []\n",
    "valid_loss_min = np.Inf\n",
    "\n",
    "for i in range(epochs):\n",
    "    tot_train_loss = 0\n",
    "    \n",
    "    model.train()\n",
    "    \n",
    "    for x, y in train_loader:\n",
    "        pred = model(x.to(device))\n",
    "        loss = loss_function(pred, y.to(device))\n",
    "        \n",
    "        optimizer.zero_grad()\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        \n",
    "        tot_train_loss += loss.item()\n",
    "        \n",
    "    else:\n",
    "        tot_valid_loss = 0\n",
    "        valid_correct = 0\n",
    "        \n",
    "        model.eval()\n",
    "        with torch.no_grad():\n",
    "        \n",
    "            for x, y in valid_loader:      \n",
    "                pred = model(x.to(device))\n",
    "                loss = loss_function(pred, y.to(device))\n",
    "                tot_valid_loss += loss.item()\n",
    "        \n",
    "        train_loss = tot_valid_loss / len(train_loader.dataset)\n",
    "        valid_loss = tot_valid_loss / len(valid_loader.dataset)\n",
    "        \n",
    "        train_losses.append(train_loss)\n",
    "        valid_losses.append(valid_loss)\n",
    "        \n",
    "        print(\"Epoch: {}/{}.. \".format(i+1, epochs),\n",
    "              \"Training Loss: {:.3f}.. \".format(train_loss),\n",
    "              \"Test Loss: {:.3f}.. \".format(valid_loss),\n",
    "              )\n",
    "        \n",
    "        if valid_loss <= valid_loss_min:\n",
    "            print('Validation loss decreased ({:.6f} --> {:.6f}).  Saving model ...'.format(\n",
    "            valid_loss_min,\n",
    "            valid_loss))\n",
    "            torch.save(model.state_dict(), 'model.pt')\n",
    "            valid_loss_min = valid_loss\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "99c1c503",
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "\n",
    "plt.plot(train_losses, label='Train Loss')\n",
    "plt.plot(valid_losses, label='Valid Loss')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c06ede34",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = Network(in_feature)\n",
    "model.load_state_dict(torch.load('model.pt'))\n",
    "\n",
    "model.to(device)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9ca9afc3",
   "metadata": {},
   "outputs": [],
   "source": [
    "feature = [f for f in relevent_features if 'f' in f]\n",
    "\n",
    "relevent_test = test.loc[:, feature]\n",
    "relevent_test.head()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d2d96065",
   "metadata": {},
   "outputs": [],
   "source": [
    "encode(relevent_test)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4ef8d340",
   "metadata": {},
   "outputs": [],
   "source": [
    "relevent_test = relevent_test.drop('f_27', axis=1)\n",
    "\n",
    "relevent_test['abs_sum'] = relevent_test.loc[:,f].abs().sum(axis=1)\n",
    "relevent_test['median']  = relevent_test.loc[:,f].median(axis=1)\n",
    "relevent_test['std']     = relevent_test.loc[:,f].std(axis=1)\n",
    "relevent_test['mean']    = relevent_test.loc[:,f].mean(axis=1)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d62a87d2",
   "metadata": {},
   "outputs": [],
   "source": [
    "relevent_test.head()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1872360f",
   "metadata": {},
   "outputs": [],
   "source": [
    "scaler = RobustScaler()\n",
    "    \n",
    "X_test_st = pd.DataFrame(scaler.fit_transform(relevent_test))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dab51c8b",
   "metadata": {},
   "outputs": [],
   "source": [
    "display_data_info({'test': X_test_st})\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a7968655",
   "metadata": {},
   "outputs": [],
   "source": [
    "class TestDataset(torch.utils.data.Dataset):\n",
    "    def __init__(self, X):\n",
    "        self.X = torch.tensor(X.values,dtype=torch.float)\n",
    "        \n",
    "    def __len__(self):\n",
    "        return len(self.X)\n",
    "    \n",
    "    def __getitem__(self, idx):\n",
    "        return self.X[idx]\n",
    "    \n",
    "    \n",
    "testset     = TestDataset(X_test_st)\n",
    "test_loader = DataLoader(testset, batch_size=1024, shuffle=False, num_workers=0)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c812f1a4",
   "metadata": {},
   "outputs": [],
   "source": [
    "preds_class = np.array([], dtype=int)\n",
    "\n",
    "with torch.no_grad():\n",
    "    for x in test_loader:\n",
    "        preds = model(x.to(device)).cpu()\n",
    "        preds_class = np.append(preds_class, preds)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a3fc6a13",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.DataFrame({\n",
    "    'id': test.id,\n",
    "    'target': preds_class\n",
    "})\n",
    "\n",
    "df = df.set_index('id')\n",
    "df.to_csv('submission.csv')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "64062d29",
   "metadata": {},
   "outputs": [],
   "source": [
    "df.head()\n"
   ]
  }
 ],
 "metadata": {},
 "nbformat": 4,
 "nbformat_minor": 5
}

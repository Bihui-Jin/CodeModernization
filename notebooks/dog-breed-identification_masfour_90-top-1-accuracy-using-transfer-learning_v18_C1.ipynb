{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ce863cb8",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from pathlib import Path"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7a15428f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# For data handling and manipulation\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import cv2\n",
    "\n",
    "# For Visualiztion\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "from IPython.display import clear_output\n",
    "\n",
    "\n",
    "# for model building and trining\n",
    "from keras import backend as K\n",
    "from keras.layers import Dense, Activation, Dropout, BatchNormalization, Input, Flatten, Conv2D, MaxPooling2D, Lambda, UpSampling2D, Concatenate\n",
    "from keras.models import Model\n",
    "from keras.optimizers import Adam\n",
    "from keras.callbacks import Callback, EarlyStopping, ReduceLROnPlateau\n",
    "from keras.applications.inception_resnet_v2 import InceptionResNetV2\n",
    "from keras.initializers import he_normal\n",
    "from keras.preprocessing.image import ImageDataGenerator\n",
    "\n",
    "# For organizing data\n",
    "import os\n",
    "import shutil\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4b49e4a2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# view sample images filenames - bash command\n",
    "!ls ../input/dog-breed-identification/train/ -U | head -5 \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d6287ea6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Firstly, let's use pandas to load the labels and see how they are mapped to data\n",
    "labels = pd.read_csv('../input/dog-breed-identification/labels.csv')\n",
    "labels.head(5)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6fee7745",
   "metadata": {},
   "outputs": [],
   "source": [
    "# get number of available classes\n",
    "classes = np.unique(labels.breed)\n",
    "classes_num = classes.size\n",
    "classes_num\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a504df77",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_dir = '../input/dog-breed-identification/train'  # the images directory\n",
    "images_names = os.listdir(train_dir)  # names of the files in the directory\n",
    "images_num = len(images_names)\n",
    "print(f'Number of images: {images_num}')  # Number of training images\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "540e37d0",
   "metadata": {},
   "outputs": [],
   "source": [
    "new_train_dir = '/root/new_train/'  # parent directoiry of the training set\n",
    "new_test_dir = '/root/new_test/'  # parent directory of the validation set\n",
    "new_valid_dir = '/root/new_valid/'  # parent directory of the test set\n",
    "!mkdir $new_train_dir\n",
    "!mkdir $new_test_dir\n",
    "!mkdir $new_valid_dir\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d55d473b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# for each of the parent directories of the sets, we'll create subdirectories for the breeds\n",
    "for sub_dir in classes:\n",
    "    os.mkdir(new_train_dir+sub_dir)\n",
    "    os.mkdir(new_test_dir+sub_dir)\n",
    "    os.mkdir(new_valid_dir+sub_dir)\n",
    "!ls $new_train_dir\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a55d1028",
   "metadata": {},
   "outputs": [],
   "source": [
    "labels_jpg = labels.copy(deep=True)\n",
    "labels_jpg['id'] += '.jpg'  # add .jpg to each image id to get its filename\n",
    "\n",
    "# group the images filenames of each breed\n",
    "grouped_ids = labels_jpg.groupby('breed')['id'].apply(list).to_dict()\n",
    "print(classes[0], grouped_ids[classes[0]])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d8aea152",
   "metadata": {},
   "outputs": [],
   "source": [
    "# specify the required split ratios\n",
    "test_split = 0.1\n",
    "valid_split = 0.2\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "18c69590",
   "metadata": {},
   "outputs": [],
   "source": [
    "# iterators to track the final sizes of the sets\n",
    "train_size = 0\n",
    "valid_size = 0\n",
    "test_size = 0\n",
    "\n",
    "# loop on the images of each breed and using the defined probabilities assign each image to one of the 3 sets\n",
    "for breed_idx, (breed, breed_images) in enumerate(grouped_ids.items()):\n",
    "    for img in breed_images:\n",
    "        rnd_prob = np.random.rand()  # give the current image a random number in the range [0, 1]\n",
    "        if rnd_prob <= test_split: \n",
    "            # copy to the corresponding breed subdirectory in the test directory\n",
    "            shutil.copy(train_dir+'/'+img, new_test_dir+'/'+breed) \n",
    "            test_size += 1\n",
    "            \n",
    "        elif rnd_prob <= (test_split + valid_split):\n",
    "            # copy to the corresponding breed subdirectory in the validation directory\n",
    "            shutil.copy(train_dir+'/'+img, new_valid_dir+'/'+breed)\n",
    "            valid_size += 1\n",
    "            \n",
    "        else:\n",
    "            # copy to the corresponding breed subdirectory in the training directory\n",
    "            shutil.copy(train_dir+'/'+img, new_train_dir+'/'+breed)\n",
    "            train_size += 1\n",
    "            \n",
    "    clear_output(wait=True)\n",
    "    print(f'Organized {breed_idx+1} out of {classes_num} breeds: {breed}')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "44b8e72d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# let's check the final sizes of the sets\n",
    "print(train_size, valid_size, test_size)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "686280a3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# let's check if the organizing process ended as we intended\n",
    "test_breed = classes[0]\n",
    "!ls $new_train_dir/$test_breed | head -5\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e7b92600",
   "metadata": {},
   "outputs": [],
   "source": [
    "# dimensions of images to use for plt.imshow\n",
    "width, height, channels = 512, 512, 3\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9a7977f2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# initialize images and labels samples\n",
    "images_samples = np.zeros((4, height, width, 3), dtype=float)\n",
    "samples_labels = []\n",
    "\n",
    "# get random 4 images\n",
    "rnd_indexes = np.random.randint(0, images_num, 4)\n",
    "for i, rnd_idx in enumerate(rnd_indexes):\n",
    "    img_filename = images_names[rnd_idx]\n",
    "    img_id = img_filename[:-4]\n",
    "    img_bgr = cv2.imread(train_dir + '/' + img_filename)  # loads the images channels in (blue, green, red) order\n",
    "    images_samples[i] = cv2.resize(src=img_bgr[:, :, [2, 1, 0]], dsize=(width, height)) / 255  # store the random image\n",
    "    img_label = labels.breed[labels.id == img_id].values[0]\n",
    "    samples_labels.append(img_label)  # store the random images' label\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9836af80",
   "metadata": {},
   "outputs": [],
   "source": [
    "# view the 4 samples\n",
    "fig, axs = plt.subplots(1, 4, figsize=(20, 5))\n",
    "for ax, img, label in zip(axs.ravel(), images_samples, samples_labels):\n",
    "    ax.imshow(img)\n",
    "    ax.axis('off')\n",
    "    ax.set_title(f'Class: {label}', size=15);\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "90e8399d",
   "metadata": {},
   "outputs": [],
   "source": [
    "norm_factor = 1 / 255\n",
    "\n",
    "# Augmentation Ranges\n",
    "transform_params = {\n",
    "    'featurewise_center': False,\n",
    "    'featurewise_std_normalization': False,\n",
    "    'samplewise_center': False,\n",
    "    'samplewise_std_normalization': False,\n",
    "    'rotation_range': 30, \n",
    "    'width_shift_range': 0.15,\n",
    "    'height_shift_range': 0.15,\n",
    "    'horizontal_flip': True,\n",
    "    'rescale': norm_factor\n",
    "}\n",
    "\n",
    "# the generator used for training - gives augmented images\n",
    "img_gen = ImageDataGenerator(**transform_params) \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c7c10cde",
   "metadata": {},
   "outputs": [],
   "source": [
    "# the generator used for validaiton - gives the images unchanged so that the validation error becomes a good\n",
    "# indication of the test error\n",
    "img_feed = ImageDataGenerator(rescale=1/255)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6a55d8c3",
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, axs = plt.subplots(2, 4, figsize=(20,10))  # let's see 4 augmentation examples\n",
    "fig.suptitle('Augmentation Results', size=32)\n",
    "\n",
    "for axs_col, img in enumerate(images_samples):\n",
    "    viz_transoform_params = {  # defined each iteration to get new augmentation values each time\n",
    "        'theta': np.random.randint(-transform_params['rotation_range'], transform_params['rotation_range']),\n",
    "        'tx': np.random.uniform(0, transform_params['width_shift_range']),\n",
    "        'ty': np.random.uniform(0, transform_params['height_shift_range']),\n",
    "        'flip_horizontal': np.random.choice([True, False], p=[0.5, 0.5])\n",
    "    }\n",
    "\n",
    "    aug_img = img_gen.apply_transform(img, viz_transoform_params)  # the same image after augmentation\n",
    "    \n",
    "    axs[0, axs_col].imshow(img);\n",
    "    axs[0, axs_col].axis('off')\n",
    "    axs[0, axs_col].set_title('Original Image', size=15)\n",
    "    \n",
    "    axs[1, axs_col].imshow(aug_img);\n",
    "    axs[1, axs_col].axis('off')\n",
    "    axs[1, axs_col].set_title('Augmented Image', size=15)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b6e86bfc",
   "metadata": {},
   "outputs": [],
   "source": [
    "# used to plot training curves (accuracy, loss) while model is training\n",
    "class Plotter(Callback):\n",
    "    def plot(self):  # Updates the graph\n",
    "        clear_output(wait=True)\n",
    "        fig, (ax1, ax2) = plt.subplots(1, 2, figsize=(16, 8))\n",
    "        \n",
    "        # plot the losses\n",
    "        ax1.plot(self.epochs, self.losses, label='train_loss')\n",
    "        ax1.plot(self.epochs, self.val_losses, label='val_loss')\n",
    "        \n",
    "        # plot the accuracies\n",
    "        ax2.plot(self.epochs, self.acc, label='train_acc')\n",
    "        ax2.plot(self.epochs, self.val_acc, label='val_acc')\n",
    "    \n",
    "        ax1.set_title(f'Loss vs Epochs')\n",
    "        ax1.set_xlabel(\"Epochs\")\n",
    "        ax1.set_ylabel(\"Loss\")\n",
    "        \n",
    "        ax2.set_title(f'Accuracy vs Epochs')\n",
    "        ax2.set_xlabel(\"Epoches\")\n",
    "        ax2.set_ylabel(\"Accuracy\")\n",
    "        \n",
    "        ax1.legend()\n",
    "        ax2.legend()\n",
    "        plt.show()\n",
    "        \n",
    "        # print out the accuracies at each epoch\n",
    "        print(f'Epoch #{self.epochs[-1]+1} >> train_acc={self.acc[-1]*100:.3f}%, train_loss={self.losses[-1]:.5f}')\n",
    "        print(f'Epoch #{self.epochs[-1]+1} >> val_acc={self.val_acc[-1]*100:.3f}%, val_loss={self.val_losses[-1]:.5f}')\n",
    "        \n",
    "    def on_train_begin(self, logs={}):\n",
    "        # initialize lists to store values from training\n",
    "        self.losses = []\n",
    "        self.val_losses = []\n",
    "        self.epochs = []\n",
    "        self.batch_no = []\n",
    "        self.acc = []\n",
    "        self.val_acc = []\n",
    "    \n",
    "    def on_epoch_end(self, epoch, logs={}):\n",
    "        # append values from the last epoch\n",
    "        self.losses.append(logs.get('loss'))\n",
    "        self.val_losses.append(logs.get('val_loss'))\n",
    "        self.acc.append(logs.get('acc'))\n",
    "        self.val_acc.append(logs.get('val_acc'))\n",
    "        self.epochs.append(epoch)\n",
    "        self.plot()  # update the graph\n",
    "        \n",
    "    def on_train_end(self, logs={}):\n",
    "        self.plot()\n",
    "        \n",
    "    def load_plot_data(self, data):\n",
    "        self.losses, self.val_losses, self.epochs, self.batch_no, self.acc, self.val_acc = data\n",
    "    \n",
    "    def get_plot_data(self):\n",
    "        return [self.losses, self.val_losses, self.epochs, self.batch_no, self.acc, self.val_acc]\n",
    "               \n",
    "plotter = Plotter()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9c4f38ad",
   "metadata": {},
   "outputs": [],
   "source": [
    "# used to decrease the learning rate if val_acc doesn't enhance\n",
    "plateau_reduce = ReduceLROnPlateau(monitor='val_loss', factor=0.01,\n",
    "                              patience=1, min_lr=1e-20)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a52c9fb9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# not used for early stopping, but to rollback to the best weights obtained during training\n",
    "e_stop = EarlyStopping(monitor='val_loss', patience=15, mode='min', restore_best_weights=True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9a555007",
   "metadata": {},
   "outputs": [],
   "source": [
    "callbacks = [plotter, plateau_reduce, e_stop]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c39208d5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# a Fully connected layer with activation, batchnorm and dropout\n",
    "def dense_block(x, neurons, layer_no):\n",
    "    x = Dense(neurons, kernel_initializer=he_normal(layer_no), name=f'topDense{layer_no}')(x)\n",
    "    x = Activation('relu', name=f'Relu{layer_no}')(x)\n",
    "    x = BatchNormalization(name=f'BatchNorm{layer_no}')(x)\n",
    "    x = Dropout(0.5, name=f'Dropout{layer_no}')(x)\n",
    "    return x\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "55b858ae",
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_model(shape):\n",
    "    input_layer = Input(shape, name='input_layer')  # input layer with given shape\n",
    "    \n",
    "    # load InceptionResNetV2 with initialized weights and remove final dense layers - frozen layers\n",
    "    incep_res = InceptionResNetV2(include_top=False, weights='imagenet', input_tensor=input_layer)\n",
    "    for layer in incep_res.layers:\n",
    "        layer.trainable = False\n",
    "\n",
    "    # pooling to reduce dimensionality of each feature map\n",
    "    pool = MaxPooling2D(pool_size=[3, 3], strides=[3, 3], padding='same')(incep_res.output)\n",
    "    flat1 = Flatten(name='Flatten1')(pool)\n",
    "    flat1_bn = BatchNormalization(name='BatchNormFlat')(flat1)\n",
    " \n",
    "    # dense layers after the InceptionResNetV2 initialized layers\n",
    "    dens1 = dense_block(flat1_bn, neurons=512, layer_no=1)\n",
    "    dens2 = dense_block(dens1, neurons=512, layer_no=2)\n",
    "    dens3 = dense_block(dens2, neurons=1024, layer_no=3)\n",
    "    \n",
    "    dens_final = Dense(classes_num, name='Dense4')(dens3)\n",
    "    output_layer = Activation('softmax', name='Softmax')(dens_final)\n",
    "    \n",
    "    model = Model(inputs=[input_layer], outputs=[output_layer])\n",
    "\n",
    "    return model\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "93633433",
   "metadata": {},
   "outputs": [],
   "source": [
    "# hyperparameters\n",
    "height, width, channels_num = 512, 512, 3\n",
    "learning_rate = 0.004\n",
    "epochs = 15\n",
    "batch_size = 32  # if increased you may run out of gpu memory - reduce image size if to increase the batch size\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "55cff1f8",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = create_model((height, width, channels_num))\n",
    "optimizer = Adam(learning_rate)\n",
    "\n",
    "model.compile(optimizer=optimizer, loss='categorical_crossentropy', metrics=['acc'])\n",
    "model.summary()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5b6890a9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# used to feed the model augmented training data after being loaded from the directory\n",
    "train_gen = img_gen.flow_from_directory(directory=new_train_dir, target_size=(height, width), color_mode='rgb', classes=list(classes), \n",
    "                                        class_mode='categorical', batch_size=batch_size, shuffle=True, interpolation='nearest')\n",
    "\n",
    "# used to feed the model augmented validation data after being loaded from the directory\n",
    "valid_gen = img_feed.flow_from_directory(directory=new_valid_dir, target_size=(height, width), color_mode='rgb', classes=list(classes), \n",
    "                                        class_mode='categorical', batch_size=batch_size, shuffle=True, interpolation='nearest')\n",
    "\n",
    "\n",
    "# # I'll load the decoder layers weights from the same model I trained on colab\n",
    "# # fit the model using the defined generators\n",
    "# model.fit_generator(train_gen, validation_data=valid_gen, epochs=epochs, \n",
    "#                         steps_per_epoch=train_size//batch_size + 1, \n",
    "#                         validation_steps=valid_size//batch_size + 1, callbacks=callbacks)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "635b660f",
   "metadata": {},
   "outputs": [],
   "source": [
    "!wget \"https://drive.google.com/uc?id=1-3Y-DB5uhOaY69pvVl5rmfirw9aKCYYB&export=download\" -O '/root/training_curves.npy'\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "efcbc7db",
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_data = np.load('/root/training_curves.npy', allow_pickle=True)\n",
    "plotter.load_plot_data(plot_data)  # load the data into the plotter\n",
    "plotter.plot()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e4702472",
   "metadata": {},
   "outputs": [],
   "source": [
    "# decoder_weights = {}\n",
    "# for layer in model.layers[-15:]:\n",
    "#     decoder_weights[layer.name] = layer.get_weights()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7cf31d29",
   "metadata": {},
   "outputs": [],
   "source": [
    "!wget \"https://drive.google.com/uc?id=1Omp4wFOWc2WslToduWAgBkyRv9poQVKb&export=download\" -O '/root/decoder_weights.npy'\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5e71bbd7",
   "metadata": {},
   "outputs": [],
   "source": [
    "decoder_weights = np.load('/root/decoder_weights.npy', allow_pickle=True).item()\n",
    "for layer_name, layer_weights in decoder_weights.items():\n",
    "    model.get_layer(layer_name).set_weights(layer_weights)  # set each layer of the decoder with its weights\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8c044ac5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# check the dictionary\n",
    "decoder_weights.keys()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3a2e106c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# define the test image generator that feeds the labelled test images to the model to evaluate it\n",
    "test_gen = ImageDataGenerator(rescale=1/255)\n",
    "test_flow = test_gen.flow_from_directory(new_test_dir,\n",
    "        target_size=(512, 512),\n",
    "        batch_size=1,\n",
    "        shuffle=False)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0c4de81b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# evaluate the model on the labelled test data\n",
    "metrics = model.evaluate_generator(test_flow, steps=test_size)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "03eff339",
   "metadata": {},
   "outputs": [],
   "source": [
    "m_names = model.metrics_names\n",
    "print(f'{m_names[0]} = {metrics[0]}\\n{m_names[1]} = {metrics[1]}')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ce92f73b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# check the corresponding classes of the encoding and ensure it matches the sample submission columns order\n",
    "one_hot_map = train_gen.class_indices\n",
    "one_hot_map\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a53e4d4b",
   "metadata": {},
   "outputs": [],
   "source": [
    "input_dir = '../input/dog-breed-identification'\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0713c51b",
   "metadata": {},
   "outputs": [],
   "source": [
    "test_names = os.listdir(input_dir+'/test')  # names of the files in the directory\n",
    "test_names.sort()\n",
    "test_size = len(test_names)\n",
    "test_size  # number of test images to predict their labels\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "26e6f31f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# this flow just returns the test images, one by one, in order\n",
    "test_flow = test_gen.flow_from_directory(input_dir,\n",
    "        target_size=(512, 512),\n",
    "        batch_size=1,\n",
    "        shuffle=False,\n",
    "        classes=['test'])  # added test folder as class because keras' flow needs subdirectories hierarchy\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4d74572b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# # obtain the model's predictions\n",
    "# y_pred = model.predict_generator(test_flow, steps=test_size)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "095af7c3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# # check the shape\n",
    "# y_pred.shape\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "eb189532",
   "metadata": {},
   "outputs": [],
   "source": [
    "# submission = pd.DataFrame(data=y_pred, columns=classes)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ba0f2ac0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# submission.insert(0, \"id\", test_names, True) \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "951ea782",
   "metadata": {},
   "outputs": [],
   "source": [
    "# submission.id = submission.id.apply(lambda x: x[:-4])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9d10e077",
   "metadata": {},
   "outputs": [],
   "source": [
    "# # check the submission is in the required format\n",
    "# submission.head(5)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "57629b66",
   "metadata": {},
   "outputs": [],
   "source": [
    "# # save the submission\n",
    "# submission.to_csv('submission_file.csv', index=False)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "66a33c10",
   "metadata": {},
   "outputs": [],
   "source": [
    "# download the submission file obtained from colab\n",
    "!wget 'https://drive.google.com/uc?id=18IQ9WVf1KcVTgwTgGZXKzx61W0ISayI8&export=download' -O 'submission_colab.csv'\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7e73f55a",
   "metadata": {},
   "outputs": [],
   "source": [
    " \n"
   ]
  }
 ],
 "metadata": {},
 "nbformat": 4,
 "nbformat_minor": 5
}

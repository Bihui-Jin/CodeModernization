{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "fc925654",
      "metadata": {},
      "outputs": [],
      "source": [
        "import pandas as pd\n",
        "from pathlib import Path"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "676b6abb",
      "metadata": {},
      "outputs": [],
      "source": [
        "# This Python 3 environment comes with many helpful analytics libraries installed\n",
        "# It is defined by the kaggle/python Docker image: https://github.com/kaggle/docker-python\n",
        "# For example, here's several helpful packages to load\n",
        "\n",
        "import numpy as np # linear algebra\n",
        "import pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\n",
        "\n",
        "# Input data files are available in the read-only \"../input/\" directory\n",
        "# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n",
        "\n",
        "import os\n",
        "for dirname, _, filenames in os.walk('/kaggle/input'):\n",
        "    for filename in filenames:\n",
        "        print(os.path.join(dirname, filename))\n",
        "\n",
        "# You can write up to 20GB to the current directory (/kaggle/working/) that gets preserved as output when you create a version using \"Save & Run All\" \n",
        "# You can also write temporary files to /kaggle/temp/, but they won't be saved outside of the current session\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "2c07f8fb",
      "metadata": {},
      "outputs": [],
      "source": [
        "import re\n",
        "import nltk\n",
        "from tqdm.notebook import tqdm\n",
        "from nltk.corpus import stopwords\n",
        "from nltk.stem.snowball import SnowballStemmer\n",
        "from nltk.tokenize.regexp import RegexpTokenizer\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.feature_extraction.text import TfidfVectorizer\n",
        "\n",
        "from sklearn.metrics import *\n",
        "from sklearn.pipeline import Pipeline\n",
        "from sklearn.tree import DecisionTreeClassifier\n",
        "from catboost import CatBoostClassifier\n",
        "from sklearn.linear_model import LogisticRegression\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "1f75047f",
      "metadata": {},
      "outputs": [],
      "source": [
        "stop_words = stopwords.words('english')\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "fad63fd8",
      "metadata": {},
      "outputs": [],
      "source": [
        "pd.options.display.max_columns = None\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "871efeb4",
      "metadata": {},
      "outputs": [],
      "source": [
        "df = pd.read_csv('/kaggle/input/jigsaw-toxic-comment-classification-challenge/train.csv.zip')\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "71e5e2dd",
      "metadata": {},
      "outputs": [],
      "source": [
        "# оставляю только буквы и цифры\n",
        "df['clean_text'] = df.comment_text.apply(\n",
        "    lambda row: re.sub(r'[^a-z0-9]+', ' ', row.lower()).strip()\n",
        ")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "1a3c3542",
      "metadata": {},
      "outputs": [],
      "source": [
        "stemmer = SnowballStemmer(\"english\")\n",
        "tokenizer = RegexpTokenizer(r'\\w{2,}')\n",
        "\n",
        "def preprocessing(text):\n",
        "    new_words = tokenizer.tokenize(text)\n",
        "    new_list = []\n",
        "    for w in new_words:\n",
        "        if w not in stop_words:\n",
        "            w = stemmer.stem(w)\n",
        "            new_list.append(w)\n",
        "    new_list = ' '.join(new_list)\n",
        "    return new_list\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "52e2004b",
      "metadata": {},
      "outputs": [],
      "source": [
        "corpus = [preprocessing(text) for text in tqdm(df.clean_text)]\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "48124127",
      "metadata": {},
      "outputs": [],
      "source": [
        "df['corpus'] = corpus\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "56ad678a",
      "metadata": {},
      "outputs": [],
      "source": [
        "df.sample(5)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "ad4b88b6",
      "metadata": {},
      "outputs": [],
      "source": [
        "# features = corpus\n",
        "# target_cols = ['toxic', 'severe_toxic', 'obscene', 'threat', 'insult']\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "efd02f75",
      "metadata": {},
      "outputs": [],
      "source": [
        "# for col in target_cols:\n",
        "#     df.loc[df[col] == 1, 'target'] = col\n",
        "\n",
        "# df['target'].fillna(0, inplace=True)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "688adeab",
      "metadata": {},
      "outputs": [],
      "source": [
        "X_train, X_test = train_test_split(\n",
        "    df['corpus'], test_size = 0.4, random_state = 2024\n",
        ") \n",
        "\n",
        "X_valid, X_test = train_test_split(\n",
        "    X_test, test_size = 0.5, random_state = 2024\n",
        ") \n",
        "\n",
        "print('train size', X_valid.shape)\n",
        "print('test size', X_test.shape)\n",
        "print('train size', X_train.shape)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "25509ba9",
      "metadata": {},
      "outputs": [],
      "source": [
        "vec = TfidfVectorizer(stop_words=stop_words)\n",
        "features_train = vec.fit_transform(X_train)\n",
        "features_test = vec.transform(X_test)\n",
        "features_valid = vec.transform(X_valid)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "6479ee81",
      "metadata": {},
      "outputs": [],
      "source": [
        "target_cols = ['toxic', 'severe_toxic', 'obscene', 'threat', 'insult', 'identity_hate']\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "f70a2f20",
      "metadata": {},
      "outputs": [],
      "source": [
        "for col in target_cols:\n",
        "    check_proportion_df = pd.concat([\n",
        "    df[col].value_counts(normalize=True), \n",
        "        df.loc[X_train.index, col].value_counts(normalize=True),\n",
        "        df.loc[X_test.index, col].value_counts(normalize=True)\n",
        "    ], axis=1)\n",
        "\n",
        "    check_proportion_df.columns = ['full', 'train', 'test']\n",
        "    \n",
        "    print(col)\n",
        "    display(check_proportion_df)\n",
        "    print('\\n'*2)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "ce3d02d2",
      "metadata": {},
      "outputs": [],
      "source": [
        "models_list = []\n",
        "for col in tqdm(target_cols):\n",
        "    clf = LogisticRegression(class_weight='balanced', n_jobs=-1)\n",
        "    clf.fit(features_train, df.loc[X_train.index, col])\n",
        "    \n",
        "    models_list += [(col, clf)]\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "2b765f04",
      "metadata": {},
      "outputs": [],
      "source": [
        "for item in models_list:\n",
        "    col, clf = item\n",
        "    print(col)\n",
        "    print(f'train f1: {f1_score(df.loc[X_train.index, col], clf.predict(features_train))}')\n",
        "    print(f'test f1: {f1_score(df.loc[X_test.index, col], clf.predict(features_test))}')\n",
        "    print(f'valid f1: {f1_score(df.loc[X_valid.index, col], clf.predict(features_valid))}' + '\\n'*2)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "78cdf01f",
      "metadata": {},
      "outputs": [],
      "source": [
        "full_features = vec.fit_transform(df['corpus'])\n",
        "\n",
        "models_list = []\n",
        "for col in tqdm(target_cols):\n",
        "    clf = LogisticRegression(class_weight='balanced', n_jobs=-1)\n",
        "    clf.fit(full_features, df[col])\n",
        "    models_list += [(col, clf)]\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "bd4b61b4",
      "metadata": {},
      "outputs": [],
      "source": [
        "test = pd.read_csv('/kaggle/input/jigsaw-toxic-comment-classification-challenge/test.csv.zip')\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "633044a4",
      "metadata": {},
      "outputs": [],
      "source": [
        "# оставляю только буквы и цифры\n",
        "test['clean_text'] = test.comment_text.apply(\n",
        "    lambda row: re.sub(r'[^a-z0-9]+', ' ', row.lower()).strip()\n",
        ")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "aa085de8",
      "metadata": {},
      "outputs": [],
      "source": [
        "test['corpus'] = [preprocessing(text) for text in tqdm(test.clean_text)]\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "98ac9bcd",
      "metadata": {},
      "outputs": [],
      "source": [
        "corpus = vec.transform(test['corpus'])\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "37ba6663",
      "metadata": {},
      "outputs": [],
      "source": [
        "for item in models_list:\n",
        "    col, clf = item\n",
        "    test[col] = clf.predict_proba(corpus)[:, 1]\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "5b7fecba",
      "metadata": {},
      "outputs": [],
      "source": [
        "test.sample(10)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "f9ce818e",
      "metadata": {},
      "outputs": [],
      "source": [
        "test[['id'] + target_cols].to_csv('submission_combined.csv', index=False)\n"
      ]
    }
  ],
  "metadata": {},
  "nbformat": 4,
  "nbformat_minor": 5
}
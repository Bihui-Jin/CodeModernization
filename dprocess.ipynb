{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "6a921681",
   "metadata": {},
   "source": [
    "# Cope scripts w/ input to destination"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5d813dc3",
   "metadata": {},
   "outputs": [],
   "source": [
    "from glob import glob\n",
    "from pathlib import Path\n",
    "import shutil, os\n",
    "from tqdm import tqdm\n",
    "\n",
    "src_list = glob(\"/home/b27jin/CodeModernization/notebooks/*.ipynb\")\n",
    "dst_dir = Path(\"/home/b27jin/CodeModernization/notebooks_w_output\")\n",
    "dst_dir.mkdir(parents=True, exist_ok=True)\n",
    "\n",
    "copied, missing = 0, []\n",
    "for file in tqdm(src_list):\n",
    "    base = Path(file).stem\n",
    "    src = Path(f\"/home/b27jin/mle-bench-internal/docker-test/scripts_out_all/{base}.ipynb\")\n",
    "    dst = dst_dir / f\"{base}.ipynb\"\n",
    "\n",
    "    if src.exists():\n",
    "        shutil.copy2(src, dst)\n",
    "        copied += 1\n",
    "        # print(f\"Copied: {src} -> {dst}\")\n",
    "    else:\n",
    "        missing.append(str(src))\n",
    "\n",
    "print(f\"\\nDone. Copied {copied}/{len(src_list)} files.\")\n",
    "if missing:\n",
    "    print(\"Missing sources:\")\n",
    "    for m in missing:\n",
    "        print(f\"  {m}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7d9ec58f",
   "metadata": {},
   "source": [
    "# Create a json file including file info"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "27146ee0",
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "from pathlib import Path\n",
    "from tqdm import tqdm\n",
    "from glob import glob\n",
    "import datetime, re\n",
    "\n",
    "src_list = glob(\"/home/b27jin/CodeModernization/notebooks/*.ipynb\")\n",
    "\n",
    "with open(\"/home/b27jin/mle-bench-internal/docker-test/mlebench_score.json\", \"r\") as f:\n",
    "    score_content = json.load(f)\n",
    "\n",
    "with open(\"/home/b27jin/CodeModernization/kernel.json\", \"r\") as f:\n",
    "    kernel_content = json.load(f)\n",
    "\n",
    "info = {}\n",
    "for file in tqdm(src_list):\n",
    "    key = Path(file).stem + \".ipynb\"\n",
    "    compt = key.split(\"_\")[0]\n",
    "    submission_id = \"_\".join(Path(file).stem.split(\"_\")[1:]) + \".html\"\n",
    "    # print(key, compt, submission_id)\n",
    "\n",
    "    info[key] = {}\n",
    "    is_buggy = False if \"status\" in score_content[key] else True\n",
    "    passed = True if \"status\" in score_content[key] else False\n",
    "\n",
    "    if passed:\n",
    "        with open(f\"/home/b27jin/mle-bench-internal/docker-test/scripts_scores/{Path(file).stem}.json\", \"r\", encoding=\"utf-8\") as f:\n",
    "            # Read the entire file content, which is a single JSON string literal\n",
    "            file_content_string = f.read()\n",
    "            # First, parse the outer string literal to get the inner content\n",
    "            inner_content = json.loads(file_content_string)\n",
    "            # Find the start of the JSON object within the inner content\n",
    "            # This handles cases where there's leading text/logs.\n",
    "            match = re.search(r'{\\s*\"competition_id\":', inner_content)\n",
    "            if not match:\n",
    "                raise ValueError(\"Could not find JSON object in file content\")\n",
    "            # Extract the JSON part of the string from where the match started\n",
    "            json_string = inner_content[match.start():]\n",
    "            # Now, parse the actual JSON object\n",
    "            score_data = json.loads(json_string)\n",
    "    measured_score = score_data['score'] if passed else None\n",
    "    reported_score = float(kernel_content[compt][submission_id]['ps']) if \"ps\" in kernel_content[compt][submission_id] else None\n",
    "    \n",
    "    if isinstance(reported_score, float) and isinstance(measured_score, float) and reported_score != 0.0:\n",
    "        thrus = abs((measured_score-reported_score)/reported_score) \n",
    "    else:\n",
    "        thrus = None\n",
    "    replicable = True if thrus and thrus <= 0.5 else False\n",
    "\n",
    "    year = kernel_content[compt][submission_id]['year']\n",
    "    month = kernel_content[compt][submission_id]['month']\n",
    "    day = kernel_content[compt][submission_id]['date']\n",
    "    creation = datetime.datetime(year, month, day).strftime('%m/%d/%Y')\n",
    "    info[key] = {\n",
    "        \"is_buggy\": is_buggy,\n",
    "        \"passed\": passed,\n",
    "        \"measured_score\": measured_score,\n",
    "        \"reported_score\": reported_score,\n",
    "        \"replicable\": replicable,\n",
    "        \"thrus\": thrus,\n",
    "        \"creation\": creation\n",
    "    }\n",
    "\n",
    "with open(\"sampled_notebook_info.json\", \"w\", encoding=\"utf-8\") as f:\n",
    "    json.dump(info, f, ensure_ascii=False, indent=2)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "85cf8337",
   "metadata": {},
   "source": [
    "# nb stats"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "4ab49574",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 12036 entities in the JSON file\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 12036/12036 [03:31<00:00, 56.93it/s] "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Timeout Notebooks: 456\n",
      "Notebooks with errors: 8778\n",
      "    - w/o csv: 6113\n",
      "    - w/ csv (replicable): 2035\n",
      "    - w/ csv (non-replicable): 630\n",
      "Notebooks without errors: 2802\n",
      "    - w/o csv: 183\n",
      "    - w/ csv (replicable): 2374\n",
      "    - w/ csv (non-replicable): 245\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "import json\n",
    "import os\n",
    "import re\n",
    "from pathlib import Path\n",
    "from tqdm import tqdm\n",
    "\n",
    "# Read the JSON file\n",
    "json_path = \"/home/b27jin/mle-bench-internal/docker-test/executable_files_w_timer_parrallel_full.json\"\n",
    "scripts_dir = \"/home/b27jin/mle-bench-internal/docker-test/scripts_out_all\"\n",
    "\n",
    "with open(\"/home/b27jin/mle-bench-internal/docker-test/mlebench_score.json\", \"r\") as f:\n",
    "    score_content = json.load(f)\n",
    "with open(\"/home/b27jin/CodeModernization/kernel.json\", \"r\") as f:\n",
    "    kernel_content = json.load(f)\n",
    "    \n",
    "def get_score(file):\n",
    "    key = Path(file).stem + \".ipynb\"\n",
    "    passed = True if \"status\" in score_content[key] else False\n",
    "    if passed:\n",
    "        with open(f\"/home/b27jin/mle-bench-internal/docker-test/scripts_scores/{Path(file).stem}.json\", \"r\", encoding=\"utf-8\") as f:\n",
    "                # Read the entire file content, which is a single JSON string literal\n",
    "                file_content_string = f.read()\n",
    "                # First, parse the outer string literal to get the inner content\n",
    "                inner_content = json.loads(file_content_string)\n",
    "                # Find the start of the JSON object within the inner content\n",
    "                # This handles cases where there's leading text/logs.\n",
    "                match = re.search(r'{\\s*\"competition_id\":', inner_content)\n",
    "                if not match:\n",
    "                    raise ValueError(\"Could not find JSON object in file content\")\n",
    "                # Extract the JSON part of the string from where the match started\n",
    "                json_string = inner_content[match.start():]\n",
    "                # Now, parse the actual JSON object\n",
    "                score_data = json.loads(json_string)\n",
    "    measured_score = score_data['score'] if passed else None\n",
    "    return measured_score\n",
    "\n",
    "def is_replicable(entity,measured_score):\n",
    "    compt = entity.split(\"_\")[0]\n",
    "    submission_id = \"_\".join(Path(entity).stem.split(\"_\")[1:]) + \".html\"\n",
    "    reported_score = float(kernel_content[compt][submission_id]['ps']) if \"ps\" in kernel_content[compt][submission_id] else None\n",
    "\n",
    "    if isinstance(reported_score, float) and isinstance(measured_score, float) and reported_score != 0.0:\n",
    "        thrus = abs((measured_score-reported_score)/reported_score) \n",
    "    else:\n",
    "        thrus = None\n",
    "    replicable = True if thrus and thrus <= 0.5 else False\n",
    "\n",
    "    return replicable\n",
    "\n",
    "error_notebooks = []\n",
    "error_notebooks_no_csv = []\n",
    "error_notebooks_csv_overThr = []\n",
    "error_notebooks_csv_belowThr = []\n",
    "\n",
    "no_error_notebooks = []\n",
    "no_error_notebooks_no_csv = []\n",
    "no_error_notebooks_csv_overThr = []\n",
    "no_error_notebooks_csv_belowThr = []\n",
    "\n",
    "timeout_notebooks = []\n",
    "\n",
    "with open(json_path, 'r') as f:\n",
    "    data = json.load(f)\n",
    "\n",
    "print(f\"Found {len(data)} entities in the JSON file\")\n",
    "\n",
    "# Check each entity\n",
    "for entity, info in tqdm(data.items()):\n",
    "    # Check if status not exists\n",
    "    if 'status' not in info and 'execution_time' in info and info['execution_time'] >= 600:\n",
    "        timeout_notebooks.append(entity)\n",
    "    else:\n",
    "        # Check if the script file exists\n",
    "        script_path = os.path.join(scripts_dir, entity)\n",
    "        if os.path.exists(script_path):\n",
    "            # Try to read and check for errors in the script\n",
    "            # Iterate over all notebook files in output_dir\n",
    "            try:\n",
    "                nb = json.loads(Path(script_path).read_text(encoding=\"utf-8\"))\n",
    "            except Exception as e:\n",
    "                print(f\"Failed to load {script_path.name}: {e}\")\n",
    "                continue\n",
    "\n",
    "            # Scan cells for any error outputs\n",
    "            has_error = False\n",
    "            for cell in nb.get(\"cells\", []):\n",
    "                if cell.get(\"cell_type\") != \"code\":\n",
    "                    continue\n",
    "                for out in cell.get(\"outputs\", []):\n",
    "                    if out.get(\"output_type\") == \"error\":\n",
    "                        error_notebooks.append(entity)\n",
    "                        measured_score = get_score(script_path)\n",
    "                        if measured_score==None:\n",
    "                            error_notebooks_no_csv.append(entity)\n",
    "                        else:\n",
    "                            replicable = is_replicable(entity, measured_score)\n",
    "                            if replicable:\n",
    "                                error_notebooks_csv_belowThr.append(entity)\n",
    "                            else:\n",
    "                                error_notebooks_csv_overThr.append(entity)\n",
    "                        \n",
    "\n",
    "                        has_error = True\n",
    "                        break\n",
    "                if has_error:\n",
    "                    break\n",
    "            \n",
    "            # If no errors found, add to no_error_notebooks\n",
    "            if not has_error:\n",
    "                no_error_notebooks.append(entity)\n",
    "                measured_score = get_score(script_path)\n",
    "                if measured_score==None:\n",
    "                    no_error_notebooks_no_csv.append(entity)\n",
    "                else:\n",
    "                    replicable = is_replicable(entity, measured_score)\n",
    "                    if replicable:\n",
    "                        no_error_notebooks_csv_belowThr.append(entity)\n",
    "                    else:\n",
    "                        no_error_notebooks_csv_overThr.append(entity)\n",
    "\n",
    "        else:\n",
    "            print(f\"Script NOT FOUND: {script_path}\")\n",
    "\n",
    "\n",
    "print(f\"Timeout Notebooks: {len(timeout_notebooks)}\")\n",
    "print(f\"Notebooks with errors: {len(error_notebooks)}\")\n",
    "print(f\"    - w/o csv: {len(error_notebooks_no_csv)}\")\n",
    "print(f\"    - w/ csv (replicable): {len(error_notebooks_csv_belowThr)}\")\n",
    "print(f\"    - w/ csv (non-replicable): {len(error_notebooks_csv_overThr)}\")\n",
    "print(f\"Notebooks without errors: {len(no_error_notebooks)}\")\n",
    "print(f\"    - w/o csv: {len(no_error_notebooks_no_csv)}\")\n",
    "print(f\"    - w/ csv (replicable): {len(no_error_notebooks_csv_belowThr)}\")\n",
    "print(f\"    - w/ csv (non-replicable): {len(no_error_notebooks_csv_overThr)}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cef21f2d",
   "metadata": {},
   "source": [
    "# Stats of all collected scripts"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "0aed04bf",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total entries: 151236\n",
      "Total filtered entries: 12197\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 12197/12197 [01:59<00:00, 102.33it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "12043 valid scripts\n",
      "r_count=154\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "import json\n",
    "import os\n",
    "import re\n",
    "import html\n",
    "import random\n",
    "import inspect\n",
    "from tqdm import tqdm\n",
    "import nbformat\n",
    "from nbformat.v4 import new_notebook, new_markdown_cell, new_code_cell\n",
    "\n",
    "with open(\"/home/b27jin/mle-bench-internal/docker-test/executable_files_stats.json\", \"r\", encoding=\"utf-8\") as f:\n",
    "    data = list(json.load(f).keys())\n",
    "\n",
    "def read_html_content(file_path, nb=None):\n",
    "    \"\"\"Read the content of an HTML file and append code cells to notebook if provided\"\"\"\n",
    "\n",
    "    with open(file_path, \"r\", encoding=\"utf-8\") as file:\n",
    "        content = file.read()\n",
    "\n",
    "        # Find all code blocks with highlight hl-ipython3 class\n",
    "        highlight_blocks = re.findall(r'<div class=\"highlight hl-ipython3\">(.*?)</div>', content, re.DOTALL)\n",
    "        \n",
    "        # Process all input areas as before for backward compatibility\n",
    "        input_areas = re.findall(r'<div class=\"input_area\">(.*?)</div>', content, re.DOTALL)\n",
    "        input_areas = \"\".join(input_areas) if input_areas else \"\"\n",
    "        input_areas = re.sub(r' *<pre>', '<pre>', input_areas)\n",
    "        \n",
    "        # If notebook object provided, add each code block as a cell\n",
    "        if nb is not None:\n",
    "            # nb.cells.append(new_code_cell('%pip install Unidecode monai ttach optuna optuna-integration'))\n",
    "            nb.cells.append(new_code_cell('import pandas as pd\\nfrom pathlib import Path'))\n",
    "            for block in highlight_blocks:\n",
    "                # Extract code from the highlight block\n",
    "                code_match = re.search(r'<pre>(.*?)</pre>', block, re.DOTALL)\n",
    "                if code_match:\n",
    "                    # Clean up the code\n",
    "                    code_text = html.unescape(code_match.group(1))\n",
    "                    raw_code = assemble_code_regex(code_text)\n",
    "                    # code = inspect.cleandoc(raw_code)\n",
    "                    nb.cells.append(new_code_cell(raw_code))\n",
    "        \n",
    "        return input_areas\n",
    "    \n",
    "def assemble_code_regex(html_snippet: str) -> str:\n",
    "    \"\"\"\n",
    "    Uses a regular expression to remove HTML tags from the snippet and unescapes HTML entities.\n",
    "    \"\"\"\n",
    "    # Unescape any HTML entities (if present)\n",
    "    code = html.unescape(html_snippet)\n",
    "    # Remove all HTML tags using regex\n",
    "    code = re.sub(r'</?[a-zA-Z][^>]*>', '', code)\n",
    "\n",
    "    return code\n",
    "\n",
    "# parent = 'C:\\\\Users\\\\b27jin\\\\Documents\\\\mle-bench-internal\\\\fetch\\\\competitions'\n",
    "parent = \"/home/b27jin/mle-bench-internal/fetch/competitions\"\n",
    "\n",
    "# 1. Load the JSON data\n",
    "with open(\"/home/b27jin/CodeModernization/kernel.json\", \"r\", encoding=\"utf-8\") as f:\n",
    "    data = json.load(f)\n",
    "print(f\"Total entries: {sum([len(files) for comp, files in data.items()])}\")\n",
    "\n",
    "# 2. Flatten & filter entries\n",
    "filtered = []\n",
    "for comp, files in data.items():\n",
    "    for fname, info in files.items():\n",
    "        if info['year'] >= 2019 and \"ps\" in info and info['runtime'] <= 600 and len(info['datasets'])<=1:\n",
    "            # keep a reference to competition and filename if you need them\n",
    "            filtered.append((comp, fname))\n",
    "\n",
    "print(f\"Total filtered entries: {len(filtered)}\")\n",
    "\n",
    "r_count = 0\n",
    "valid_scripts = []\n",
    "for comp, fname in tqdm(filtered):\n",
    "    path = os.path.join(parent, comp, 'html', fname)\n",
    "\n",
    "    # Create notebook first\n",
    "    nb = new_notebook()\n",
    "\n",
    "    # Pass notebook to read_html_content to add cells directly\n",
    "    content = read_html_content(path, nb)\n",
    "\n",
    "    # If no cells were added, add the whole content as one cell\n",
    "    if len(nb.cells) != 1:\n",
    "       valid_scripts.append(f\"{comp}_{fname.split('.html')[0]}.ipynb\")\n",
    "    else:\n",
    "        r_count += 1\n",
    "\n",
    "\n",
    "print(f'{len(valid_scripts)} valid scripts')\n",
    "print(f'{r_count=}')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "06a9d6b9",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 12036/12036 [00:00<00:00, 4799186.51it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "12036 files in scripts_full\n",
      "12043 valid scripts\n",
      "In files_only but not in valid_scripts: 4\n",
      "   osic-pulmonary-fibrosis-progression_fflorio_osic-starter-in-r-preprocessing-with-recipes_v7_C1.ipynb\n",
      "   spaceship-titanic_draganpinsent98_spaceship-titanic-r-glm-rf-dt-nb_v29_C1.ipynb\n",
      "   spaceship-titanic_draganpinsent98_spaceship-titanic-r-glm-rf-dt-nb_v30_C1.ipynb\n",
      "   spaceship-titanic_yiukitcheung_spaceship-titanic-r-0-804-accuracy_v21_C1.ipynb\n",
      "In valid_scripts but not in files_only: 11\n",
      "   imet-2020-fgvc7_ashkhagan_imet2020_v2_C1.ipynb\n",
      "   kuzushiji-recognition_seriousran_try-to-break-0_v1_C1.ipynb\n",
      "   rsna-breast-cancer-detection_abdulkadirguner_27subat-sub2-sites1and2_v1_C1.ipynb\n",
      "   rsna-breast-cancer-detection_cafelatte1_rsna-baseline-with-logistic-regression_v22_C1.ipynb\n",
      "   rsna-breast-cancer-detection_dschettler8845_rsna-bcd-simple-age-baseline-submission_v11_C1.ipynb\n",
      "   rsna-breast-cancer-detection_jitshil143_rsna-breast-cancer-inference_v11_C1.ipynb\n",
      "   rsna-breast-cancer-detection_meeratif_rsna-breast-cancer-prediction-eda_v10_C1.ipynb\n",
      "   rsna-breast-cancer-detection_mr0106_rsmabcd_v3_C1.ipynb\n",
      "   rsna-breast-cancer-detection_reighns_test-submission-for-cnn-model_v16_C1.ipynb\n",
      "   rsna-breast-cancer-detection_tomooinubushi_some-lb-probing-results-to-share_v15_C1.ipynb\n",
      "   statoil-iceberg-classifier-challenge_twhitehurst3_fcn-keras-iceberg_v1_C1.ipynb\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "json_path = \"/home/b27jin/mle-bench-internal/docker-test/executable_files_w_timer_parrallel_full.json\"\n",
    "with open(json_path, 'r') as f:\n",
    "    data = json.load(f)\n",
    "# Check each entity\n",
    "files_only = []\n",
    "for entity, info in tqdm(data.items()):\n",
    "    files_only.append(entity)\n",
    "\n",
    "print(f'{len(files_only)} files in scripts_full')\n",
    "\n",
    "valid_set = set(valid_scripts)\n",
    "print(f'{len(valid_set)} valid scripts')\n",
    "files_set = set(files_only)\n",
    "\n",
    "in_files_not_valid = sorted(files_set - valid_set)\n",
    "in_valid_not_files = sorted(valid_set - files_set)\n",
    "print(f\"In files_only but not in valid_scripts: {len(in_files_not_valid)}\")\n",
    "for f in in_files_not_valid[:25]:\n",
    "    print(\"  \", f)\n",
    "print(f\"In valid_scripts but not in files_only: {len(in_valid_not_files)}\")\n",
    "for f in in_valid_not_files:\n",
    "    print(\"  \", f)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a2ea8495",
   "metadata": {},
   "source": [
    "# Create Kernel"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "b082e90f",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Competitions:   0%|          | 0/79 [00:23<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[]\n",
      "True\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{'cassava-leaf-disease-classification': {'aaroswings_ensemble-inference-notebook_v34_C1.html': {'year': 2021,\n",
       "   'month': 2,\n",
       "   'date': 6,\n",
       "   'datetime': '2021-02-07T04:00:45.000000Z',\n",
       "   'runtime': 32,\n",
       "   'api': ['numpy',\n",
       "    'albumentations',\n",
       "    'opencv-python-headless',\n",
       "    'opencv-python',\n",
       "    'torch',\n",
       "    'pillow',\n",
       "    'pandas'],\n",
       "   'datasets': ['Cassava Leaf Disease Classification', 'private-dataset']}}}"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from tqdm import tqdm\n",
    "import re,os,glob\n",
    "import datetime\n",
    "from collections import Counter\n",
    "import ast\n",
    "import html\n",
    "import json\n",
    "import warnings\n",
    "import tempfile\n",
    "import nbformat\n",
    "import subprocess\n",
    "from pathlib import Path\n",
    "from nbformat.v4 import new_notebook, new_code_cell\n",
    "warnings.filterwarnings(\"ignore\", category=SyntaxWarning)\n",
    "\n",
    "def get_folders(base_path):\n",
    "    \"\"\"Get the folder names under the base path\"\"\"\n",
    "    return [f for f in os.listdir(base_path) if os.path.isdir(os.path.join(base_path, f))]\n",
    "\n",
    "def read_html_content(file_path, nb=None):\n",
    "    \"\"\"Read the content of an HTML file and append code cells to notebook if provided\"\"\"\n",
    "\n",
    "    with open(file_path, \"r\", encoding=\"utf-8\") as file:\n",
    "        content = file.read()\n",
    "\n",
    "        # Find all code blocks with highlight hl-ipython3 class\n",
    "        highlight_blocks = re.findall(r'<div class=\"highlight hl-ipython3\">(.*?)</div>', content, re.DOTALL)\n",
    "        \n",
    "        # Process all input areas as before for backward compatibility\n",
    "        input_areas = re.findall(r'<div class=\"input_area\">(.*?)</div>', content, re.DOTALL)\n",
    "        input_areas = \"\".join(input_areas) if input_areas else \"\"\n",
    "        input_areas = re.sub(r' *<pre>', '<pre>', input_areas)\n",
    "        \n",
    "        # If notebook object provided, add each code block as a cell\n",
    "        if nb is not None:\n",
    "            # nb.cells.append(new_code_cell('%pip install Unidecode monai ttach optuna optuna-integration'))\n",
    "            nb.cells.append(new_code_cell('import pandas as pd\\nfrom pathlib import Path'))\n",
    "            for block in highlight_blocks:\n",
    "                # Extract code from the highlight block\n",
    "                code_match = re.search(r'<pre>(.*?)</pre>', block, re.DOTALL)\n",
    "                if code_match:\n",
    "                    # Clean up the code\n",
    "                    code_text = html.unescape(code_match.group(1))\n",
    "                    raw_code = assemble_code_regex(code_text)\n",
    "                    # code = inspect.cleandoc(raw_code)\n",
    "                    nb.cells.append(new_code_cell(raw_code))\n",
    "        \n",
    "        return nb\n",
    "    \n",
    "def assemble_code_regex(html_snippet: str) -> str:\n",
    "    \"\"\"\n",
    "    Uses a regular expression to remove HTML tags from the snippet and unescapes HTML entities.\n",
    "    \"\"\"\n",
    "    # Unescape any HTML entities (if present)\n",
    "    code = html.unescape(html_snippet)\n",
    "    # Remove all HTML tags using regex\n",
    "    code = re.sub(r'</?[a-zA-Z][^>]*>', '', code)\n",
    "\n",
    "    return code\n",
    "\n",
    "\n",
    "def time_to_seconds(text):\n",
    "    \"\"\"\n",
    "    Extracts hours, minutes, and seconds from a text and converts them to seconds.\n",
    "    Expected formats are, for example, \"4s\", \"1m 54s\", or \"1h 59m 59s\".\n",
    "    \"\"\"\n",
    "    # The regex looks for optional hours and minutes, and mandatory seconds.\n",
    "    time_pattern = r'(?:(?P<h>\\d+)\\s*h)?\\s*(?:(?P<m>\\d+)\\s*m)?\\s*(?P<s>\\d+)\\s*s'\n",
    "    match = re.search(time_pattern, text)\n",
    "    if match:\n",
    "        h = int(match.group('h')) if match.group('h') is not None else 0\n",
    "        m_val = int(match.group('m')) if match.group('m') is not None else 0\n",
    "        s = int(match.group('s'))\n",
    "        return h * 3600 + m_val * 60 + s\n",
    "    return None\n",
    "\n",
    "def get_imports_from_file(notebook):\n",
    "    \"\"\"Use pigar to detect dependencies\"\"\"\n",
    "    deps = set()\n",
    "    with tempfile.TemporaryDirectory() as tmpdir:\n",
    "        workdir = Path(tmpdir)\n",
    "        \n",
    "        with open(workdir / \"script.ipynb\", \"w\", encoding=\"utf-8\") as file:\n",
    "            nbformat.write(notebook, file)\n",
    "        try:\n",
    "            # pigar generate <folder>\n",
    "            # print(\"Running pigar...\")\n",
    "            result = subprocess.run(\n",
    "                [\"pigar\", \"generate\", \"--auto-select\", tmpdir],\n",
    "                # [\"pipreqs\", \"--scan-notebooks\", tmpdir],\n",
    "                cwd=tmpdir,\n",
    "                capture_output=True,\n",
    "                text=True,\n",
    "                # input=\"*\\n\" + \"y\\n\" + \"*\\n\" * 20,\n",
    "                input=\"y\\n\" * 20,\n",
    "            )\n",
    "            # print(\"Pigar completed.\")\n",
    "\n",
    "            # print(\"STDOUT:\", result.stdout)\n",
    "            # print(\"STDERR:\", result.stderr)\n",
    "            # print(\"Return code:\", result.returncode)\n",
    "\n",
    "            print(get_folders(tmpdir))\n",
    "            # Parse requirements.txt output\n",
    "            req_file = Path(tmpdir) / \"requirements.txt\"\n",
    "            print(req_file.exists())\n",
    "            if req_file.exists():\n",
    "                for line in req_file.read_text().splitlines():\n",
    "                    line = line.strip()\n",
    "                    if not line or line.startswith('#'):\n",
    "                        continue\n",
    "                    pkg = line.split('==')[0].split('>=')[0].split('<=')[0].strip()\n",
    "                    if pkg:\n",
    "                        deps.add(pkg)\n",
    "            \n",
    "                return deps\n",
    "        except Exception as e:\n",
    "            print(f\"pigar failed: {e}\")\n",
    "            pass\n",
    "    \n",
    "    return deps\n",
    "\n",
    "\n",
    "# parent = 'C:\\\\Users\\\\b27jin\\\\Documents\\\\mle-bench-internal\\\\fetch\\\\competitions'\n",
    "parent = '/home/b27jin/mle-bench-internal/fetch/competitions'\n",
    "\n",
    "entity = {}\n",
    "for competi in tqdm(get_folders(parent), desc=\"Competitions\"):\n",
    "# for competi in dev:\n",
    "    entity[competi] = {}\n",
    "    i=1\n",
    "    for file in tqdm(glob.glob(os.path.join(parent, competi, 'meta_html','*_C1.html')), desc=competi, leave=False):\n",
    "        entity[competi][file.split(\"/\")[-1]] = {}\n",
    "        with open(os.path.join(parent, competi, 'meta_html',file.split(\"/\")[-1]), \"r\", encoding=\"utf-8\") as fp:\n",
    "            content = fp.read()\n",
    "            # Submission Year\n",
    "            pattern = r'<span [^>]*title=\"([A-Z][a-z]{2} [A-Z][a-z]{2} \\d{2} \\d{4} \\d{2}:\\d{2}:\\d{2} GMT[+-]\\d{4} \\([^\"]+\\))\"'\n",
    "            date = re.findall(pattern, content, re.DOTALL)[0]\n",
    "            # print(date)\n",
    "            date_str = date.split(\" (\")[0].replace(\"GMT\", \"\")\n",
    "            # print(date_str)\n",
    "            dt = datetime.datetime.strptime(date_str, \"%a %b %d %Y %H:%M:%S %z\")\n",
    "\n",
    "            entity[competi][file.split(\"/\")[-1]]['year'] = dt.year\n",
    "            entity[competi][file.split(\"/\")[-1]]['month'] = dt.month\n",
    "            entity[competi][file.split(\"/\")[-1]]['date'] = dt.day\n",
    "            entity[competi][file.split(\"/\")[-1]]['datetime'] = dt.astimezone(datetime.timezone.utc).strftime('%Y-%m-%dT%H:%M:%S.%fZ')\n",
    "            \n",
    "            # Find Private Score     \n",
    "            pattern = r'<p class=\"sc-gQaihK[^\"]*\">\\s*([-\\d.]+)\\s*</p>'\n",
    "            matches = re.findall(pattern, content, re.DOTALL)\n",
    "            # has P.Score\n",
    "            if matches:\n",
    "                entity[competi][file.split(\"/\")[-1]]['ps'] =  matches[0]\n",
    "\n",
    "            # Extract all time blocks (non-greedy match with DOTALL)\n",
    "            pattern = r'<p\\s+class=\"sc-gQaihK\\s+(?:sc-bHbnRu|sc-hKjFaw)\\s+bwaGMg\\s+(?:hAkjhA|jGRPCU)\">(.*?)</p>'\n",
    "            p_tags = re.findall(pattern, content, re.DOTALL)\n",
    "            for tag in p_tags:\n",
    "                seconds = time_to_seconds(tag)\n",
    "                if seconds is not None:\n",
    "                    entity[competi][file.split(\"/\")[-1]]['runtime'] =  seconds\n",
    "\n",
    "            # Extract dependencies\n",
    "            path = os.path.join(parent, competi, 'html', file.split(\"/\")[-1])\n",
    "            # Create notebook first\n",
    "            nb = new_notebook()\n",
    "            # Pass notebook to read_html_content to add cells directly\n",
    "            nb = read_html_content(path, nb)\n",
    "\n",
    "            # If no cells were added, add the whole content as one cell\n",
    "            if len(nb.cells) != 1:\n",
    "                file_deps = get_imports_from_file(nb)\n",
    "                entity[competi][file.split(\"/\")[-1]]['api'] = list(file_deps)\n",
    "            else:\n",
    "                entity[competi][file.split(\"/\")[-1]]['R'] = 1\n",
    "            \n",
    "\n",
    "            pattern = r'<p\\s+class=\"sc-gQaihK sc-dyfHgC bwaGMg igmQhu\">\\s*(.*?)\\s*</p>'\n",
    "            matches = re.findall(pattern, content, flags=re.DOTALL)\n",
    "            entity[competi][file.split(\"/\")[-1]]['datasets'] =  list(set(matches))\n",
    "        \n",
    "        break\n",
    "    break\n",
    "entity\n",
    "# Save the entity dictionary into a JSON file.\n",
    "# with open(\"kernel.json\", \"w\", encoding=\"utf-8\") as json_file:\n",
    "#     json.dump(entity, json_file, indent=4, ensure_ascii=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "e17f3d31",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 0/79 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 79/79 [00:00<00:00, 171.83it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total files in all competitions: 171075\n",
      "Total runnable _C1 files in all competitions: 151236\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "tot = 0\n",
    "tot_c1 = 0\n",
    "for competi in tqdm(get_folders(parent)):\n",
    "    tot += len(glob.glob(os.path.join(parent, competi,'meta_html','*.html')))\n",
    "    tot_c1 += len(glob.glob(os.path.join(parent, competi,'meta_html','*_C1.html')))\n",
    "print(f'Total files in all competitions: {tot}')\n",
    "print(f'Total runnable _C1 files in all competitions: {tot_c1}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "id": "be7955ba",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 79/79 [00:00<00:00, 386.29it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "cassava-leaf-disease-classification 9376\n",
      "tabular-playground-series-may-2022 1350\n",
      "tweet-sentiment-extraction 5473\n",
      "freesound-audio-tagging-2019 837\n",
      "cdiscount-image-classification-challenge 379\n",
      "text-normalization-challenge-english-language 261\n",
      "inaturalist-2019-fgvc6 90\n",
      "herbarium-2021-fgvc8 143\n",
      "random-acts-of-pizza 48\n",
      "aerial-cactus-identification 2679\n",
      "leaf-classification 1482\n",
      "movie-review-sentiment-analysis-kernels-only 1311\n",
      "dog-breed-identification 2418\n",
      "plant-pathology-2021-fgvc8 3509\n",
      "histopathologic-cancer-detection 2658\n",
      "champs-scalar-coupling 1863\n",
      "tabular-playground-series-dec-2021 2081\n",
      "osic-pulmonary-fibrosis-progression 5546\n",
      "ventilator-pressure-prediction 2254\n",
      "jigsaw-unintended-bias-in-toxicity-classification 3439\n",
      "chaii-hindi-and-tamil-question-answering 1599\n",
      "denoising-dirty-documents 441\n",
      "playground-series-s3e18 1321\n",
      "imet-2020-fgvc7 195\n",
      "bms-molecular-translation 1105\n",
      "smartphone-decimeter-2022 239\n",
      "facebook-recruiting-iii-keyword-extraction 74\n",
      "iwildcam-2019-fgvc6 226\n",
      "tensorflow-speech-recognition-challenge 462\n",
      "invasive-species-monitoring 193\n",
      "dogs-vs-cats-redux-kernels-edition 2067\n",
      "spaceship-titanic 11278\n",
      "rsna-breast-cancer-detection 4509\n",
      "rsna-miccai-brain-tumor-radiogenomic-classification 3310\n",
      "aptos2019-blindness-detection 6168\n",
      "statoil-iceberg-classifier-challenge 704\n",
      "new-york-city-taxi-fare-prediction 3246\n",
      "uw-madison-gi-tract-image-segmentation 2036\n",
      "plant-seedlings-classification 1420\n",
      "siim-isic-melanoma-classification 6404\n",
      "kuzushiji-recognition 308\n",
      "vinbigdata-chest-xray-abnormalities-detection 2155\n",
      "mlsp-2013-birds 14\n",
      "nfl-player-contact-detection 530\n",
      "text-normalization-challenge-russian-language 36\n",
      "google-quest-challenge 2162\n",
      "lmsys-chatbot-arena 1734\n",
      "spooky-author-identification 1955\n",
      "hms-harmful-brain-activity-classification 4618\n",
      "ml2021spring-hw2 6\n",
      "ranzcr-clip-catheter-line-classification 2120\n",
      "tensorflow2-question-answering 856\n",
      "google-research-identify-contrails-reduce-global-warming 1017\n",
      "seti-breakthrough-listen 1246\n",
      "billion-word-imputation 1\n",
      "icecube-neutrinos-in-deep-ice 1217\n",
      "siim-covid19-detection 3873\n",
      "nomad2018-predict-transparent-conductors 307\n",
      "stanford-covid-vaccine 1560\n",
      "learning-agency-lab-automated-essay-scoring-2 3199\n",
      "whale-categorization-playground 361\n",
      "alaska2-image-steganalysis 659\n",
      "iwildcam-2020-fgvc7 185\n",
      "vesuvius-challenge-ink-detection 1781\n",
      "petfinder-pawpularity-score 5340\n",
      "herbarium-2022-fgvc9 252\n",
      "predict-volcanic-eruptions-ingv-oe 764\n",
      "AI4Code 1148\n",
      "jigsaw-toxic-comment-classification-challenge 3664\n",
      "paddy-disease-classification 713\n",
      "plant-pathology-2020-fgvc7 2695\n",
      "tgs-salt-identification-challenge 1564\n",
      "detecting-insults-in-social-commentary 4\n",
      "3d-object-detection-for-autonomous-vehicles 410\n",
      "rsna-2022-cervical-spine-fracture-detection 2655\n",
      "hotel-id-2021-fgvc8 231\n",
      "us-patent-phrase-to-phrase-matching 2672\n",
      "herbarium-2020-fgvc7 163\n",
      "h-and-m-personalized-fashion-recommendations 2867\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "for competi in tqdm(get_folders(parent)):\n",
    "    print(competi, len(glob.glob(os.path.join(parent, competi,'meta_html','*_C1.html'))))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "42ec0170",
   "metadata": {},
   "outputs": [],
   "source": [
    "import requests\n",
    "import json\n",
    "import datetime\n",
    "from pathlib import Path\n",
    "import time\n",
    "\n",
    "with open(\"/home/b27jin/config.json\", \"r\") as f:\n",
    "    config = json.load(f)\n",
    "pypi_key = config[\"pypi\"]\n",
    "\n",
    "with open(\"/home/b27jin/CodeModernization/kernel.json\", \"r\", encoding=\"utf-8\") as f:\n",
    "    kernel_content = json.load(f)\n",
    "\n",
    "results = []\n",
    "session = requests.Session()\n",
    "base_url = \"https://libraries.io/api/pypi/{pkg}\"\n",
    "\n",
    "for script_name in valid_scripts:\n",
    "    compt = script_name.split(\"_\")[0]\n",
    "    submission_id = \"_\".join(Path(script_name).stem.split(\"_\")[1:]) + \".html\"\n",
    "\n",
    "    script_meta = kernel_content[compt][submission_id]\n",
    "    submission_date = submission_date = datetime.datetime(script_meta[\"year\"], script_meta[\"month\"], script_meta[\"date\"])\n",
    "    \n",
    "    apis = script_meta.get(\"api\") or []\n",
    "    print(apis)\n",
    "    for api in apis:\n",
    "        url = base_url.format(pkg=api)\n",
    "        try:\n",
    "            resp = session.get(url, params={\"api_key\": pypi_key, \"per_page\": 100}, timeout=15)\n",
    "            resp.raise_for_status()\n",
    "            api_meta = resp.json()\n",
    "        except Exception as e:\n",
    "            print(f\"Fetch fail {api}: {e}\")\n",
    "            continue\n",
    "        \n",
    "        closest_v = None\n",
    "        closest_dt = None\n",
    "        if api_meta and api_meta[\"status\"] != \"Removed\":\n",
    "            versions = api_meta.get(\"versions\", [])\n",
    "            for version in versions:\n",
    "                pub_date = datetime.datetime.strptime(version['published_at'], '%Y-%m-%dT%H:%M:%S.%fZ') #'2008-04-25T16:22:32.000Z',\n",
    "\n",
    "                if not pub_date:\n",
    "                    continue\n",
    "\n",
    "                if pub_date <= submission_date:\n",
    "                    if closest_dt is None or pub_date > closest_dt:\n",
    "                        closest_dt = pub_date\n",
    "                        closest_v = version['number']\n",
    "            \n",
    "            if closest_dt:\n",
    "                results.append((script_name, api, closest_v, closest_dt.strftime(\"%Y-%m-%d\"), submission_date.strftime(\"%Y-%m-%d\")))\n",
    "                print(f\"{script_name} | {api} | {closest_v} | {closest_dt.date()} <= {submission_date.date()}\")\n",
    "            else:\n",
    "                print(f\"{script_name} | {api} | no version <= submission_date\")\n",
    "        \n",
    "        time.sleep(0.2)\n",
    "    break"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "mle_env",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}

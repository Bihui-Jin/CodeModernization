{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "20958c24",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-08-18T20:39:28.190322Z",
     "iopub.status.busy": "2025-08-18T20:39:28.190127Z",
     "iopub.status.idle": "2025-08-18T20:39:28.871158Z",
     "shell.execute_reply": "2025-08-18T20:39:28.870692Z"
    }
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from pathlib import Path"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "bd7c9954",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-08-18T20:39:28.873008Z",
     "iopub.status.busy": "2025-08-18T20:39:28.872716Z",
     "iopub.status.idle": "2025-08-18T20:39:34.802526Z",
     "shell.execute_reply": "2025-08-18T20:39:34.802085Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['train.zip', 'test_images', 'sample_submission.csv.zip', 'description.md', 'test_images.zip', 'train_images', 'train_images.zip', 'test.zip', 'sample_submission.csv', 'test.csv.zip', 'train.csv', 'train.csv.zip', 'test.csv', 'aptos2019-blindness-detection']\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-08-18 20:39:29.615094: E external/local_xla/xla/stream_executor/cuda/cuda_fft.cc:477] Unable to register cuFFT factory: Attempting to register factory for plugin cuFFT when one has already been registered\n",
      "WARNING: All log messages before absl::InitializeLog() is called are written to STDERR\n",
      "E0000 00:00:1755549569.624585       8 cuda_dnn.cc:8310] Unable to register cuDNN factory: Attempting to register factory for plugin cuDNN when one has already been registered\n",
      "E0000 00:00:1755549569.628551       8 cuda_blas.cc:1418] Unable to register cuBLAS factory: Attempting to register factory for plugin cuBLAS when one has already been registered\n",
      "2025-08-18 20:39:29.644392: I tensorflow/core/platform/cpu_feature_guard.cc:210] This TensorFlow binary is optimized to use available CPU instructions in performance-critical operations.\n",
      "To enable the following instructions: AVX2 FMA, in other operations, rebuild TensorFlow with the appropriate compiler flags.\n"
     ]
    }
   ],
   "source": [
    "# This Python 3 environment comes with many helpful analytics libraries installed\n",
    "# It is defined by the kaggle/python docker image: https://github.com/kaggle/docker-python\n",
    "# For example, here's several helpful packages to load in \n",
    "\n",
    "import numpy as np # linear algebra\n",
    "import pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\n",
    "\n",
    "import os\n",
    "import shutil\n",
    "from tqdm import tqdm\n",
    "from PIL import Image\n",
    "\n",
    "DATA_PATH = \"../input/\"\n",
    "TRAIN_PATH = DATA_PATH + 'train_images/'\n",
    "\n",
    "print(os.listdir(DATA_PATH))\n",
    "\n",
    "from glob import glob \n",
    "from skimage.io import imread\n",
    "import gc\n",
    "\n",
    "from sklearn.utils import shuffle\n",
    "from sklearn.model_selection import train_test_split\n",
    "from keras.utils import to_categorical\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "c84646fd",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-08-18T20:39:34.804333Z",
     "iopub.status.busy": "2025-08-18T20:39:34.804050Z",
     "iopub.status.idle": "2025-08-18T20:39:34.824850Z",
     "shell.execute_reply": "2025-08-18T20:39:34.824589Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>path</th>\n",
       "      <th>id</th>\n",
       "      <th>label</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>../input/train_images/184a185e7447.png</td>\n",
       "      <td>184a185e7447</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>../input/train_images/c4aef0d88d1b.png</td>\n",
       "      <td>c4aef0d88d1b</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>../input/train_images/d69698f838db.png</td>\n",
       "      <td>d69698f838db</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>../input/train_images/15cc2aef772a.png</td>\n",
       "      <td>15cc2aef772a</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>../input/train_images/f7edc074f06b.png</td>\n",
       "      <td>f7edc074f06b</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                     path            id  label\n",
       "0  ../input/train_images/184a185e7447.png  184a185e7447      0\n",
       "1  ../input/train_images/c4aef0d88d1b.png  c4aef0d88d1b      0\n",
       "2  ../input/train_images/d69698f838db.png  d69698f838db      0\n",
       "3  ../input/train_images/15cc2aef772a.png  15cc2aef772a      1\n",
       "4  ../input/train_images/f7edc074f06b.png  f7edc074f06b      2"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "base_tile_dir = DATA_PATH + 'train_images/'\n",
    "\n",
    "df = pd.DataFrame({'path': glob(base_tile_dir +'/*.png')})\n",
    "\n",
    "df['id'] = df.path.map(lambda x: x.split('/')[3].split(\".\")[0])\n",
    "\n",
    "labels = pd.read_csv(DATA_PATH + \"train.csv\")\n",
    "labels = labels.rename(index=str, columns={'id_code':'id', 'diagnosis':'label'})\n",
    "\n",
    "df_data = df.merge(labels, on = \"id\")\n",
    "\n",
    "df_data.head()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "106e3f4c",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-08-18T20:39:34.826179Z",
     "iopub.status.busy": "2025-08-18T20:39:34.826032Z",
     "iopub.status.idle": "2025-08-18T20:39:34.835943Z",
     "shell.execute_reply": "2025-08-18T20:39:34.835646Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                                        path            id  label\n",
      "108   ../input/train_images/e0313be77035.png  e0313be77035      0\n",
      "266   ../input/train_images/44271f3cb18f.png  44271f3cb18f      0\n",
      "1305  ../input/train_images/0243404e8a00.png  0243404e8a00      4\n",
      "1049  ../input/train_images/917f76f360b6.png  917f76f360b6      2\n",
      "973   ../input/train_images/907aaff827e5.png  907aaff827e5      2\n",
      "label\n",
      "0    450\n",
      "2    300\n",
      "1    300\n",
      "4    200\n",
      "3    150\n",
      "Name: count, dtype: int64\n"
     ]
    }
   ],
   "source": [
    "SAMPLE_SIZE = 150 # load 80k negative examples\n",
    "\n",
    "# take a random sample of class 0 with size equal to num samples in class 1\n",
    "df_0 = df_data[df_data['label'] == 0].sample(SAMPLE_SIZE*3, random_state = 101)\n",
    "# filter out class 1\n",
    "df_1 = df_data[df_data['label'] == 1].sample(SAMPLE_SIZE*2, random_state = 101)\n",
    "# filter out class 2\n",
    "df_2 = df_data[df_data['label'] == 2].sample(SAMPLE_SIZE*2, random_state = 101)\n",
    "# filter out class 3\n",
    "df_3 = df_data[df_data['label'] == 3].sample(SAMPLE_SIZE, random_state = 101)\n",
    "# filter out class 4\n",
    "df_4 = df_data[df_data['label'] == 4].sample(200, random_state = 101)\n",
    "\n",
    "# concat the dataframes\n",
    "df_data = shuffle(pd.concat([df_0, df_1, df_2, df_3, df_4], axis=0).reset_index(drop=True))\n",
    "\n",
    "print(df_data.head())\n",
    "print(df_data.label.value_counts())\n",
    "\n",
    "# train_test_split # stratify=y creates a balanced validation set.\n",
    "y = df_data['label']\n",
    "df_train, df_val = train_test_split(df_data, test_size=0.10, random_state=101, stratify=y)\n",
    "\n",
    "# Create directories\n",
    "train_path = 'base_dir/train'\n",
    "valid_path = 'base_dir/valid'\n",
    "test_path = '../input/test'\n",
    "for fold in [train_path, valid_path]:\n",
    "    for subf in [\"0\", \"1\",\"2\",\"3\",\"4\"]:\n",
    "        os.makedirs(os.path.join(fold, subf))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "671f9e86",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-08-18T20:39:34.837091Z",
     "iopub.status.busy": "2025-08-18T20:39:34.836867Z",
     "iopub.status.idle": "2025-08-18T20:39:34.840652Z",
     "shell.execute_reply": "2025-08-18T20:39:34.840388Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>path</th>\n",
       "      <th>label</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>id</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>e0313be77035</th>\n",
       "      <td>../input/train_images/e0313be77035.png</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>44271f3cb18f</th>\n",
       "      <td>../input/train_images/44271f3cb18f.png</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0243404e8a00</th>\n",
       "      <td>../input/train_images/0243404e8a00.png</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>917f76f360b6</th>\n",
       "      <td>../input/train_images/917f76f360b6.png</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>907aaff827e5</th>\n",
       "      <td>../input/train_images/907aaff827e5.png</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                path  label\n",
       "id                                                         \n",
       "e0313be77035  ../input/train_images/e0313be77035.png      0\n",
       "44271f3cb18f  ../input/train_images/44271f3cb18f.png      0\n",
       "0243404e8a00  ../input/train_images/0243404e8a00.png      4\n",
       "917f76f360b6  ../input/train_images/917f76f360b6.png      2\n",
       "907aaff827e5  ../input/train_images/907aaff827e5.png      2"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Set the id as the index in df_data\n",
    "df_data.set_index('id', inplace=True)\n",
    "df_data.head()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "7d4439c2",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-08-18T20:39:34.841686Z",
     "iopub.status.busy": "2025-08-18T20:39:34.841513Z",
     "iopub.status.idle": "2025-08-18T20:41:39.517642Z",
     "shell.execute_reply": "2025-08-18T20:41:39.517156Z"
    }
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1260/1260 [01:53<00:00, 11.15it/s]\n",
      "100%|██████████| 140/140 [00:11<00:00, 12.04it/s]\n"
     ]
    }
   ],
   "source": [
    "IMAGE_SIZE = 96\n",
    "\n",
    "for image in tqdm(df_train['id'].values):\n",
    "    # the id in the csv file does not have the .tif extension therefore we add it here\n",
    "    fname = image + '.png'\n",
    "    label = str(df_data.loc[image,'label']) # get the label for a certain image\n",
    "    src = os.path.join(TRAIN_PATH, fname)\n",
    "    dst = os.path.join(train_path, label, fname)\n",
    "    \n",
    "    pil_im = Image.open(src)\n",
    "    resized_image = pil_im.resize((IMAGE_SIZE, IMAGE_SIZE))\n",
    "    resized_image.save(dst)\n",
    "\n",
    "for image in tqdm(df_val['id'].values):\n",
    "    fname = image + '.png'\n",
    "    label = str(df_data.loc[image,'label']) # get the label for a certain image\n",
    "    src = os.path.join(TRAIN_PATH, fname)\n",
    "    dst = os.path.join(valid_path, label, fname)\n",
    "    \n",
    "    pil_im = Image.open(src)\n",
    "    resized_image = pil_im.resize((IMAGE_SIZE, IMAGE_SIZE))\n",
    "    resized_image.save(dst)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "00611ae3",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-08-18T20:41:39.519549Z",
     "iopub.status.busy": "2025-08-18T20:41:39.519362Z",
     "iopub.status.idle": "2025-08-18T20:41:39.781504Z",
     "shell.execute_reply": "2025-08-18T20:41:39.781137Z"
    }
   },
   "outputs": [
    {
     "ename": "ImportError",
     "evalue": "cannot import name 'ImageDataGenerator' from 'keras.preprocessing.image' (/usr/local/lib/python3.11/dist-packages/keras/api/preprocessing/image/__init__.py)",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mImportError\u001b[0m                               Traceback (most recent call last)",
      "\u001b[0;32m/tmp/ipykernel_8/2302889557.py\u001b[0m in \u001b[0;36m<cell line: 0>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0;32mfrom\u001b[0m \u001b[0mkeras\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpreprocessing\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mimage\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mImageDataGenerator\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      2\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0mnum_train_samples\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdf_train\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0mnum_val_samples\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdf_val\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0mtrain_batch_size\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;36m32\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mImportError\u001b[0m: cannot import name 'ImageDataGenerator' from 'keras.preprocessing.image' (/usr/local/lib/python3.11/dist-packages/keras/api/preprocessing/image/__init__.py)"
     ]
    }
   ],
   "source": [
    "from keras.preprocessing.image import ImageDataGenerator\n",
    "\n",
    "num_train_samples = len(df_train)\n",
    "num_val_samples = len(df_val)\n",
    "train_batch_size = 32\n",
    "val_batch_size = 32\n",
    "\n",
    "train_steps = np.ceil(num_train_samples / train_batch_size)\n",
    "val_steps = np.ceil(num_val_samples / val_batch_size)\n",
    "\n",
    "datagen = ImageDataGenerator(preprocessing_function=lambda x:(x - x.mean()) / x.std() if x.std() > 0 else x,\n",
    "                            horizontal_flip=True,\n",
    "                            vertical_flip=True)\n",
    "\n",
    "train_gen = datagen.flow_from_directory(train_path,\n",
    "                                        target_size=(IMAGE_SIZE,IMAGE_SIZE),\n",
    "                                        batch_size=train_batch_size,\n",
    "                                        class_mode='categorical')\n",
    "\n",
    "val_gen = datagen.flow_from_directory(valid_path,\n",
    "                                        target_size=(IMAGE_SIZE,IMAGE_SIZE),\n",
    "                                        batch_size=val_batch_size,\n",
    "                                        class_mode='categorical')\n",
    "\n",
    "# Note: shuffle=False causes the test dataset to not be shuffled\n",
    "test_gen = datagen.flow_from_directory(valid_path,\n",
    "                                        target_size=(IMAGE_SIZE,IMAGE_SIZE),\n",
    "                                        batch_size=1,\n",
    "                                        class_mode='categorical',\n",
    "                                        shuffle=False)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "e903f4d5",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-08-18T20:41:39.783090Z",
     "iopub.status.busy": "2025-08-18T20:41:39.782823Z",
     "iopub.status.idle": "2025-08-18T20:41:39.994235Z",
     "shell.execute_reply": "2025-08-18T20:41:39.993885Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Done !\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.11/dist-packages/keras/src/layers/convolutional/base_conv.py:107: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
      "  super().__init__(activity_regularizer=activity_regularizer, **kwargs)\n",
      "2025-08-18 20:41:39.793921: E external/local_xla/xla/stream_executor/cuda/cuda_driver.cc:152] failed call to cuInit: INTERNAL: CUDA error: Failed call to cuInit: UNKNOWN ERROR (303)\n"
     ]
    }
   ],
   "source": [
    "from keras.models import Sequential\n",
    "from keras.layers import Dense, Dropout, Flatten, BatchNormalization, Activation\n",
    "from keras.layers import Conv2D, MaxPool2D\n",
    "from keras.optimizers import RMSprop, Adam\n",
    "\n",
    "kernel_size = (3,3)\n",
    "pool_size= (2,2)\n",
    "first_filters = 32\n",
    "second_filters = 64\n",
    "third_filters = 128\n",
    "\n",
    "dropout_conv = 0.3\n",
    "dropout_dense = 0.5\n",
    "\n",
    "model = Sequential()\n",
    "model.add(Conv2D(first_filters, kernel_size, activation = 'relu', input_shape = (IMAGE_SIZE, IMAGE_SIZE, 3)))\n",
    "model.add(Conv2D(first_filters, kernel_size, use_bias=False))\n",
    "model.add(BatchNormalization())\n",
    "model.add(Activation(\"relu\"))\n",
    "model.add(MaxPool2D(pool_size = pool_size)) \n",
    "model.add(Dropout(dropout_conv))\n",
    "\n",
    "model.add(Conv2D(second_filters, kernel_size, use_bias=False))\n",
    "model.add(BatchNormalization())\n",
    "model.add(Activation(\"relu\"))\n",
    "model.add(Conv2D(second_filters, kernel_size, use_bias=False))\n",
    "model.add(BatchNormalization())\n",
    "model.add(Activation(\"relu\"))\n",
    "model.add(MaxPool2D(pool_size = pool_size))\n",
    "model.add(Dropout(dropout_conv))\n",
    "\n",
    "model.add(Conv2D(third_filters, kernel_size, use_bias=False))\n",
    "model.add(BatchNormalization())\n",
    "model.add(Activation(\"relu\"))\n",
    "model.add(Conv2D(third_filters, kernel_size, use_bias=False))\n",
    "model.add(BatchNormalization())\n",
    "model.add(Activation(\"relu\"))\n",
    "model.add(MaxPool2D(pool_size = pool_size))\n",
    "model.add(Dropout(dropout_conv))\n",
    "\n",
    "#model.add(GlobalAveragePooling2D())\n",
    "model.add(Flatten())\n",
    "model.add(Dense(256, use_bias=False))\n",
    "model.add(BatchNormalization())\n",
    "model.add(Activation(\"relu\"))\n",
    "model.add(Dropout(dropout_dense))\n",
    "model.add(Dense(5, activation = \"sigmoid\"))\n",
    "\n",
    "# Compile the model\n",
    "model.compile(Adam(0.01), loss = \"categorical_crossentropy\", metrics=[\"accuracy\"])\n",
    "\n",
    "print(\"Done !\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "6f5ea47a",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-08-18T20:41:39.995703Z",
     "iopub.status.busy": "2025-08-18T20:41:39.995445Z",
     "iopub.status.idle": "2025-08-18T20:41:40.004326Z",
     "shell.execute_reply": "2025-08-18T20:41:40.004010Z"
    }
   },
   "outputs": [
    {
     "ename": "AttributeError",
     "evalue": "'Sequential' object has no attribute 'fit_generator'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "\u001b[0;32m/tmp/ipykernel_8/3918087694.py\u001b[0m in \u001b[0;36m<cell line: 0>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[0mearlystopper\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mEarlyStopping\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmonitor\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m'val_loss'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mpatience\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m2\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mverbose\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mrestore_best_weights\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0mreducel\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mReduceLROnPlateau\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmonitor\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m'val_loss'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mpatience\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mverbose\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfactor\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m0.1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 4\u001b[0;31m history = model.fit_generator(train_gen, steps_per_epoch=train_steps, \n\u001b[0m\u001b[1;32m      5\u001b[0m                     \u001b[0mvalidation_data\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mval_gen\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      6\u001b[0m                     \u001b[0mvalidation_steps\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mval_steps\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mAttributeError\u001b[0m: 'Sequential' object has no attribute 'fit_generator'"
     ]
    }
   ],
   "source": [
    "from keras.callbacks import EarlyStopping, ReduceLROnPlateau\n",
    "earlystopper = EarlyStopping(monitor='val_loss', patience=2, verbose=1, restore_best_weights=True)\n",
    "reducel = ReduceLROnPlateau(monitor='val_loss', patience=1, verbose=1, factor=0.1)\n",
    "history = model.fit_generator(train_gen, steps_per_epoch=train_steps, \n",
    "                    validation_data=val_gen,\n",
    "                    validation_steps=val_steps,\n",
    "                    epochs=13,\n",
    "                   callbacks=[reducel, earlystopper])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "6ddf0c52",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-08-18T20:41:40.005472Z",
     "iopub.status.busy": "2025-08-18T20:41:40.005365Z",
     "iopub.status.idle": "2025-08-18T20:41:40.010809Z",
     "shell.execute_reply": "2025-08-18T20:41:40.010548Z"
    }
   },
   "outputs": [
    {
     "ename": "AttributeError",
     "evalue": "'Sequential' object has no attribute 'predict_generator'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "\u001b[0;32m/tmp/ipykernel_8/663662760.py\u001b[0m in \u001b[0;36m<cell line: 0>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0;31m# make a prediction\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 5\u001b[0;31m \u001b[0my_pred_keras\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpredict_generator\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtest_gen\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msteps\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdf_val\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mverbose\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;31mAttributeError\u001b[0m: 'Sequential' object has no attribute 'predict_generator'"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import roc_curve, auc, roc_auc_score\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# make a prediction\n",
    "y_pred_keras = model.predict_generator(test_gen, steps=len(df_val), verbose=1)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "869923f6",
   "metadata": {},
   "outputs": [],
   "source": [
    " \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "b25f143e",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-08-18T20:41:40.012165Z",
     "iopub.status.busy": "2025-08-18T20:41:40.011873Z",
     "iopub.status.idle": "2025-08-18T20:42:12.540272Z",
     "shell.execute_reply": "2025-08-18T20:42:12.539905Z"
    }
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 367/367 [00:30<00:00, 12.07it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Indexes: 0 - 20\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 208ms/step\n",
      "Indexes: 20 - 40\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 57ms/step\n",
      "Indexes: 40 - 60\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 56ms/step\n",
      "Indexes: 60 - 80\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 54ms/step\n",
      "Indexes: 80 - 100\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 54ms/step\n",
      "Indexes: 100 - 120\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 58ms/step\n",
      "Indexes: 120 - 140\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 55ms/step\n",
      "Indexes: 140 - 160\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 51ms/step\n",
      "Indexes: 160 - 180\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 53ms/step\n",
      "Indexes: 180 - 200\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 55ms/step\n",
      "Indexes: 200 - 220\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 57ms/step\n",
      "Indexes: 220 - 240\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 54ms/step\n",
      "Indexes: 240 - 260\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 51ms/step\n",
      "Indexes: 260 - 280\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 54ms/step\n",
      "Indexes: 280 - 300\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 54ms/step\n",
      "Indexes: 300 - 320\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 51ms/step\n",
      "Indexes: 320 - 340\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 53ms/step\n",
      "Indexes: 340 - 360\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 54ms/step\n",
      "Indexes: 360 - 380\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 140ms/step\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id_code</th>\n",
       "      <th>diagnosis</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>f9156aeffc5e</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>28824d12d31d</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>4c60b10a3a6a</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>6cbc3dad809c</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1cb814ed6332</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "        id_code  diagnosis\n",
       "0  f9156aeffc5e          2\n",
       "1  28824d12d31d          2\n",
       "2  4c60b10a3a6a          3\n",
       "3  6cbc3dad809c          3\n",
       "4  1cb814ed6332          3"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "base_test_dir = '../input/test_images/'\n",
    "\n",
    "test_files = glob(os.path.join(base_test_dir,'*.png'))\n",
    "\n",
    "os.makedirs('valid/')\n",
    "\n",
    "for image in tqdm(test_files):\n",
    "    fname = image.split('/')[-1]\n",
    "    \n",
    "    src = os.path.join(base_test_dir, fname)\n",
    "    dst = os.path.join(\"valid/\",fname)\n",
    "    \n",
    "    pil_im = Image.open(src)\n",
    "    resized_image = pil_im.resize((IMAGE_SIZE, IMAGE_SIZE))\n",
    "    resized_image.save(dst)\n",
    "    \n",
    "test_files = glob(os.path.join('valid','*.png'))\n",
    "\n",
    "\n",
    "submission = pd.DataFrame()\n",
    "file_batch = 20\n",
    "max_idx = len(test_files)\n",
    "for idx in range(0, max_idx, file_batch):\n",
    "    print(\"Indexes: %i - %i\"%(idx, idx+file_batch))\n",
    "    test_df = pd.DataFrame({'path': test_files[idx:idx+file_batch]})\n",
    "    test_df['id_code'] = test_df.path.map(lambda x: x.split('/')[1].split(\".\")[0])\n",
    "    test_df['image'] = test_df['path'].map(imread)\n",
    "    K_test = np.stack(test_df[\"image\"].values)\n",
    "    K_test = (K_test - K_test.mean()) / K_test.std()\n",
    "    predictions = model.predict(K_test)\n",
    "    \n",
    "    pred = []\n",
    "    \n",
    "    for l in predictions:\n",
    "        pred.append(np.argmax(l))\n",
    "    \n",
    "    \n",
    "    test_df['diagnosis'] = pred\n",
    "    submission = pd.concat([submission, test_df[[\"id_code\", \"diagnosis\"]]])\n",
    "submission.head()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "ed966249",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-08-18T20:42:12.541534Z",
     "iopub.status.busy": "2025-08-18T20:42:12.541394Z",
     "iopub.status.idle": "2025-08-18T20:42:12.591181Z",
     "shell.execute_reply": "2025-08-18T20:42:12.590883Z"
    }
   },
   "outputs": [],
   "source": [
    "#submission\n",
    "# Delete the test_dir directory we created to prevent a Kaggle error.\n",
    "# Kaggle allows a max of 500 files to be saved.\n",
    "\n",
    "shutil.rmtree(train_path)\n",
    "shutil.rmtree(valid_path)\n",
    "shutil.rmtree('valid/')\n",
    "submission.to_csv(\"submission.csv\", index = False, header = True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "6c5308d9",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-08-18T20:42:12.592271Z",
     "iopub.status.busy": "2025-08-18T20:42:12.592093Z",
     "iopub.status.idle": "2025-08-18T20:42:12.596236Z",
     "shell.execute_reply": "2025-08-18T20:42:12.595950Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "diagnosis\n",
       "3    261\n",
       "2     64\n",
       "4     29\n",
       "1     12\n",
       "0      1\n",
       "Name: count, dtype: int64"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = pd.read_csv(\"submission.csv\")\n",
    "df[\"diagnosis\"].value_counts()\n"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}

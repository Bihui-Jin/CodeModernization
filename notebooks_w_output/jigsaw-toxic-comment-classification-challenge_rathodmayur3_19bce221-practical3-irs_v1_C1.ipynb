{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "245e5b64",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-08-18T14:40:05.957733Z",
     "iopub.status.busy": "2025-08-18T14:40:05.957470Z",
     "iopub.status.idle": "2025-08-18T14:40:06.641263Z",
     "shell.execute_reply": "2025-08-18T14:40:06.640848Z"
    }
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from pathlib import Path"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "26d7ced2",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-08-18T14:40:06.643086Z",
     "iopub.status.busy": "2025-08-18T14:40:06.642795Z",
     "iopub.status.idle": "2025-08-18T14:40:06.646827Z",
     "shell.execute_reply": "2025-08-18T14:40:06.646541Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/kaggle/input/sample_submission.csv\n",
      "/kaggle/input/test.csv.zip\n",
      "/kaggle/input/train.csv.zip\n",
      "/kaggle/input/description.md\n",
      "/kaggle/input/sample_submission.csv.zip\n",
      "/kaggle/input/train.csv\n",
      "/kaggle/input/test.csv\n",
      "/kaggle/input/jigsaw-toxic-comment-classification-challenge/sample_submission.csv\n",
      "/kaggle/input/jigsaw-toxic-comment-classification-challenge/test.csv.zip\n",
      "/kaggle/input/jigsaw-toxic-comment-classification-challenge/train.csv.zip\n",
      "/kaggle/input/jigsaw-toxic-comment-classification-challenge/description.md\n",
      "/kaggle/input/jigsaw-toxic-comment-classification-challenge/sample_submission.csv.zip\n",
      "/kaggle/input/jigsaw-toxic-comment-classification-challenge/train.csv\n",
      "/kaggle/input/jigsaw-toxic-comment-classification-challenge/test.csv\n"
     ]
    }
   ],
   "source": [
    "# This Python 3 environment comes with many helpful analytics libraries installed\n",
    "# It is defined by the kaggle/python Docker image: https://github.com/kaggle/docker-python\n",
    "# For example, here's several helpful packages to load\n",
    "\n",
    "import numpy as np # linear algebra\n",
    "import pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\n",
    "\n",
    "# Input data files are available in the read-only \"../input/\" directory\n",
    "# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n",
    "\n",
    "import os\n",
    "for dirname, _, filenames in os.walk('/kaggle/input'):\n",
    "    for filename in filenames:\n",
    "        print(os.path.join(dirname, filename))\n",
    "\n",
    "# You can write up to 20GB to the current directory (/kaggle/working/) that gets preserved as output when you create a version using \"Save & Run All\" \n",
    "# You can also write temporary files to /kaggle/temp/, but they won't be saved outside of the current session\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "3ee4e3d1",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-08-18T14:40:06.648069Z",
     "iopub.status.busy": "2025-08-18T14:40:06.647855Z",
     "iopub.status.idle": "2025-08-18T14:40:06.649935Z",
     "shell.execute_reply": "2025-08-18T14:40:06.649656Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "This is Rathod Mayur || 19BCE221 || This is my 3rd practical of IRS\n"
     ]
    }
   ],
   "source": [
    "print(\"This is Rathod Mayur || 19BCE221 || This is my 3rd practical of IRS\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "365eceb8",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-08-18T14:40:06.651084Z",
     "iopub.status.busy": "2025-08-18T14:40:06.650981Z",
     "iopub.status.idle": "2025-08-18T14:40:07.231479Z",
     "shell.execute_reply": "2025-08-18T14:40:07.231098Z"
    }
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "import seaborn as sns\n",
    "import re\n",
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "# I this fetch_20newsgroups dataset for make prediction using CountVectorizer.\n",
    "from sklearn.datasets import fetch_20newsgroups\n",
    "from sklearn.naive_bayes import MultinomialNB\n",
    "from sklearn import metrics\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "5c8154d3",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-08-18T14:40:07.233668Z",
     "iopub.status.busy": "2025-08-18T14:40:07.233445Z",
     "iopub.status.idle": "2025-08-18T14:40:07.235615Z",
     "shell.execute_reply": "2025-08-18T14:40:07.235263Z"
    }
   },
   "outputs": [],
   "source": [
    "corpus = ['This is the first document.',\n",
    "          'This document is the second document.',\n",
    "          'And this is the third one.',\n",
    "          'Is this the first document?',]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "3f8ec421",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-08-18T14:40:07.236815Z",
     "iopub.status.busy": "2025-08-18T14:40:07.236606Z",
     "iopub.status.idle": "2025-08-18T14:40:07.240737Z",
     "shell.execute_reply": "2025-08-18T14:40:07.240438Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<Compressed Sparse Row sparse matrix of dtype 'int64'\n",
      "\twith 21 stored elements and shape (4, 9)>\n",
      "  Coords\tValues\n",
      "  (0, 8)\t1\n",
      "  (0, 3)\t1\n",
      "  (0, 6)\t1\n",
      "  (0, 2)\t1\n",
      "  (0, 1)\t1\n",
      "  (1, 8)\t1\n",
      "  (1, 3)\t1\n",
      "  (1, 6)\t1\n",
      "  (1, 1)\t2\n",
      "  (1, 5)\t1\n",
      "  (2, 8)\t1\n",
      "  (2, 3)\t1\n",
      "  (2, 6)\t1\n",
      "  (2, 0)\t1\n",
      "  (2, 7)\t1\n",
      "  (2, 4)\t1\n",
      "  (3, 8)\t1\n",
      "  (3, 3)\t1\n",
      "  (3, 6)\t1\n",
      "  (3, 2)\t1\n",
      "  (3, 1)\t1\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "array(['and', 'document', 'first', 'is', 'one', 'second', 'the', 'third',\n",
       "       'this'], dtype=object)"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "vectorizer = CountVectorizer()\n",
    "X = vectorizer.fit_transform(corpus)\n",
    "print(X)\n",
    "vectorizer.get_feature_names_out()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "8e5992ad",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-08-18T14:40:07.241962Z",
     "iopub.status.busy": "2025-08-18T14:40:07.241729Z",
     "iopub.status.idle": "2025-08-18T14:40:07.243942Z",
     "shell.execute_reply": "2025-08-18T14:40:07.243659Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[0 1 1 1 0 0 1 0 1]\n",
      " [0 2 0 1 0 1 1 0 1]\n",
      " [1 0 0 1 1 0 1 1 1]\n",
      " [0 1 1 1 0 0 1 0 1]]\n"
     ]
    }
   ],
   "source": [
    "print(X.toarray())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "8396c650",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-08-18T14:40:07.245124Z",
     "iopub.status.busy": "2025-08-18T14:40:07.244942Z",
     "iopub.status.idle": "2025-08-18T14:40:07.247811Z",
     "shell.execute_reply": "2025-08-18T14:40:07.247547Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['and this' 'document is' 'first document' 'is the' 'is this'\n",
      " 'second document' 'the first' 'the second' 'the third' 'third one'\n",
      " 'this document' 'this is' 'this the']\n",
      "***Vector Repersentation***\n",
      " [[0 0 1 1 0 0 1 0 0 0 0 1 0]\n",
      " [0 1 0 1 0 1 0 1 0 0 1 0 0]\n",
      " [1 0 0 1 0 0 0 0 1 1 0 1 0]\n",
      " [0 0 1 0 1 0 1 0 0 0 0 0 1]]\n"
     ]
    }
   ],
   "source": [
    "vectorizer2 = CountVectorizer(analyzer='word', ngram_range=(2, 2))\n",
    "X2 = vectorizer2.fit_transform(corpus)\n",
    "print(vectorizer2.get_feature_names_out())\n",
    "print(\"***Vector Repersentation***\\n\",X2.toarray())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "ec4eec9d",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-08-18T14:40:07.248918Z",
     "iopub.status.busy": "2025-08-18T14:40:07.248707Z",
     "iopub.status.idle": "2025-08-18T14:40:18.055088Z",
     "shell.execute_reply": "2025-08-18T14:40:18.054554Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total accuracy classification score: 0.6460435475305364\n",
      "Total F1 classification score: 0.6203806145034193\n"
     ]
    }
   ],
   "source": [
    "# This is the Example for sklearn datasets.\n",
    "# In this is I perform CountVectorizer and then make Prediction.\n",
    "\n",
    "# Create our vectorizer\n",
    "vectorizer = CountVectorizer()\n",
    "\n",
    "train = fetch_20newsgroups(subset='train',remove=('headers', 'footers', 'quotes'))\n",
    "test = fetch_20newsgroups(subset='test',remove=('headers', 'footers', 'quotes'))\n",
    "\n",
    "# Get the training vectors\n",
    "vectors = vectorizer.fit_transform(train.data)\n",
    "\n",
    "clf = MultinomialNB(alpha=.01)\n",
    "clf.fit(vectors, train.target)\n",
    "\n",
    "# Get the test vectors\n",
    "vectors_test = vectorizer.transform(test.data)\n",
    "\n",
    "# Predict and score the vectors\n",
    "pred = clf.predict(vectors_test)\n",
    "acc_score = metrics.accuracy_score(test.target, pred)\n",
    "f1_score = metrics.f1_score(test.target, pred, average='macro')\n",
    "\n",
    "print('Total accuracy classification score: {}'.format(acc_score))\n",
    "print('Total F1 classification score: {}'.format(f1_score))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "ac6a837c",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-08-18T14:40:18.056499Z",
     "iopub.status.busy": "2025-08-18T14:40:18.056337Z",
     "iopub.status.idle": "2025-08-18T14:40:18.058521Z",
     "shell.execute_reply": "2025-08-18T14:40:18.058221Z"
    }
   },
   "outputs": [],
   "source": [
    "txt = [\"He is ::having a great Time, at the park time?\",\n",
    "       \"She, unlike most women, is a big player on the park's grass.\",\n",
    "       \"she can't be going\"]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "67ff368d",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-08-18T14:40:18.059710Z",
     "iopub.status.busy": "2025-08-18T14:40:18.059500Z",
     "iopub.status.idle": "2025-08-18T14:40:18.067412Z",
     "shell.execute_reply": "2025-08-18T14:40:18.067121Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['at' 'be' 'big' 'can' 'going' 'grass' 'great' 'having' 'he' 'is' 'most'\n",
      " 'on' 'park' 'player' 'she' 'the' 'time' 'unlike' 'women']\n"
     ]
    }
   ],
   "source": [
    "vectorizer = TfidfVectorizer()\n",
    "X = vectorizer.fit_transform(txt)\n",
    "print(vectorizer.get_feature_names_out())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "977e0bb6",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-08-18T14:40:18.068655Z",
     "iopub.status.busy": "2025-08-18T14:40:18.068393Z",
     "iopub.status.idle": "2025-08-18T14:40:18.071564Z",
     "shell.execute_reply": "2025-08-18T14:40:18.071241Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(3, 19)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "array([[0.32049968, 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.32049968, 0.32049968, 0.32049968, 0.24374827,\n",
       "        0.        , 0.        , 0.24374827, 0.        , 0.        ,\n",
       "        0.24374827, 0.64099936, 0.        , 0.        ],\n",
       "       [0.        , 0.        , 0.32767345, 0.        , 0.        ,\n",
       "        0.32767345, 0.        , 0.        , 0.        , 0.24920411,\n",
       "        0.32767345, 0.32767345, 0.24920411, 0.32767345, 0.24920411,\n",
       "        0.24920411, 0.        , 0.32767345, 0.32767345],\n",
       "       [0.        , 0.52863461, 0.        , 0.52863461, 0.52863461,\n",
       "        0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.        , 0.        , 0.        , 0.40204024,\n",
       "        0.        , 0.        , 0.        , 0.        ]])"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "print(X.shape)\n",
    "X.toarray()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "6d42b11b",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-08-18T14:40:18.072660Z",
     "iopub.status.busy": "2025-08-18T14:40:18.072434Z",
     "iopub.status.idle": "2025-08-18T14:40:18.074530Z",
     "shell.execute_reply": "2025-08-18T14:40:18.074243Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The text:  ['His smile was not perfect', 'His smile was not not not not so perfect', 'she not sang', 'she was not perfect']\n"
     ]
    }
   ],
   "source": [
    "txt1 = ['His smile was not perfect', 'His smile was not not not not so perfect', 'she not sang', 'she was not perfect']\n",
    "print (\"The text: \", txt1)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "3a4889ba",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-08-18T14:40:18.075641Z",
     "iopub.status.busy": "2025-08-18T14:40:18.075463Z",
     "iopub.status.idle": "2025-08-18T14:40:18.077515Z",
     "shell.execute_reply": "2025-08-18T14:40:18.077206Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Vocabulary: \n",
      "{'he': 8, 'is': 9, 'having': 7, 'great': 6, 'time': 16, 'at': 0, 'the': 15, 'park': 12, 'she': 14, 'unlike': 17, 'most': 10, 'women': 18, 'big': 2, 'player': 13, 'on': 11, 'grass': 5, 'can': 3, 'be': 1, 'going': 4}\n"
     ]
    }
   ],
   "source": [
    "# This will print out a list of words used, and their index in the vectors\n",
    "print('Vocabulary: ')\n",
    "print(vectorizer.vocabulary_)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "135d245f",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-08-18T14:40:18.078660Z",
     "iopub.status.busy": "2025-08-18T14:40:18.078492Z",
     "iopub.status.idle": "2025-08-18T14:40:18.082881Z",
     "shell.execute_reply": "2025-08-18T14:40:18.082603Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[1.69314718, 1.        , 1.28768207, 0.        , 0.        ,\n",
       "        1.69314718, 0.        , 1.28768207],\n",
       "       [1.69314718, 4.        , 1.28768207, 0.        , 0.        ,\n",
       "        1.69314718, 2.38629436, 1.28768207],\n",
       "       [0.        , 1.        , 0.        , 2.38629436, 1.69314718,\n",
       "        0.        , 0.        , 0.        ],\n",
       "       [0.        , 1.        , 1.28768207, 0.        , 1.69314718,\n",
       "        0.        , 0.        , 1.28768207]])"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tf = TfidfVectorizer(smooth_idf=False, sublinear_tf=False, norm=None, analyzer='word')\n",
    "txt_fitted = tf.fit(txt1)\n",
    "txt_transformed = tf.fit_transform(txt1)\n",
    "txt_transformed.toarray()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "cd5644c6",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-08-18T14:40:18.084122Z",
     "iopub.status.busy": "2025-08-18T14:40:18.083937Z",
     "iopub.status.idle": "2025-08-18T14:40:18.086480Z",
     "shell.execute_reply": "2025-08-18T14:40:18.086175Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Hot vector: \n",
      "[[0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]]\n"
     ]
    }
   ],
   "source": [
    "# if we wanted to get the vector for one word:\n",
    "print('Hot vector: ')\n",
    "print(vectorizer.transform(['smile']).toarray())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "779b3916",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-08-18T14:40:18.087657Z",
     "iopub.status.busy": "2025-08-18T14:40:18.087478Z",
     "iopub.status.idle": "2025-08-18T14:40:18.195164Z",
     "shell.execute_reply": "2025-08-18T14:40:18.194810Z"
    }
   },
   "outputs": [
    {
     "ename": "AttributeError",
     "evalue": "'TfidfVectorizer' object has no attribute 'get_feature_names'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "\u001b[0;32m/tmp/ipykernel_8/2420527923.py\u001b[0m in \u001b[0;36m<cell line: 0>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0midf\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0midf_\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 2\u001b[0;31m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdict\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mzip\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtxt_fitted\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget_feature_names\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0midf\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      3\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0;31m# We see that the tokens 'sang','she' have the most idf weight because\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0;31m# they are the only tokens that appear in one document only.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mAttributeError\u001b[0m: 'TfidfVectorizer' object has no attribute 'get_feature_names'"
     ]
    }
   ],
   "source": [
    "idf = tf.idf_\n",
    "print(dict(zip(txt_fitted.get_feature_names(), idf)))\n",
    "\n",
    "# We see that the tokens 'sang','she' have the most idf weight because \n",
    "# they are the only tokens that appear in one document only.\n",
    "# The token 'not' appears 6 times but it is also in all documents, so its idf is the lowest\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "215628b6",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-08-18T14:40:18.196848Z",
     "iopub.status.busy": "2025-08-18T14:40:18.196626Z",
     "iopub.status.idle": "2025-08-18T14:40:18.200503Z",
     "shell.execute_reply": "2025-08-18T14:40:18.200243Z"
    }
   },
   "outputs": [
    {
     "ename": "AttributeError",
     "evalue": "'TfidfVectorizer' object has no attribute 'get_feature_names'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "\u001b[0;32m/tmp/ipykernel_8/318455382.py\u001b[0m in \u001b[0;36m<cell line: 0>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mrr\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mdict\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mzip\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtxt_fitted\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget_feature_names\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0midf\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;31mAttributeError\u001b[0m: 'TfidfVectorizer' object has no attribute 'get_feature_names'"
     ]
    }
   ],
   "source": [
    "rr = dict(zip(txt_fitted.get_feature_names(), idf))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "ab1393ca",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-08-18T14:40:18.201695Z",
     "iopub.status.busy": "2025-08-18T14:40:18.201535Z",
     "iopub.status.idle": "2025-08-18T14:40:18.205613Z",
     "shell.execute_reply": "2025-08-18T14:40:18.205323Z"
    }
   },
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'rr' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m/tmp/ipykernel_8/3988527666.py\u001b[0m in \u001b[0;36m<cell line: 0>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mtoken_weight\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mpd\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mDataFrame\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfrom_dict\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mrr\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0morient\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m'index'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mreset_index\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      2\u001b[0m \u001b[0mtoken_weight\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcolumns\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'token'\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m'weight'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0mtoken_weight\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtoken_weight\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msort_values\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mby\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m'weight'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mascending\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mFalse\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0mtoken_weight\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mNameError\u001b[0m: name 'rr' is not defined"
     ]
    }
   ],
   "source": [
    "token_weight = pd.DataFrame.from_dict(rr, orient='index').reset_index()\n",
    "token_weight.columns=('token','weight')\n",
    "token_weight = token_weight.sort_values(by='weight', ascending=False)\n",
    "token_weight \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "b6964cb4",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-08-18T14:40:18.206705Z",
     "iopub.status.busy": "2025-08-18T14:40:18.206493Z",
     "iopub.status.idle": "2025-08-18T14:40:18.210741Z",
     "shell.execute_reply": "2025-08-18T14:40:18.210474Z"
    }
   },
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'token_weight' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m/tmp/ipykernel_8/4134805813.py\u001b[0m in \u001b[0;36m<cell line: 0>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;31m# Plot bar graph on this txt.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 2\u001b[0;31m \u001b[0msns\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbarplot\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m'token'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m'weight'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdata\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mtoken_weight\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      3\u001b[0m \u001b[0mplt\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtitle\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"Inverse Document Frequency(idf) per token\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0mfig\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mplt\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mgcf\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0mfig\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mset_size_inches\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m10\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;36m5\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mNameError\u001b[0m: name 'token_weight' is not defined"
     ]
    }
   ],
   "source": [
    "# Plot bar graph on this txt.\n",
    "sns.barplot(x='token', y='weight', data=token_weight)            \n",
    "plt.title(\"Inverse Document Frequency(idf) per token\")\n",
    "fig=plt.gcf()\n",
    "fig.set_size_inches(10,5)\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "fa426e4d",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-08-18T14:40:18.211812Z",
     "iopub.status.busy": "2025-08-18T14:40:18.211580Z",
     "iopub.status.idle": "2025-08-18T14:40:18.216025Z",
     "shell.execute_reply": "2025-08-18T14:40:18.215761Z"
    }
   },
   "outputs": [
    {
     "ename": "AttributeError",
     "evalue": "'TfidfVectorizer' object has no attribute 'get_feature_names'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "\u001b[0;32m/tmp/ipykernel_8/2355104974.py\u001b[0m in \u001b[0;36m<cell line: 0>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;31m# get feature names\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 2\u001b[0;31m \u001b[0mfeature_names\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0marray\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget_feature_names\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      3\u001b[0m \u001b[0msorted_by_idf\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0margsort\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0midf_\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"Features with lowest idf:\\n{}\"\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mformat\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfeature_names\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0msorted_by_idf\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;36m3\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mAttributeError\u001b[0m: 'TfidfVectorizer' object has no attribute 'get_feature_names'"
     ]
    }
   ],
   "source": [
    "# get feature names \n",
    "feature_names = np.array(tf.get_feature_names())\n",
    "sorted_by_idf = np.argsort(tf.idf_)\n",
    "\n",
    "print(\"Features with lowest idf:\\n{}\".format(feature_names[sorted_by_idf[:3]]))\n",
    "print(\"\\nFeatures with highest idf:\\n{}\".format(feature_names[sorted_by_idf[-3:]]))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8260d5bb",
   "metadata": {},
   "outputs": [],
   "source": [
    " \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "7a70a2b2",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-08-18T14:40:18.217265Z",
     "iopub.status.busy": "2025-08-18T14:40:18.217014Z",
     "iopub.status.idle": "2025-08-18T14:40:19.077492Z",
     "shell.execute_reply": "2025-08-18T14:40:19.077030Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>comment_text</th>\n",
       "      <th>toxic</th>\n",
       "      <th>severe_toxic</th>\n",
       "      <th>obscene</th>\n",
       "      <th>threat</th>\n",
       "      <th>insult</th>\n",
       "      <th>identity_hate</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0000997932d777bf</td>\n",
       "      <td>Explanation\\nWhy the edits made under my usern...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>000103f0d9cfb60f</td>\n",
       "      <td>D'aww! He matches this background colour I'm s...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>000113f07ec002fd</td>\n",
       "      <td>Hey man, I'm really not trying to edit war. It...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0001b41b1c6bb37e</td>\n",
       "      <td>\"\\nMore\\nI can't make any real suggestions on ...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0001d958c54c6e35</td>\n",
       "      <td>You, sir, are my hero. Any chance you remember...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                 id                                       comment_text  toxic  \\\n",
       "0  0000997932d777bf  Explanation\\nWhy the edits made under my usern...      0   \n",
       "1  000103f0d9cfb60f  D'aww! He matches this background colour I'm s...      0   \n",
       "2  000113f07ec002fd  Hey man, I'm really not trying to edit war. It...      0   \n",
       "3  0001b41b1c6bb37e  \"\\nMore\\nI can't make any real suggestions on ...      0   \n",
       "4  0001d958c54c6e35  You, sir, are my hero. Any chance you remember...      0   \n",
       "\n",
       "   severe_toxic  obscene  threat  insult  identity_hate  \n",
       "0             0        0       0       0              0  \n",
       "1             0        0       0       0              0  \n",
       "2             0        0       0       0              0  \n",
       "3             0        0       0       0              0  \n",
       "4             0        0       0       0              0  "
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_data  =  pd.read_csv('../input/jigsaw-toxic-comment-classification-challenge/train.csv.zip')\n",
    "train_data.head()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "14777f23",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-08-18T14:40:19.078795Z",
     "iopub.status.busy": "2025-08-18T14:40:19.078680Z",
     "iopub.status.idle": "2025-08-18T14:40:19.098337Z",
     "shell.execute_reply": "2025-08-18T14:40:19.098023Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>toxic</th>\n",
       "      <th>severe_toxic</th>\n",
       "      <th>obscene</th>\n",
       "      <th>threat</th>\n",
       "      <th>insult</th>\n",
       "      <th>identity_hate</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>count</th>\n",
       "      <td>159571.000000</td>\n",
       "      <td>159571.000000</td>\n",
       "      <td>159571.000000</td>\n",
       "      <td>159571.000000</td>\n",
       "      <td>159571.000000</td>\n",
       "      <td>159571.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mean</th>\n",
       "      <td>0.095844</td>\n",
       "      <td>0.009996</td>\n",
       "      <td>0.052948</td>\n",
       "      <td>0.002996</td>\n",
       "      <td>0.049364</td>\n",
       "      <td>0.008805</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>std</th>\n",
       "      <td>0.294379</td>\n",
       "      <td>0.099477</td>\n",
       "      <td>0.223931</td>\n",
       "      <td>0.054650</td>\n",
       "      <td>0.216627</td>\n",
       "      <td>0.093420</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>min</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25%</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50%</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>75%</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>max</th>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "               toxic   severe_toxic        obscene         threat  \\\n",
       "count  159571.000000  159571.000000  159571.000000  159571.000000   \n",
       "mean        0.095844       0.009996       0.052948       0.002996   \n",
       "std         0.294379       0.099477       0.223931       0.054650   \n",
       "min         0.000000       0.000000       0.000000       0.000000   \n",
       "25%         0.000000       0.000000       0.000000       0.000000   \n",
       "50%         0.000000       0.000000       0.000000       0.000000   \n",
       "75%         0.000000       0.000000       0.000000       0.000000   \n",
       "max         1.000000       1.000000       1.000000       1.000000   \n",
       "\n",
       "              insult  identity_hate  \n",
       "count  159571.000000  159571.000000  \n",
       "mean        0.049364       0.008805  \n",
       "std         0.216627       0.093420  \n",
       "min         0.000000       0.000000  \n",
       "25%         0.000000       0.000000  \n",
       "50%         0.000000       0.000000  \n",
       "75%         0.000000       0.000000  \n",
       "max         1.000000       1.000000  "
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_data.describe()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "fadbb794",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-08-18T14:40:19.099528Z",
     "iopub.status.busy": "2025-08-18T14:40:19.099377Z",
     "iopub.status.idle": "2025-08-18T14:40:19.862391Z",
     "shell.execute_reply": "2025-08-18T14:40:19.861957Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>comment_text</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>00001cee341fdb12</td>\n",
       "      <td>Yo bitch Ja Rule is more succesful then you'll...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0000247867823ef7</td>\n",
       "      <td>== From RfC == \\n\\n The title is fine as it is...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>00013b17ad220c46</td>\n",
       "      <td>\" \\n\\n == Sources == \\n\\n * Zawe Ashton on Lap...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>00017563c3f7919a</td>\n",
       "      <td>:If you have a look back at the source, the in...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>00017695ad8997eb</td>\n",
       "      <td>I don't anonymously edit articles at all.</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                 id                                       comment_text\n",
       "0  00001cee341fdb12  Yo bitch Ja Rule is more succesful then you'll...\n",
       "1  0000247867823ef7  == From RfC == \\n\\n The title is fine as it is...\n",
       "2  00013b17ad220c46  \" \\n\\n == Sources == \\n\\n * Zawe Ashton on Lap...\n",
       "3  00017563c3f7919a  :If you have a look back at the source, the in...\n",
       "4  00017695ad8997eb          I don't anonymously edit articles at all."
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_data=pd.read_csv('../input/jigsaw-toxic-comment-classification-challenge/test.csv.zip')\n",
    "test_data.head()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "4ec95885",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-08-18T14:40:19.864021Z",
     "iopub.status.busy": "2025-08-18T14:40:19.863772Z",
     "iopub.status.idle": "2025-08-18T14:40:20.041607Z",
     "shell.execute_reply": "2025-08-18T14:40:20.041188Z"
    }
   },
   "outputs": [],
   "source": [
    "from nltk.corpus import stopwords\n",
    "from nltk.stem.porter import PorterStemmer\n",
    "from wordcloud import WordCloud\n",
    "from nltk.stem.snowball import SnowballStemmer\n",
    "from sklearn.model_selection import train_test_split\n",
    "import pickle\n",
    "import string\n",
    "import xgboost as xgb\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.naive_bayes import MultinomialNB\n",
    "from sklearn import metrics\n",
    "from sklearn.metrics import roc_auc_score , accuracy_score , confusion_matrix , f1_score\n",
    "from skmultilearn.problem_transform import BinaryRelevance\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "5a722d0a",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-08-18T14:40:20.043487Z",
     "iopub.status.busy": "2025-08-18T14:40:20.043281Z",
     "iopub.status.idle": "2025-08-18T14:40:20.045933Z",
     "shell.execute_reply": "2025-08-18T14:40:20.045654Z"
    }
   },
   "outputs": [],
   "source": [
    "def clean_comment(text):\n",
    "    text = text.lower()\n",
    "    text = re.sub('','',text).strip() # remove html chars\n",
    "    text = re.sub('\\[|\\(.*\\]|\\)','', text).strip() # remove text in square brackets and parenthesis\n",
    "    text = text.translate(str.maketrans('', '', string.punctuation)) # remove punctuation marks\n",
    "    text = re.sub(\"(\\\\W)\",\" \",text).strip() # remove non-ascii chars\n",
    "    text = re.sub('\\S*\\d\\S*\\s*','', text).strip()  # remove words containing numbers\n",
    "    return text.strip()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "ab721dd9",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-08-18T14:40:20.047111Z",
     "iopub.status.busy": "2025-08-18T14:40:20.046919Z",
     "iopub.status.idle": "2025-08-18T14:40:33.423218Z",
     "shell.execute_reply": "2025-08-18T14:40:33.422724Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0    explanation why the edits made under my userna...\n",
       "1    daww he matches this background colour im seem...\n",
       "2    hey man im really not trying to edit war its j...\n",
       "3    more i cant make any real suggestions on impro...\n",
       "4    you sir are my hero any chance you remember wh...\n",
       "Name: comment_text, dtype: object"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# First convert into string\n",
    "train_data.comment_text = train_data.comment_text.astype(str)\n",
    "\n",
    "# now clean the data using clean_comment.\n",
    "train_data.comment_text = train_data.comment_text.apply(clean_comment)\n",
    "train_data.comment_text.head()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "9dec34d8",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-08-18T14:40:33.424696Z",
     "iopub.status.busy": "2025-08-18T14:40:33.424568Z",
     "iopub.status.idle": "2025-08-18T14:40:36.464207Z",
     "shell.execute_reply": "2025-08-18T14:40:36.463773Z"
    }
   },
   "outputs": [],
   "source": [
    "import nltk\n",
    "from nltk.stem.snowball import SnowballStemmer\n",
    "import en_core_web_sm\n",
    "nlp = en_core_web_sm.load()\n",
    "\n",
    "snow_stemmer = SnowballStemmer(language='english')\n",
    "\n",
    "stopwords = nlp.Defaults.stop_words\n",
    "def apply_stemmer(text):\n",
    "    words = text.split()\n",
    "    sent = [snow_stemmer.stem(word) for word in words if not word in set(stopwords)]\n",
    "    return ' '.join(sent)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "6be4994c",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-08-18T14:40:36.466271Z",
     "iopub.status.busy": "2025-08-18T14:40:36.466013Z",
     "iopub.status.idle": "2025-08-18T14:41:31.082498Z",
     "shell.execute_reply": "2025-08-18T14:41:31.081930Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0    explan edit usernam hardcor metallica fan reve...\n",
       "1    daww match background colour im seem stuck tha...\n",
       "2    hey man im tri edit war guy constant remov rel...\n",
       "3    cant real suggest improv wonder section statis...\n",
       "4                      sir hero chanc rememb page that\n",
       "Name: comment_text, dtype: object"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Apply Stemming\n",
    "train_data.comment_text = train_data.comment_text.apply(apply_stemmer)\n",
    "train_data.comment_text.head()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "ac3c9ddb",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-08-18T14:41:31.084097Z",
     "iopub.status.busy": "2025-08-18T14:41:31.083966Z",
     "iopub.status.idle": "2025-08-18T14:41:31.092267Z",
     "shell.execute_reply": "2025-08-18T14:41:31.091973Z"
    }
   },
   "outputs": [],
   "source": [
    "X = train_data.comment_text\n",
    "y = train_data.drop(['id','comment_text'],axis = 1)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "02b8a768",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-08-18T14:41:31.093551Z",
     "iopub.status.busy": "2025-08-18T14:41:31.093435Z",
     "iopub.status.idle": "2025-08-18T14:41:31.107855Z",
     "shell.execute_reply": "2025-08-18T14:41:31.107495Z"
    }
   },
   "outputs": [],
   "source": [
    "x_train,x_test,y_train,y_test =  train_test_split(X,y,test_size = 0.2,random_state = 45)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "ea358695",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-08-18T14:41:31.109294Z",
     "iopub.status.busy": "2025-08-18T14:41:31.109069Z",
     "iopub.status.idle": "2025-08-18T14:41:56.865518Z",
     "shell.execute_reply": "2025-08-18T14:41:56.865036Z"
    }
   },
   "outputs": [],
   "source": [
    "word_vectorizer = TfidfVectorizer(\n",
    "    strip_accents='unicode',     \n",
    "    analyzer='word',            \n",
    "    token_pattern=r'\\w{1,}',    \n",
    "    ngram_range=(1, 3),         \n",
    "    stop_words='english',\n",
    "    sublinear_tf=True)\n",
    "\n",
    "word_vectorizer.fit(x_train)    \n",
    "train_word_features = word_vectorizer.transform(x_train)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "067c3d74",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-08-18T14:41:56.867285Z",
     "iopub.status.busy": "2025-08-18T14:41:56.867145Z",
     "iopub.status.idle": "2025-08-18T14:42:06.095173Z",
     "shell.execute_reply": "2025-08-18T14:42:06.094704Z"
    }
   },
   "outputs": [],
   "source": [
    "X_train_transformed = word_vectorizer.transform(x_train)\n",
    "X_test_transformed = word_vectorizer.transform(x_test)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "cc726bd5",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-08-18T14:42:06.096877Z",
     "iopub.status.busy": "2025-08-18T14:42:06.096735Z",
     "iopub.status.idle": "2025-08-18T14:42:52.225888Z",
     "shell.execute_reply": "2025-08-18T14:42:52.225212Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<style>#sk-container-id-1 {color: black;background-color: white;}#sk-container-id-1 pre{padding: 0;}#sk-container-id-1 div.sk-toggleable {background-color: white;}#sk-container-id-1 label.sk-toggleable__label {cursor: pointer;display: block;width: 100%;margin-bottom: 0;padding: 0.3em;box-sizing: border-box;text-align: center;}#sk-container-id-1 label.sk-toggleable__label-arrow:before {content: \"â–¸\";float: left;margin-right: 0.25em;color: #696969;}#sk-container-id-1 label.sk-toggleable__label-arrow:hover:before {color: black;}#sk-container-id-1 div.sk-estimator:hover label.sk-toggleable__label-arrow:before {color: black;}#sk-container-id-1 div.sk-toggleable__content {max-height: 0;max-width: 0;overflow: hidden;text-align: left;background-color: #f0f8ff;}#sk-container-id-1 div.sk-toggleable__content pre {margin: 0.2em;color: black;border-radius: 0.25em;background-color: #f0f8ff;}#sk-container-id-1 input.sk-toggleable__control:checked~div.sk-toggleable__content {max-height: 200px;max-width: 100%;overflow: auto;}#sk-container-id-1 input.sk-toggleable__control:checked~label.sk-toggleable__label-arrow:before {content: \"â–¾\";}#sk-container-id-1 div.sk-estimator input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-1 div.sk-label input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-1 input.sk-hidden--visually {border: 0;clip: rect(1px 1px 1px 1px);clip: rect(1px, 1px, 1px, 1px);height: 1px;margin: -1px;overflow: hidden;padding: 0;position: absolute;width: 1px;}#sk-container-id-1 div.sk-estimator {font-family: monospace;background-color: #f0f8ff;border: 1px dotted black;border-radius: 0.25em;box-sizing: border-box;margin-bottom: 0.5em;}#sk-container-id-1 div.sk-estimator:hover {background-color: #d4ebff;}#sk-container-id-1 div.sk-parallel-item::after {content: \"\";width: 100%;border-bottom: 1px solid gray;flex-grow: 1;}#sk-container-id-1 div.sk-label:hover label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-1 div.sk-serial::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: 0;}#sk-container-id-1 div.sk-serial {display: flex;flex-direction: column;align-items: center;background-color: white;padding-right: 0.2em;padding-left: 0.2em;position: relative;}#sk-container-id-1 div.sk-item {position: relative;z-index: 1;}#sk-container-id-1 div.sk-parallel {display: flex;align-items: stretch;justify-content: center;background-color: white;position: relative;}#sk-container-id-1 div.sk-item::before, #sk-container-id-1 div.sk-parallel-item::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: -1;}#sk-container-id-1 div.sk-parallel-item {display: flex;flex-direction: column;z-index: 1;position: relative;background-color: white;}#sk-container-id-1 div.sk-parallel-item:first-child::after {align-self: flex-end;width: 50%;}#sk-container-id-1 div.sk-parallel-item:last-child::after {align-self: flex-start;width: 50%;}#sk-container-id-1 div.sk-parallel-item:only-child::after {width: 0;}#sk-container-id-1 div.sk-dashed-wrapped {border: 1px dashed gray;margin: 0 0.4em 0.5em 0.4em;box-sizing: border-box;padding-bottom: 0.4em;background-color: white;}#sk-container-id-1 div.sk-label label {font-family: monospace;font-weight: bold;display: inline-block;line-height: 1.2em;}#sk-container-id-1 div.sk-label-container {text-align: center;}#sk-container-id-1 div.sk-container {/* jupyter's `normalize.less` sets `[hidden] { display: none; }` but bootstrap.min.css set `[hidden] { display: none !important; }` so we also need the `!important` here to be able to override the default hidden behavior on the sphinx rendered scikit-learn.org. See: https://github.com/scikit-learn/scikit-learn/issues/21755 */display: inline-block !important;position: relative;}#sk-container-id-1 div.sk-text-repr-fallback {display: none;}</style><div id=\"sk-container-id-1\" class=\"sk-top-container\"><div class=\"sk-text-repr-fallback\"><pre>OneVsRestClassifier(estimator=LogisticRegression(C=10, random_state=100,\n",
       "                                                 solver=&#x27;liblinear&#x27;))</pre><b>In a Jupyter environment, please rerun this cell to show the HTML representation or trust the notebook. <br />On GitHub, the HTML representation is unable to render, please try loading this page with nbviewer.org.</b></div><div class=\"sk-container\" hidden><div class=\"sk-item sk-dashed-wrapped\"><div class=\"sk-label-container\"><div class=\"sk-label sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-1\" type=\"checkbox\" ><label for=\"sk-estimator-id-1\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">OneVsRestClassifier</label><div class=\"sk-toggleable__content\"><pre>OneVsRestClassifier(estimator=LogisticRegression(C=10, random_state=100,\n",
       "                                                 solver=&#x27;liblinear&#x27;))</pre></div></div></div><div class=\"sk-parallel\"><div class=\"sk-parallel-item\"><div class=\"sk-item\"><div class=\"sk-label-container\"><div class=\"sk-label sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-2\" type=\"checkbox\" ><label for=\"sk-estimator-id-2\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">estimator: LogisticRegression</label><div class=\"sk-toggleable__content\"><pre>LogisticRegression(C=10, random_state=100, solver=&#x27;liblinear&#x27;)</pre></div></div></div><div class=\"sk-serial\"><div class=\"sk-item\"><div class=\"sk-estimator sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-3\" type=\"checkbox\" ><label for=\"sk-estimator-id-3\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">LogisticRegression</label><div class=\"sk-toggleable__content\"><pre>LogisticRegression(C=10, random_state=100, solver=&#x27;liblinear&#x27;)</pre></div></div></div></div></div></div></div></div></div></div>"
      ],
      "text/plain": [
       "OneVsRestClassifier(estimator=LogisticRegression(C=10, random_state=100,\n",
       "                                                 solver='liblinear'))"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.multiclass import OneVsRestClassifier\n",
    "from skmultilearn.problem_transform import BinaryRelevance\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "seed=100\n",
    "\n",
    "log_reg = LogisticRegression(C = 10, penalty='l2', solver = 'liblinear', random_state=seed)\n",
    "\n",
    "# fit model\n",
    "classifier_ovr_log = OneVsRestClassifier(log_reg)\n",
    "classifier_ovr_log.fit(X_train_transformed, y_train)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "cfcc50b2",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-08-18T14:42:52.227457Z",
     "iopub.status.busy": "2025-08-18T14:42:52.227266Z",
     "iopub.status.idle": "2025-08-18T14:42:52.493620Z",
     "shell.execute_reply": "2025-08-18T14:42:52.493226Z"
    }
   },
   "outputs": [],
   "source": [
    "y_train_pred_proba = classifier_ovr_log.predict_proba(X_train_transformed)\n",
    "y_test_pred_proba = classifier_ovr_log.predict_proba(X_test_transformed)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "11a975de",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-08-18T14:42:52.495250Z",
     "iopub.status.busy": "2025-08-18T14:42:52.495101Z",
     "iopub.status.idle": "2025-08-18T14:42:52.497521Z",
     "shell.execute_reply": "2025-08-18T14:42:52.497267Z"
    }
   },
   "outputs": [],
   "source": [
    "def make_test_predictions(df,classifier):\n",
    "    df.comment_text = df.comment_text.apply(clean_comment)\n",
    "    df.comment_text = df.comment_text.apply(apply_stemmer)\n",
    "    X_test = df.comment_text\n",
    "    X_test_transformed = word_vectorizer.transform(X_test)\n",
    "    y_test_pred = classifier.predict_proba(X_test_transformed)\n",
    "    return y_test_pred\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "97e6609b",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-08-18T14:42:52.498718Z",
     "iopub.status.busy": "2025-08-18T14:42:52.498429Z",
     "iopub.status.idle": "2025-08-18T14:43:59.851828Z",
     "shell.execute_reply": "2025-08-18T14:43:59.851324Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[9.99989906e-01, 3.48900753e-01, 9.99967167e-01, 4.48902405e-02,\n",
       "        9.99209052e-01, 5.74793829e-01],\n",
       "       [4.88663084e-03, 1.56255441e-03, 2.73185663e-03, 9.30419896e-04,\n",
       "        5.74959925e-03, 1.76905706e-03],\n",
       "       [9.58295835e-03, 1.63792815e-03, 4.28093789e-03, 6.22680663e-04,\n",
       "        5.09035196e-03, 1.33114745e-03],\n",
       "       ...,\n",
       "       [1.61223427e-03, 6.17899714e-04, 2.03705319e-03, 5.16147663e-04,\n",
       "        1.97307144e-03, 1.21050614e-03],\n",
       "       [7.23585485e-03, 1.46190524e-03, 9.29094995e-03, 1.39539591e-03,\n",
       "        9.42753384e-03, 2.03683343e-02],\n",
       "       [9.97740727e-01, 2.10892788e-03, 9.36371605e-01, 4.38763697e-03,\n",
       "        5.74664356e-01, 8.63002010e-03]])"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_pred=make_test_predictions(test_data,classifier_ovr_log)\n",
    "y_pred\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "8b8f9ae5",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-08-18T14:43:59.853202Z",
     "iopub.status.busy": "2025-08-18T14:43:59.853037Z",
     "iopub.status.idle": "2025-08-18T14:43:59.860191Z",
     "shell.execute_reply": "2025-08-18T14:43:59.859923Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>toxic</th>\n",
       "      <th>severe_toxic</th>\n",
       "      <th>obscene</th>\n",
       "      <th>threat</th>\n",
       "      <th>insult</th>\n",
       "      <th>identity_hate</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.999990</td>\n",
       "      <td>0.348901</td>\n",
       "      <td>0.999967</td>\n",
       "      <td>0.044890</td>\n",
       "      <td>0.999209</td>\n",
       "      <td>0.574794</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.004887</td>\n",
       "      <td>0.001563</td>\n",
       "      <td>0.002732</td>\n",
       "      <td>0.000930</td>\n",
       "      <td>0.005750</td>\n",
       "      <td>0.001769</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.009583</td>\n",
       "      <td>0.001638</td>\n",
       "      <td>0.004281</td>\n",
       "      <td>0.000623</td>\n",
       "      <td>0.005090</td>\n",
       "      <td>0.001331</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.000827</td>\n",
       "      <td>0.000617</td>\n",
       "      <td>0.000710</td>\n",
       "      <td>0.000430</td>\n",
       "      <td>0.000867</td>\n",
       "      <td>0.000376</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.008856</td>\n",
       "      <td>0.000373</td>\n",
       "      <td>0.004628</td>\n",
       "      <td>0.000430</td>\n",
       "      <td>0.004610</td>\n",
       "      <td>0.000736</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>153159</th>\n",
       "      <td>0.012474</td>\n",
       "      <td>0.001381</td>\n",
       "      <td>0.003993</td>\n",
       "      <td>0.000748</td>\n",
       "      <td>0.009043</td>\n",
       "      <td>0.001297</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>153160</th>\n",
       "      <td>0.063257</td>\n",
       "      <td>0.003455</td>\n",
       "      <td>0.016730</td>\n",
       "      <td>0.004961</td>\n",
       "      <td>0.026025</td>\n",
       "      <td>0.006423</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>153161</th>\n",
       "      <td>0.001612</td>\n",
       "      <td>0.000618</td>\n",
       "      <td>0.002037</td>\n",
       "      <td>0.000516</td>\n",
       "      <td>0.001973</td>\n",
       "      <td>0.001211</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>153162</th>\n",
       "      <td>0.007236</td>\n",
       "      <td>0.001462</td>\n",
       "      <td>0.009291</td>\n",
       "      <td>0.001395</td>\n",
       "      <td>0.009428</td>\n",
       "      <td>0.020368</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>153163</th>\n",
       "      <td>0.997741</td>\n",
       "      <td>0.002109</td>\n",
       "      <td>0.936372</td>\n",
       "      <td>0.004388</td>\n",
       "      <td>0.574664</td>\n",
       "      <td>0.008630</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>153164 rows Ã— 6 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "           toxic  severe_toxic   obscene    threat    insult  identity_hate\n",
       "0       0.999990      0.348901  0.999967  0.044890  0.999209       0.574794\n",
       "1       0.004887      0.001563  0.002732  0.000930  0.005750       0.001769\n",
       "2       0.009583      0.001638  0.004281  0.000623  0.005090       0.001331\n",
       "3       0.000827      0.000617  0.000710  0.000430  0.000867       0.000376\n",
       "4       0.008856      0.000373  0.004628  0.000430  0.004610       0.000736\n",
       "...          ...           ...       ...       ...       ...            ...\n",
       "153159  0.012474      0.001381  0.003993  0.000748  0.009043       0.001297\n",
       "153160  0.063257      0.003455  0.016730  0.004961  0.026025       0.006423\n",
       "153161  0.001612      0.000618  0.002037  0.000516  0.001973       0.001211\n",
       "153162  0.007236      0.001462  0.009291  0.001395  0.009428       0.020368\n",
       "153163  0.997741      0.002109  0.936372  0.004388  0.574664       0.008630\n",
       "\n",
       "[153164 rows x 6 columns]"
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_pred_df = pd.DataFrame(y_pred,columns=y.columns)\n",
    "y_pred_df\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "775c7bf7",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-08-18T14:43:59.861475Z",
     "iopub.status.busy": "2025-08-18T14:43:59.861200Z",
     "iopub.status.idle": "2025-08-18T14:44:00.686422Z",
     "shell.execute_reply": "2025-08-18T14:44:00.685955Z"
    }
   },
   "outputs": [],
   "source": [
    "submission_df = pd.concat([test_data.id, y_pred_df], axis=1)\n",
    "submission_df.to_csv('submission.csv', index = False)\n"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}

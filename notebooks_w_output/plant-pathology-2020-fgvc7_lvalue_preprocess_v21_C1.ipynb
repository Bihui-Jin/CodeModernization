{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "8572195f",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-08-18T09:29:17.411738Z",
     "iopub.status.busy": "2025-08-18T09:29:17.411463Z",
     "iopub.status.idle": "2025-08-18T09:29:18.125193Z",
     "shell.execute_reply": "2025-08-18T09:29:18.124703Z"
    }
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from pathlib import Path"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "f95cf256",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-08-18T09:29:18.127106Z",
     "iopub.status.busy": "2025-08-18T09:29:18.126840Z",
     "iopub.status.idle": "2025-08-18T09:29:24.350169Z",
     "shell.execute_reply": "2025-08-18T09:29:24.349775Z"
    }
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-08-18 09:29:18.741590: E external/local_xla/xla/stream_executor/cuda/cuda_fft.cc:477] Unable to register cuFFT factory: Attempting to register factory for plugin cuFFT when one has already been registered\n",
      "WARNING: All log messages before absl::InitializeLog() is called are written to STDERR\n",
      "E0000 00:00:1755509358.755658       8 cuda_dnn.cc:8310] Unable to register cuDNN factory: Attempting to register factory for plugin cuDNN when one has already been registered\n",
      "E0000 00:00:1755509358.760035       8 cuda_blas.cc:1418] Unable to register cuBLAS factory: Attempting to register factory for plugin cuBLAS when one has already been registered\n",
      "2025-08-18 09:29:18.776299: I tensorflow/core/platform/cpu_feature_guard.cc:210] This TensorFlow binary is optimized to use available CPU instructions in performance-critical operations.\n",
      "To enable the following instructions: AVX2 FMA, in other operations, rebuild TensorFlow with the appropriate compiler flags.\n"
     ]
    },
    {
     "ename": "ImportError",
     "evalue": "cannot import name 'ImageDataGenerator' from 'keras.preprocessing.image' (/usr/local/lib/python3.11/dist-packages/keras/api/preprocessing/image/__init__.py)",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mImportError\u001b[0m                               Traceback (most recent call last)",
      "\u001b[0;32m/tmp/ipykernel_8/394002189.py\u001b[0m in \u001b[0;36m<cell line: 0>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      8\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mos\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      9\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0msklearn\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmodel_selection\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mtrain_test_split\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 10\u001b[0;31m \u001b[0;32mfrom\u001b[0m \u001b[0mkeras\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpreprocessing\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mimage\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mImageDataGenerator\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     11\u001b[0m \u001b[0mget_ipython\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msystem\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'pip install efficientnet pandarallel'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     12\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mefficientnet\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtfkeras\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mefn\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mImportError\u001b[0m: cannot import name 'ImageDataGenerator' from 'keras.preprocessing.image' (/usr/local/lib/python3.11/dist-packages/keras/api/preprocessing/image/__init__.py)"
     ]
    }
   ],
   "source": [
    "# Import library\n",
    "import cv2\n",
    "import matplotlib.pyplot as plt\n",
    "from tqdm import tqdm\n",
    "import numpy as np # linear algebra\n",
    "import pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\n",
    "tqdm.pandas()\n",
    "import os\n",
    "from sklearn.model_selection import train_test_split\n",
    "from keras.preprocessing.image import ImageDataGenerator\n",
    "!pip install efficientnet pandarallel\n",
    "import efficientnet.tfkeras as efn \n",
    "import tensorflow as tf\n",
    "import tensorflow.keras as keras\n",
    "from pandarallel import pandarallel\n",
    "pandarallel.initialize(progress_bar=True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "7a50e57c",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-08-18T09:29:24.351708Z",
     "iopub.status.busy": "2025-08-18T09:29:24.351547Z",
     "iopub.status.idle": "2025-08-18T09:29:24.357845Z",
     "shell.execute_reply": "2025-08-18T09:29:24.357552Z"
    }
   },
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'tf' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m/tmp/ipykernel_8/2953329165.py\u001b[0m in \u001b[0;36m<cell line: 0>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     10\u001b[0m     \u001b[0mtf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcompat\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mv1\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0menable_eager_execution\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     11\u001b[0m \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 12\u001b[0;31m     \u001b[0mstrategy\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdistribute\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mMirroredStrategy\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m: name 'tf' is not defined"
     ]
    }
   ],
   "source": [
    "USE_TPU = 'TPU_NAME' in os.environ\n",
    "if USE_TPU:\n",
    "    # detect and init the TPU\n",
    "    tpu = tf.distribute.cluster_resolver.TPUClusterResolver()\n",
    "    tf.config.experimental_connect_to_cluster(tpu)\n",
    "    tf.tpu.experimental.initialize_tpu_system(tpu)\n",
    "\n",
    "    # instantiate a distribution strategy\n",
    "    strategy = tf.distribute.experimental.TPUStrategy(tpu)\n",
    "    tf.compat.v1.enable_eager_execution()\n",
    "else:\n",
    "    strategy = tf.distribute.MirroredStrategy()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "cd465345",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-08-18T09:29:24.359011Z",
     "iopub.status.busy": "2025-08-18T09:29:24.358819Z",
     "iopub.status.idle": "2025-08-18T09:29:24.364326Z",
     "shell.execute_reply": "2025-08-18T09:29:24.364048Z"
    }
   },
   "outputs": [],
   "source": [
    "# Read data\n",
    "IMAGE_PATH = \"../input/plant-pathology-2020-fgvc7/images/\"\n",
    "TEST_PATH = \"../input/plant-pathology-2020-fgvc7/test.csv\"\n",
    "TRAIN_PATH = \"../input/plant-pathology-2020-fgvc7/train.csv\"\n",
    "SUB_PATH = \"../input/plant-pathology-2020-fgvc7/sample_submission.csv\"\n",
    "\n",
    "sub = pd.read_csv(SUB_PATH)\n",
    "test_data = pd.read_csv(TEST_PATH)\n",
    "train_data = pd.read_csv(TRAIN_PATH)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "bf000373",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-08-18T09:29:24.365613Z",
     "iopub.status.busy": "2025-08-18T09:29:24.365407Z",
     "iopub.status.idle": "2025-08-18T09:29:24.369123Z",
     "shell.execute_reply": "2025-08-18T09:29:24.368800Z"
    }
   },
   "outputs": [],
   "source": [
    "def init_grabcut_mask(h, w):\n",
    "    mask = np.ones((h, w), np.uint8) * cv2.GC_PR_BGD\n",
    "    mask[h//4:3*h//4, w//4:3*w//4] = cv2.GC_PR_FGD\n",
    "    mask[2*h//5:3*h//5, 2*w//5:3*w//5] = cv2.GC_FGD\n",
    "    #mask[h//2, w//2] = cv2.GC_FGD\n",
    "    return mask\n",
    "\n",
    "\n",
    "def remove_background(image, h=136, w=205):\n",
    "    orig_image = image\n",
    "    image = cv2.resize(image, (w, h))\n",
    "    mask = init_grabcut_mask(h, w)\n",
    "    bgm = np.zeros((1, 65), np.float64)\n",
    "    fgm = np.zeros((1, 65), np.float64)\n",
    "    cv2.grabCut(image, mask, None, bgm, fgm, 1, cv2.GC_INIT_WITH_MASK)\n",
    "    mask_binary = np.where((mask == 2) | (mask == 0), 0, 1).astype('uint8')\n",
    "    h, w = orig_image.shape[:2]\n",
    "    mask_binary = cv2.resize(mask_binary, (w, h))\n",
    "    result = cv2.bitwise_and(orig_image, orig_image, mask=mask_binary)\n",
    "    return result\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "009b1a8f",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-08-18T09:29:24.370213Z",
     "iopub.status.busy": "2025-08-18T09:29:24.370034Z",
     "iopub.status.idle": "2025-08-18T09:29:24.375456Z",
     "shell.execute_reply": "2025-08-18T09:29:24.375172Z"
    }
   },
   "outputs": [
    {
     "ename": "SyntaxError",
     "evalue": "invalid syntax. Perhaps you forgot a comma? (1764400885.py, line 75)",
     "output_type": "error",
     "traceback": [
      "\u001b[0;36m  File \u001b[0;32m\"/tmp/ipykernel_8/1764400885.py\"\u001b[0;36m, line \u001b[0;32m75\u001b[0m\n\u001b[0;31m    return tf.cond(choice  0.5, lambda: x, lambda: random_crop(x))\u001b[0m\n\u001b[0m                   ^\u001b[0m\n\u001b[0;31mSyntaxError\u001b[0m\u001b[0;31m:\u001b[0m invalid syntax. Perhaps you forgot a comma?\n"
     ]
    }
   ],
   "source": [
    "def rotate(x: tf.Tensor) -> tf.Tensor:\n",
    "    \"\"\"Rotation augmentation\n",
    "\n",
    "    Args:\n",
    "        x: Image\n",
    "\n",
    "    Returns:\n",
    "        Augmented image\n",
    "    \"\"\"\n",
    "\n",
    "    # Rotate 0, 90, 180, 270 degrees\n",
    "    return tf.image.rot90(x, tf.random.uniform(shape=[], minval=0, maxval=4, dtype=tf.int32))\n",
    "\n",
    "\n",
    "def flip(x: tf.Tensor) -> tf.Tensor:\n",
    "    \"\"\"Flip augmentation\n",
    "\n",
    "    Args:\n",
    "        x: Image to flip\n",
    "\n",
    "    Returns:\n",
    "        Augmented image\n",
    "    \"\"\"\n",
    "    x = tf.image.random_flip_left_right(x)\n",
    "    x = tf.image.random_flip_up_down(x)\n",
    "\n",
    "    return x\n",
    "\n",
    "\n",
    "def color(x: tf.Tensor) -> tf.Tensor:\n",
    "    \"\"\"Color augmentation\n",
    "\n",
    "    Args:\n",
    "        x: Image\n",
    "\n",
    "    Returns:\n",
    "        Augmented image\n",
    "    \"\"\"\n",
    "    x = tf.image.random_hue(x, 0.08)\n",
    "    x = tf.image.random_saturation(x, 0.6, 1.6)\n",
    "    x = tf.image.random_brightness(x, 0.05)\n",
    "    x = tf.image.random_contrast(x, 0.7, 1.3)\n",
    "    return x\n",
    "\n",
    "\n",
    "def zoom(x: tf.Tensor) -> tf.Tensor:\n",
    "    \"\"\"Zoom augmentation\n",
    "\n",
    "    Args:\n",
    "        x: Image\n",
    "\n",
    "    Returns:\n",
    "        Augmented image\n",
    "    \"\"\"\n",
    "\n",
    "    # Generate 20 crop settings, ranging from a 1% to 20% crop.\n",
    "    scales = list(np.arange(0.8, 1.0, 0.01))\n",
    "    boxes = np.zeros((len(scales), 4))\n",
    "\n",
    "    for i, scale in enumerate(scales):\n",
    "        x1 = y1 = 0.5 - (0.5 * scale)\n",
    "        x2 = y2 = 0.5 + (0.5 * scale)\n",
    "        boxes[i] = [x1, y1, x2, y2]\n",
    "\n",
    "    def random_crop(img):\n",
    "        # Create different crops for an image\n",
    "        crops = tf.image.crop_and_resize([img], boxes=boxes, box_indices=np.zeros(len(scales)), crop_size=(32, 32))\n",
    "        # Return a random crop\n",
    "        return crops[tf.random.uniform(shape=[], minval=0, maxval=len(scales), dtype=tf.int32)]\n",
    "\n",
    "\n",
    "    choice = tf.random.uniform(shape=[], minval=0., maxval=1., dtype=tf.float32)\n",
    "\n",
    "    # Only apply cropping 50% of the time\n",
    "    return tf.cond(choice  0.5, lambda: x, lambda: random_crop(x))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "29d4a523",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-08-18T09:29:24.376741Z",
     "iopub.status.busy": "2025-08-18T09:29:24.376511Z",
     "iopub.status.idle": "2025-08-18T09:29:24.382432Z",
     "shell.execute_reply": "2025-08-18T09:29:24.382166Z"
    }
   },
   "outputs": [],
   "source": [
    "def get_data_generators(preprocess=True, augment=True, IMAGE_SIZE=(3*136, 3*205)):\n",
    "    \n",
    "    def load_image(image_id):\n",
    "        file_path = image_id + \".jpg\"\n",
    "        image = cv2.imread(IMAGE_PATH + file_path)\n",
    "        image = cv2.resize(image, IMAGE_SIZE[::-1])\n",
    "        image = cv2.cvtColor(image, cv2.COLOR_BGR2RGB)\n",
    "        if preprocess:\n",
    "            image = remove_background(image)\n",
    "        return image\n",
    "\n",
    "    print(\"Preprocessing training images...\")\n",
    "    train_images = np.stack(train_data[\"image_id\"].parallel_apply(load_image))\n",
    "    plt.imshow(train_images[0])\n",
    "    labels = train_data[['healthy', 'multiple_diseases', 'rust', 'scab']]\n",
    "    dataset = tf.data.Dataset.from_tensor_slices((train_images, np.stack(labels.values)))\n",
    "    \n",
    "    def map_func(image, label):\n",
    "        image = tf.cast(image, tf.float32) / 255\n",
    "        return image, label\n",
    "    dataset = dataset.map(map_func, \n",
    "                          num_parallel_calls=tf.data.experimental.AUTOTUNE, \n",
    "                          deterministic=False)\n",
    "\n",
    "    if augment:\n",
    "        # Add augmentations\n",
    "        augmentations = [flip, color, rotate, zoom]\n",
    "    \n",
    "        # Add the augmentations to the dataset\n",
    "        for f in augmentations:\n",
    "            # Apply the augmentation, run 4 jobs in parallel.\n",
    "            dataset = dataset.map(lambda x, y: (f(x), y),\n",
    "                                  num_parallel_calls=tf.data.experimental.AUTOTUNE, \n",
    "                                  deterministic=False)\n",
    "\n",
    "        # Make sure that the values are still in [0, 1]\n",
    "        dataset = dataset.map(lambda x, y: (tf.clip_by_value(x, 0, 1), y), \n",
    "                              num_parallel_calls=tf.data.experimental.AUTOTUNE, \n",
    "                              deterministic=False)\n",
    "    \n",
    "    train_size = int(len(train_data) * 0.85)\n",
    "    valid_size = len(train_data) - train_size\n",
    "    \n",
    "    train = dataset.take(train_size)\n",
    "    train = train.repeat().batch(32)\n",
    "    train = train.prefetch(2)\n",
    "    \n",
    "    valid = dataset.skip(train_size).take(valid_size)\n",
    "    valid = valid.repeat().batch(32)\n",
    "    valid = valid.prefetch(2)\n",
    "    \n",
    "    print(\"Preprocessing test images...\")\n",
    "    test_images = np.stack(test_data[\"image_id\"].parallel_apply(load_image))\n",
    "    test = tf.data.Dataset.from_tensor_slices((np.stack(test_images,)))\n",
    "    \n",
    "    test = test.map(lambda image: tf.cast(image, tf.float32) / 255, \n",
    "                    num_parallel_calls=tf.data.experimental.AUTOTUNE, \n",
    "                    deterministic=False)\n",
    "    test = test.batch(32).prefetch(2)\n",
    "    \n",
    "    return train, valid, test\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "5d871612",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-08-18T09:29:24.383565Z",
     "iopub.status.busy": "2025-08-18T09:29:24.383318Z",
     "iopub.status.idle": "2025-08-18T09:29:24.393942Z",
     "shell.execute_reply": "2025-08-18T09:29:24.393606Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Preprocessing training images...\n"
     ]
    },
    {
     "ename": "AttributeError",
     "evalue": "'Series' object has no attribute 'parallel_apply'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "\u001b[0;32m/tmp/ipykernel_8/3661367199.py\u001b[0m in \u001b[0;36m<cell line: 0>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mtrain\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mval\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtest\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mget_data_generators\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;32mFalse\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;32mTrue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m/tmp/ipykernel_8/4090462216.py\u001b[0m in \u001b[0;36mget_data_generators\u001b[0;34m(preprocess, augment, IMAGE_SIZE)\u001b[0m\n\u001b[1;32m     11\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     12\u001b[0m     \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"Preprocessing training images...\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 13\u001b[0;31m     \u001b[0mtrain_images\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstack\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtrain_data\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m\"image_id\"\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mparallel_apply\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mload_image\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     14\u001b[0m     \u001b[0mplt\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mimshow\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtrain_images\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     15\u001b[0m     \u001b[0mlabels\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtrain_data\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'healthy'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'multiple_diseases'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'rust'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'scab'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/pandas/core/generic.py\u001b[0m in \u001b[0;36m__getattr__\u001b[0;34m(self, name)\u001b[0m\n\u001b[1;32m   6297\u001b[0m         ):\n\u001b[1;32m   6298\u001b[0m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mname\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 6299\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mobject\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__getattribute__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mname\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   6300\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   6301\u001b[0m     \u001b[0;34m@\u001b[0m\u001b[0mfinal\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mAttributeError\u001b[0m: 'Series' object has no attribute 'parallel_apply'"
     ]
    }
   ],
   "source": [
    "train, val, test = get_data_generators(False, True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "e8b74290",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-08-18T09:29:24.395102Z",
     "iopub.status.busy": "2025-08-18T09:29:24.394904Z",
     "iopub.status.idle": "2025-08-18T09:29:24.397488Z",
     "shell.execute_reply": "2025-08-18T09:29:24.397205Z"
    }
   },
   "outputs": [],
   "source": [
    "def get_model(): \n",
    "    model = keras.Sequential()\n",
    "    model.add(efn.EfficientNetB7(\n",
    "        include_top=False, weights='imagenet', input_tensor=None, input_shape=None,\n",
    "        pooling=None, classes=4))\n",
    "    model.add(keras.layers.GlobalAveragePooling2D())\n",
    "    model.add(keras.layers.Dense(128, activation=\"relu\"))\n",
    "    model.add(keras.layers.Dense(64, activation=\"relu\"))\n",
    "    model.add(keras.layers.Dense(4, activation=\"softmax\"))\n",
    "    model.summary()\n",
    "    return model\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "4727b5cd",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-08-18T09:29:24.398768Z",
     "iopub.status.busy": "2025-08-18T09:29:24.398508Z",
     "iopub.status.idle": "2025-08-18T09:29:24.404173Z",
     "shell.execute_reply": "2025-08-18T09:29:24.403897Z"
    }
   },
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'strategy' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m/tmp/ipykernel_8/1158637717.py\u001b[0m in \u001b[0;36m<cell line: 0>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0;32mwith\u001b[0m \u001b[0mstrategy\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mscope\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      2\u001b[0m     \u001b[0mmodel\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mget_model\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m     model.compile(\n\u001b[1;32m      4\u001b[0m         \u001b[0moptimizer\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mkeras\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0moptimizers\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mAdam\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlearning_rate\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m1e-3\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m         \u001b[0mloss\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mkeras\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlosses\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcategorical_crossentropy\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mNameError\u001b[0m: name 'strategy' is not defined"
     ]
    }
   ],
   "source": [
    "with strategy.scope():\n",
    "    model = get_model()\n",
    "    model.compile(\n",
    "        optimizer=keras.optimizers.Adam(learning_rate=1e-3),\n",
    "        loss=keras.losses.categorical_crossentropy,\n",
    "        metrics=[keras.metrics.categorical_accuracy])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "bf47a7c0",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-08-18T09:29:24.405293Z",
     "iopub.status.busy": "2025-08-18T09:29:24.405105Z",
     "iopub.status.idle": "2025-08-18T09:29:24.439474Z",
     "shell.execute_reply": "2025-08-18T09:29:24.439145Z"
    }
   },
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'model' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m/tmp/ipykernel_8/288679593.py\u001b[0m in \u001b[0;36m<cell line: 0>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0mtensorflow\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mkeras\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcallbacks\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mReduceLROnPlateau\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mTensorBoard\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 3\u001b[0;31m history = model.fit(train,                                    \n\u001b[0m\u001b[1;32m      4\u001b[0m     \u001b[0msteps_per_epoch\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m50\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m     \u001b[0mepochs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m40\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mNameError\u001b[0m: name 'model' is not defined"
     ]
    }
   ],
   "source": [
    "from tensorflow.keras.callbacks import ReduceLROnPlateau, TensorBoard\n",
    "\n",
    "history = model.fit(train,                                    \n",
    "    steps_per_epoch=50, \n",
    "    epochs=40,\n",
    "    validation_data=val,\n",
    "    validation_steps=50,\n",
    "    validation_freq=1,\n",
    "    verbose=1,\n",
    "    callbacks=[\n",
    "        #ReduceLROnPlateau(monitor='val_loss', factor=0.3, patience=3, min_lr=0.000001),\n",
    "        #TensorBoard(log_dir=\"tensorboard/\")\n",
    "    ])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "f3ede8fe",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-08-18T09:29:24.440705Z",
     "iopub.status.busy": "2025-08-18T09:29:24.440410Z",
     "iopub.status.idle": "2025-08-18T09:29:24.446170Z",
     "shell.execute_reply": "2025-08-18T09:29:24.445868Z"
    }
   },
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'model' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m/tmp/ipykernel_8/1528956638.py\u001b[0m in \u001b[0;36m<cell line: 0>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;31m# Submission\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 2\u001b[0;31m \u001b[0mtest_pr\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpredict\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtest\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mverbose\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      3\u001b[0m \u001b[0msub\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mloc\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'healthy'\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtest_pr\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0msub\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mto_csv\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'submission.csv'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mindex\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mFalse\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0msub\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mhead\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mNameError\u001b[0m: name 'model' is not defined"
     ]
    }
   ],
   "source": [
    "# Submission\n",
    "test_pr = model.predict(test, verbose=1)\n",
    "sub.loc[:, 'healthy':] = test_pr\n",
    "sub.to_csv('submission.csv', index=False)\n",
    "sub.head()\n"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}

{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "c01cfaca",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-08-19T03:37:01.103112Z",
     "iopub.status.busy": "2025-08-19T03:37:01.102846Z",
     "iopub.status.idle": "2025-08-19T03:37:01.823530Z",
     "shell.execute_reply": "2025-08-19T03:37:01.823040Z"
    }
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from pathlib import Path"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "027ddcaa",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-08-19T03:37:01.825443Z",
     "iopub.status.busy": "2025-08-19T03:37:01.825183Z",
     "iopub.status.idle": "2025-08-19T03:37:08.199630Z",
     "shell.execute_reply": "2025-08-19T03:37:08.199171Z"
    }
   },
   "outputs": [],
   "source": [
    "import gc\n",
    "import os\n",
    "import sys\n",
    "import time\n",
    "import copy\n",
    "import random\n",
    "import shutil\n",
    "import typing as tp\n",
    "from pathlib import Path\n",
    "from argparse import ArgumentParser\n",
    "\n",
    "import yaml\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from scipy.sparse import coo_matrix\n",
    "from sklearn.metrics import roc_auc_score\n",
    "\n",
    "from tqdm import tqdm\n",
    "from joblib import Parallel, delayed\n",
    "\n",
    "import cv2\n",
    "import albumentations\n",
    "\n",
    "from albumentations.core.transforms_interface import ImageOnlyTransform, DualTransform\n",
    "from albumentations.pytorch import ToTensorV2\n",
    "\n",
    "import torch\n",
    "from torch import nn\n",
    "from torch.utils import data\n",
    "from torchvision import models as torchvision_models\n",
    "\n",
    "sys.path.append('../input/pytorch-image-models/pytorch-image-models-master')\n",
    "import timm\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "3fdc9b35",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-08-19T03:37:08.201386Z",
     "iopub.status.busy": "2025-08-19T03:37:08.201266Z",
     "iopub.status.idle": "2025-08-19T03:37:08.204513Z",
     "shell.execute_reply": "2025-08-19T03:37:08.204234Z"
    }
   },
   "outputs": [],
   "source": [
    "ROOT = Path.cwd().parent\n",
    "INPUT = ROOT / \"input\"\n",
    "OUTPUT = ROOT / \"output\"\n",
    "DATA = INPUT / \"ranzcr-clip-catheter-line-classification\"\n",
    "TRAIN = DATA / \"train\"\n",
    "TEST = DATA / \"test\"\n",
    "\n",
    "\n",
    "TRAINED_MODEL = INPUT / \"ranzcr-clip-weights-for-multi-head-model-v1\"\n",
    "TMP = ROOT / \"tmp\"\n",
    "TMP.mkdir(exist_ok=True)\n",
    "\n",
    "RANDAM_SEED = 1086\n",
    "N_CLASSES = 11\n",
    "FOLDS = [0, 1, 2, 3, 4]\n",
    "N_FOLD = len(FOLDS)\n",
    "IMAGE_SIZE = (640, 640)\n",
    "\n",
    "CONVERT_TO_RANK = True\n",
    "FAST_COMMIT = False\n",
    "\n",
    "CLASSES = [\n",
    "    'ETT - Abnormal',\n",
    "    'ETT - Borderline',\n",
    "    'ETT - Normal',\n",
    "    'NGT - Abnormal',\n",
    "    'NGT - Borderline',\n",
    "    'NGT - Incompletely Imaged',\n",
    "    'NGT - Normal',\n",
    "    'CVC - Abnormal',\n",
    "    'CVC - Borderline',\n",
    "    'CVC - Normal',\n",
    "    'Swan Ganz Catheter Present'\n",
    "]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "f345da32",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-08-19T03:37:08.205896Z",
     "iopub.status.busy": "2025-08-19T03:37:08.205622Z",
     "iopub.status.idle": "2025-08-19T03:37:08.248905Z",
     "shell.execute_reply": "2025-08-19T03:37:08.248580Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train\n",
      "description.md\n",
      "train.csv\n",
      "train.csv.zip\n",
      "train_annotations.csv.zip\n",
      "sample_submission.csv\n",
      "test.zip\n",
      "train_annotations.csv\n",
      "train.zip\n",
      "sample_submission.csv.zip\n",
      "test\n",
      "ranzcr-clip-catheter-line-classification\n"
     ]
    }
   ],
   "source": [
    "for p in DATA.iterdir():\n",
    "    print(p.name)\n",
    "\n",
    "train = pd.read_csv(DATA / \"train.csv\")\n",
    "smpl_sub =  pd.read_csv(DATA / \"sample_submission.csv\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "fddd45d8",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-08-19T03:37:08.250252Z",
     "iopub.status.busy": "2025-08-19T03:37:08.250129Z",
     "iopub.status.idle": "2025-08-19T03:37:08.253975Z",
     "shell.execute_reply": "2025-08-19T03:37:08.253686Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(3009, 10)"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "smpl_sub.shape\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "2aa7586f",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-08-19T03:37:08.255094Z",
     "iopub.status.busy": "2025-08-19T03:37:08.254895Z",
     "iopub.status.idle": "2025-08-19T03:37:08.256899Z",
     "shell.execute_reply": "2025-08-19T03:37:08.256567Z"
    }
   },
   "outputs": [],
   "source": [
    "if FAST_COMMIT and len(smpl_sub) == 3582:\n",
    "    smpl_sub = smpl_sub.iloc[:64 * 3].reset_index(drop=True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "98215a4d",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-08-19T03:37:08.258189Z",
     "iopub.status.busy": "2025-08-19T03:37:08.257982Z",
     "iopub.status.idle": "2025-08-19T03:37:08.263699Z",
     "shell.execute_reply": "2025-08-19T03:37:08.263445Z"
    }
   },
   "outputs": [
    {
     "ename": "SyntaxError",
     "evalue": "invalid syntax (753461029.py, line 54)",
     "output_type": "error",
     "traceback": [
      "\u001b[0;36m  File \u001b[0;32m\"/tmp/ipykernel_8/753461029.py\"\u001b[0;36m, line \u001b[0;32m54\u001b[0m\n\u001b[0;31m    if min_eval is None or fold_eval  min_eval:\u001b[0m\n\u001b[0m                                      ^\u001b[0m\n\u001b[0;31mSyntaxError\u001b[0m\u001b[0;31m:\u001b[0m invalid syntax\n"
     ]
    }
   ],
   "source": [
    "def multi_label_stratified_group_k_fold(label_arr: np.array, gid_arr: np.array, n_fold: int, seed: int=42):\n",
    "    \"\"\"\n",
    "    create multi-label stratified group kfold indexs.\n",
    "\n",
    "    reference: https://www.kaggle.com/jakubwasikowski/stratified-group-k-fold-cross-validation\n",
    "    input:\n",
    "        label_arr: numpy.ndarray, shape = (n_train, n_class)\n",
    "            multi-label for each sample's index using multi-hot vectors\n",
    "        gid_arr: numpy.array, shape = (n_train,)\n",
    "            group id for each sample's index\n",
    "        n_fold: int. number of fold.\n",
    "        seed: random seed.\n",
    "    output:\n",
    "        yield indexs array list for each fold's train and validation.\n",
    "    \"\"\"\n",
    "    np.random.seed(seed)\n",
    "    random.seed(seed)\n",
    "    start_time = time.time()\n",
    "    n_train, n_class = label_arr.shape\n",
    "    gid_unique = sorted(set(gid_arr))\n",
    "    n_group = len(gid_unique)\n",
    "\n",
    "    # # aid_arr: (n_train,), indicates alternative id for group id.\n",
    "    # # generally, group ids are not 0-index and continuous or not integer.\n",
    "    gid2aid = dict(zip(gid_unique, range(n_group)))\n",
    "#     aid2gid = dict(zip(range(n_group), gid_unique))\n",
    "    aid_arr = np.vectorize(lambda x: gid2aid[x])(gid_arr)\n",
    "\n",
    "    # # count labels by class\n",
    "    cnts_by_class = label_arr.sum(axis=0)  # (n_class, )\n",
    "\n",
    "    # # count labels by group id.\n",
    "    col, row = np.array(sorted(enumerate(aid_arr), key=lambda x: x[1])).T\n",
    "    cnts_by_group = coo_matrix(\n",
    "        (np.ones(len(label_arr)), (row, col))\n",
    "    ).dot(coo_matrix(label_arr)).toarray().astype(int)\n",
    "    del col\n",
    "    del row\n",
    "    cnts_by_fold = np.zeros((n_fold, n_class), int)\n",
    "\n",
    "    groups_by_fold = [[] for fid in range(n_fold)]\n",
    "    group_and_cnts = list(enumerate(cnts_by_group))  # pair of aid and cnt by group\n",
    "    np.random.shuffle(group_and_cnts)\n",
    "    print(\"finished preparation\", time.time() - start_time)\n",
    "    for aid, cnt_by_g in sorted(group_and_cnts, key=lambda x: -np.std(x[1])):\n",
    "        best_fold = None\n",
    "        min_eval = None\n",
    "        for fid in range(n_fold):\n",
    "            # # eval assignment.\n",
    "            cnts_by_fold[fid] += cnt_by_g\n",
    "            fold_eval = (cnts_by_fold / cnts_by_class).std(axis=0).mean()\n",
    "            cnts_by_fold[fid] -= cnt_by_g\n",
    "\n",
    "            if min_eval is None or fold_eval  min_eval:\n",
    "                min_eval = fold_eval\n",
    "                best_fold = fid\n",
    "\n",
    "        cnts_by_fold[best_fold] += cnt_by_g\n",
    "        groups_by_fold[best_fold].append(aid)\n",
    "    print(\"finished assignment.\", time.time() - start_time)\n",
    "\n",
    "    gc.collect()\n",
    "    idx_arr = np.arange(n_train)\n",
    "    for fid in range(n_fold):\n",
    "        val_groups = groups_by_fold[fid]\n",
    "\n",
    "        val_indexs_bool = np.isin(aid_arr, val_groups)\n",
    "        train_indexs = idx_arr[~val_indexs_bool]\n",
    "        val_indexs = idx_arr[val_indexs_bool]\n",
    "\n",
    "        print(\"[fold {}]\".format(fid), end=\" \")\n",
    "        print(\"n_group: (train, val) = ({}, {})\".format(n_group - len(val_groups), len(val_groups)), end=\" \")\n",
    "        print(\"n_sample: (train, val) = ({}, {})\".format(len(train_indexs), len(val_indexs)))\n",
    "\n",
    "        yield train_indexs, val_indexs\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "84d34cd5",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-08-19T03:37:08.264855Z",
     "iopub.status.busy": "2025-08-19T03:37:08.264617Z",
     "iopub.status.idle": "2025-08-19T03:37:08.286939Z",
     "shell.execute_reply": "2025-08-19T03:37:08.286673Z"
    }
   },
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'multi_label_stratified_group_k_fold' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m/tmp/ipykernel_8/1342596084.py\u001b[0m in \u001b[0;36m<cell line: 0>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m train_val_indexs = list(\n\u001b[0;32m----> 5\u001b[0;31m     multi_label_stratified_group_k_fold(label_arr, group_id, N_FOLD, RANDAM_SEED))\n\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m: name 'multi_label_stratified_group_k_fold' is not defined"
     ]
    }
   ],
   "source": [
    "label_arr = train[CLASSES].values\n",
    "group_id = train.PatientID.values\n",
    "\n",
    "train_val_indexs = list(\n",
    "    multi_label_stratified_group_k_fold(label_arr, group_id, N_FOLD, RANDAM_SEED))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "7d95ceb0",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-08-19T03:37:08.288151Z",
     "iopub.status.busy": "2025-08-19T03:37:08.287946Z",
     "iopub.status.idle": "2025-08-19T03:37:08.293920Z",
     "shell.execute_reply": "2025-08-19T03:37:08.293662Z"
    }
   },
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'train_val_indexs' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m/tmp/ipykernel_8/2076788479.py\u001b[0m in \u001b[0;36m<cell line: 0>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0mtrain\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m\"fold\"\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m-\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 2\u001b[0;31m \u001b[0;32mfor\u001b[0m \u001b[0mfold_id\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mtrn_idx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mval_idx\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32min\u001b[0m \u001b[0menumerate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtrain_val_indexs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      3\u001b[0m     \u001b[0mtrain\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mloc\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mval_idx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\"fold\"\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mfold_id\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0mtrain\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mgroupby\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"fold\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mCLASSES\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msum\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mNameError\u001b[0m: name 'train_val_indexs' is not defined"
     ]
    }
   ],
   "source": [
    "train[\"fold\"] = -1\n",
    "for fold_id, (trn_idx, val_idx) in enumerate(train_val_indexs):\n",
    "    train.loc[val_idx, \"fold\"] = fold_id\n",
    "    \n",
    "train.groupby(\"fold\")[CLASSES].sum()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "051e0cb9",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-08-19T03:37:08.295087Z",
     "iopub.status.busy": "2025-08-19T03:37:08.294916Z",
     "iopub.status.idle": "2025-08-19T03:38:34.777369Z",
     "shell.execute_reply": "2025-08-19T03:38:34.776623Z"
    }
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=2)]: Using backend LokyBackend with 2 concurrent workers.\n",
      "[Parallel(n_jobs=2)]: Done   16 out of 3009 | elapsed:    0.8s\n",
      "[Parallel(n_jobs=2)]: Done  228 out of 3009 | elapsed:    6.8s\n",
      "[Parallel(n_jobs=2)]: Done  588 out of 3009 | elapsed:   17.4s\n",
      "[Parallel(n_jobs=2)]: Done 1092 out of 3009 | elapsed:   31.9s\n",
      "[Parallel(n_jobs=2)]: Done 1740 out of 3009 | elapsed:   49.8s\n",
      "[Parallel(n_jobs=2)]: Done 2532 out of 3009 | elapsed:  1.2min\n",
      "[Parallel(n_jobs=2)]: Done 3009 out of 3009 | elapsed:  1.4min finished\n"
     ]
    }
   ],
   "source": [
    "def resize_images(img_id, input_dir, output_dir, resize_to=(512, 512), ext=\"png\"):\n",
    "    img_path = input_dir / f\"{img_id}.jpg\"\n",
    "    save_path = output_dir / f\"{img_id}.{ext}\"\n",
    "    \n",
    "    img = cv2.imread(str(img_path), cv2.IMREAD_GRAYSCALE)\n",
    "    img = cv2.resize(img, resize_to)\n",
    "    cv2.imwrite(str(save_path), img, )\n",
    "\n",
    "TEST_RESIZED = TMP / \"test_{0}x{1}\".format(*IMAGE_SIZE)\n",
    "TEST_RESIZED.mkdir(exist_ok=True)\n",
    "TEST_RESIZED\n",
    "\n",
    "_ = Parallel(n_jobs=2, verbose=5)([\n",
    "    delayed(resize_images)(img_id, TEST, TEST_RESIZED, IMAGE_SIZE, \"png\")\n",
    "    for img_id in smpl_sub.StudyInstanceUID.values\n",
    "])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "f1c6092a",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-08-19T03:38:34.780936Z",
     "iopub.status.busy": "2025-08-19T03:38:34.780152Z",
     "iopub.status.idle": "2025-08-19T03:38:34.796542Z",
     "shell.execute_reply": "2025-08-19T03:38:34.795740Z"
    }
   },
   "outputs": [],
   "source": [
    "def get_activation(activ_name: str=\"relu\"):\n",
    "    \"\"\"\"\"\"\n",
    "    act_dict = {\n",
    "        \"relu\": nn.ReLU(inplace=True),\n",
    "        \"tanh\": nn.Tanh(),\n",
    "        \"sigmoid\": nn.Sigmoid(),\n",
    "        \"identity\": nn.Identity()}\n",
    "    if activ_name in act_dict:\n",
    "        return act_dict[activ_name]\n",
    "    else:\n",
    "        raise NotImplementedError\n",
    "        \n",
    "\n",
    "class Conv2dBNActiv(nn.Module):\n",
    "    \"\"\"Conv2d -> (BN ->) -> Activation\"\"\"\n",
    "    \n",
    "    def __init__(\n",
    "        self, in_channels: int, out_channels: int,\n",
    "        kernel_size: int, stride: int=1, padding: int=0,\n",
    "        bias: bool=False, use_bn: bool=True, activ: str=\"relu\"\n",
    "    ):\n",
    "        \"\"\"\"\"\"\n",
    "        super(Conv2dBNActiv, self).__init__()\n",
    "        layers = []\n",
    "        layers.append(nn.Conv2d(\n",
    "            in_channels, out_channels,\n",
    "            kernel_size, stride, padding, bias=bias))\n",
    "        if use_bn:\n",
    "            layers.append(nn.BatchNorm2d(out_channels))\n",
    "            \n",
    "        layers.append(get_activation(activ))\n",
    "        self.layers = nn.Sequential(*layers)\n",
    "        \n",
    "    def forward(self, x):\n",
    "        \"\"\"Forward\"\"\"\n",
    "        return self.layers(x)\n",
    "        \n",
    "\n",
    "class SSEBlock(nn.Module):\n",
    "    \"\"\"channel `S`queeze and `s`patial `E`xcitation Block.\"\"\"\n",
    "\n",
    "    def __init__(self, in_channels: int):\n",
    "        \"\"\"Initialize.\"\"\"\n",
    "        super(SSEBlock, self).__init__()\n",
    "        self.channel_squeeze = nn.Conv2d(\n",
    "            in_channels=in_channels, out_channels=1,\n",
    "            kernel_size=1, stride=1, padding=0, bias=False)\n",
    "        self.sigmoid = nn.Sigmoid()\n",
    "\n",
    "    def forward(self, x):\n",
    "        \"\"\"Forward.\"\"\"\n",
    "        # # x: (bs, ch, h, w) => h: (bs, 1, h, w)\n",
    "        h = self.sigmoid(self.channel_squeeze(x))\n",
    "        # # x, h => return: (bs, ch, h, w)\n",
    "        return x * h\n",
    "    \n",
    "    \n",
    "class SpatialAttentionBlock(nn.Module):\n",
    "    \"\"\"Spatial Attention for (C, H, W) feature maps\"\"\"\n",
    "    \n",
    "    def __init__(\n",
    "        self, in_channels: int,\n",
    "        out_channels_list: tp.List[int],\n",
    "    ):\n",
    "        \"\"\"Initialize\"\"\"\n",
    "        super(SpatialAttentionBlock, self).__init__()\n",
    "        self.n_layers = len(out_channels_list)\n",
    "        channels_list = [in_channels] + out_channels_list\n",
    "        assert self.n_layers > 0\n",
    "        assert channels_list[-1] == 1\n",
    "        \n",
    "        for i in range(self.n_layers - 1):\n",
    "            in_chs, out_chs = channels_list[i: i + 2]\n",
    "            layer = Conv2dBNActiv(in_chs, out_chs, 3, 1, 1, activ=\"relu\")\n",
    "            setattr(self, f\"conv{i + 1}\", layer)\n",
    "            \n",
    "        in_chs, out_chs = channels_list[-2:]\n",
    "        layer = Conv2dBNActiv(in_chs, out_chs, 3, 1, 1, activ=\"sigmoid\")\n",
    "        setattr(self, f\"conv{self.n_layers}\", layer)\n",
    "    \n",
    "    def forward(self, x):\n",
    "        \"\"\"Forward\"\"\"\n",
    "        h = x\n",
    "        for i in range(self.n_layers):\n",
    "            h = getattr(self, f\"conv{i + 1}\")(h)\n",
    "            \n",
    "        h = h * x\n",
    "        return h\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "a5a7f852",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-08-19T03:38:34.799810Z",
     "iopub.status.busy": "2025-08-19T03:38:34.799026Z",
     "iopub.status.idle": "2025-08-19T03:38:34.811776Z",
     "shell.execute_reply": "2025-08-19T03:38:34.811050Z"
    }
   },
   "outputs": [],
   "source": [
    "class SingleHeadModel(nn.Module):\n",
    "    \n",
    "    def __init__(\n",
    "        self, base_name: str='resnext50_32x4d', out_dim: int=11, pretrained=False\n",
    "    ):\n",
    "        \"\"\"\"\"\"\n",
    "        self.base_name = base_name\n",
    "        super(SingleHeadModel, self).__init__()\n",
    "        \n",
    "        # # load base model\n",
    "        base_model = timm.create_model(base_name, pretrained=pretrained)\n",
    "        in_features = base_model.num_features\n",
    "        \n",
    "        # # remove global pooling and head classifier\n",
    "        # base_model.reset_classifier(0, '')\n",
    "        base_model.reset_classifier(0)\n",
    "        \n",
    "        # # Shared CNN Bacbone\n",
    "        self.backbone = base_model\n",
    "        \n",
    "        # # Single Heads.\n",
    "        self.head_fc = nn.Sequential(\n",
    "            nn.Linear(in_features, in_features),\n",
    "            nn.ReLU(inplace=True),\n",
    "            nn.Dropout(0.5),\n",
    "            nn.Linear(in_features, out_dim))\n",
    "\n",
    "    def forward(self, x):\n",
    "        \"\"\"\"\"\"\n",
    "        h = self.backbone(x)\n",
    "        h = self.head_fc(h)\n",
    "        return h\n",
    "        \n",
    "\n",
    "class MultiHeadModel(nn.Module):\n",
    "    \n",
    "    def __init__(\n",
    "        self, base_name: str='resnext50_32x4d',\n",
    "        out_dims_head: tp.List[int]=[3, 4, 3, 1], pretrained=False):\n",
    "        \"\"\"\"\"\"\n",
    "        self.base_name = base_name\n",
    "        self.n_heads = len(out_dims_head)\n",
    "        super(MultiHeadModel, self).__init__()\n",
    "        \n",
    "        # # load base model\n",
    "        base_model = timm.create_model(base_name, pretrained=pretrained)\n",
    "        in_features = base_model.num_features\n",
    "        \n",
    "        # # remove global pooling and head classifier\n",
    "        base_model.reset_classifier(0, '')\n",
    "        \n",
    "        # # Shared CNN Bacbone\n",
    "        self.backbone = base_model\n",
    "        \n",
    "        # # Multi Heads.\n",
    "        for i, out_dim in enumerate(out_dims_head):\n",
    "            layer_name = f\"head_{i}\"\n",
    "            layer = nn.Sequential(\n",
    "                SpatialAttentionBlock(in_features, [64, 32, 16, 1]),\n",
    "                nn.AdaptiveAvgPool2d(output_size=1),\n",
    "                nn.Flatten(start_dim=1),\n",
    "                nn.Linear(in_features, in_features),\n",
    "                nn.ReLU(inplace=True),\n",
    "                nn.Dropout(0.5),\n",
    "                nn.Linear(in_features, out_dim))\n",
    "            setattr(self, layer_name, layer)\n",
    "\n",
    "    def forward(self, x):\n",
    "        \"\"\"\"\"\"\n",
    "        h = self.backbone(x)\n",
    "        hs = [\n",
    "            getattr(self, f\"head_{i}\")(h) for i in range(self.n_heads)]\n",
    "        y = torch.cat(hs, axis=1)\n",
    "        return y\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "f9684822",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-08-19T03:38:34.814733Z",
     "iopub.status.busy": "2025-08-19T03:38:34.814266Z",
     "iopub.status.idle": "2025-08-19T03:38:34.821908Z",
     "shell.execute_reply": "2025-08-19T03:38:34.821223Z"
    }
   },
   "outputs": [],
   "source": [
    "class LabeledImageDataset(data.Dataset):\n",
    "    \"\"\"\n",
    "    Dataset class for (image, label) pairs\n",
    "\n",
    "    reads images and applys transforms to them.\n",
    "\n",
    "    Attributes\n",
    "    ----------\n",
    "    file_list : List[Tuple[tp.Union[str, Path], tp.Union[int, float, np.ndarray]]]\n",
    "        list of (image file, label) pair\n",
    "    transform_list : List[Dict]\n",
    "        list of dict representing image transform \n",
    "    \"\"\"\n",
    "\n",
    "    def __init__(\n",
    "        self,\n",
    "        file_list: tp.List[\n",
    "            tp.Tuple[tp.Union[str, Path], tp.Union[int, float, np.ndarray]]],\n",
    "        transform_list: tp.List[tp.Dict],\n",
    "    ):\n",
    "        \"\"\"Initialize\"\"\"\n",
    "        self.file_list = file_list\n",
    "        self.transform = ImageTransformForCls(transform_list)\n",
    "\n",
    "    def __len__(self):\n",
    "        \"\"\"Return Num of Images.\"\"\"\n",
    "        return len(self.file_list)\n",
    "\n",
    "    def __getitem__(self, index):\n",
    "        \"\"\"Return transformed image and mask for given index.\"\"\"\n",
    "        img_path, label = self.file_list[index]\n",
    "        img = self._read_image_as_array(img_path)\n",
    "        \n",
    "        img, label = self.transform((img, label))\n",
    "        return img, label\n",
    "\n",
    "    def _read_image_as_array(self, path: str):\n",
    "        \"\"\"Read image file and convert into numpy.ndarray\"\"\"\n",
    "        img_arr = cv2.imread(str(path))\n",
    "        img_arr = cv2.cvtColor(img_arr, cv2.COLOR_BGR2RGB)\n",
    "        return img_arr\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "705319ce",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-08-19T03:38:34.824530Z",
     "iopub.status.busy": "2025-08-19T03:38:34.824077Z",
     "iopub.status.idle": "2025-08-19T03:38:34.829446Z",
     "shell.execute_reply": "2025-08-19T03:38:34.828786Z"
    }
   },
   "outputs": [],
   "source": [
    "def get_dataloaders_for_inference(\n",
    "    file_list: tp.List[tp.List], batch_size=64,\n",
    "):\n",
    "    \"\"\"Create DataLoader\"\"\"\n",
    "    dataset = LabeledImageDataset(\n",
    "        file_list,\n",
    "        transform_list=[\n",
    "          [\"Normalize\", {\n",
    "              \"always_apply\": True, \"max_pixel_value\": 255.0,\n",
    "              \"mean\": [\"0.4887381077884414\"], \"std\": [\"0.23064819430546407\"]}],\n",
    "          [\"ToTensorV2\", {\"always_apply\": True}],\n",
    "        ])\n",
    "    loader = data.DataLoader(\n",
    "        dataset,\n",
    "        batch_size=batch_size, shuffle=False,\n",
    "        num_workers=2, pin_memory=True,\n",
    "        drop_last=False)\n",
    "\n",
    "    return loader\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "e321a507",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-08-19T03:38:34.832023Z",
     "iopub.status.busy": "2025-08-19T03:38:34.831590Z",
     "iopub.status.idle": "2025-08-19T03:38:34.840614Z",
     "shell.execute_reply": "2025-08-19T03:38:34.839823Z"
    }
   },
   "outputs": [],
   "source": [
    "class ImageTransformBase:\n",
    "    \"\"\"\n",
    "    Base Image Transform class.\n",
    "\n",
    "    Args:\n",
    "        data_augmentations: List of tuple(method: str, params :dict), each elems pass to albumentations\n",
    "    \"\"\"\n",
    "\n",
    "    def __init__(self, data_augmentations: tp.List[tp.Tuple[str, tp.Dict]]):\n",
    "        \"\"\"Initialize.\"\"\"\n",
    "        augmentations_list = [\n",
    "            self._get_augmentation(aug_name)(**params)\n",
    "            for aug_name, params in data_augmentations]\n",
    "        self.data_aug = albumentations.Compose(augmentations_list)\n",
    "\n",
    "    def __call__(self, pair: tp.Tuple[np.ndarray]) -> tp.Tuple[np.ndarray]:\n",
    "        \"\"\"You have to implement this by task\"\"\"\n",
    "        raise NotImplementedError\n",
    "\n",
    "    def _get_augmentation(self, aug_name: str) -> tp.Tuple[ImageOnlyTransform, DualTransform]:\n",
    "        \"\"\"Get augmentations from albumentations\"\"\"\n",
    "        if hasattr(albumentations, aug_name):\n",
    "            return getattr(albumentations, aug_name)\n",
    "        else:\n",
    "            return eval(aug_name)\n",
    "\n",
    "\n",
    "class ImageTransformForCls(ImageTransformBase):\n",
    "    \"\"\"Data Augmentor for Classification Task.\"\"\"\n",
    "\n",
    "    def __init__(self, data_augmentations: tp.List[tp.Tuple[str, tp.Dict]]):\n",
    "        \"\"\"Initialize.\"\"\"\n",
    "        super(ImageTransformForCls, self).__init__(data_augmentations)\n",
    "\n",
    "    def __call__(self, in_arrs: tp.Tuple[np.ndarray]) -> tp.Tuple[np.ndarray]:\n",
    "        \"\"\"Apply Transform.\"\"\"\n",
    "        img, label = in_arrs\n",
    "        augmented = self.data_aug(image=img)\n",
    "        img = augmented[\"image\"]\n",
    "\n",
    "        return img, label\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "a857751e",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-08-19T03:38:34.843534Z",
     "iopub.status.busy": "2025-08-19T03:38:34.843087Z",
     "iopub.status.idle": "2025-08-19T03:38:34.850448Z",
     "shell.execute_reply": "2025-08-19T03:38:34.849739Z"
    }
   },
   "outputs": [],
   "source": [
    "def load_setting_file(path: str):\n",
    "    \"\"\"Load YAML setting file.\"\"\"\n",
    "    with open(path) as f:\n",
    "        settings = yaml.safe_load(f)\n",
    "    return settings\n",
    "\n",
    "\n",
    "def set_random_seed(seed: int = 42, deterministic: bool = False):\n",
    "    \"\"\"Set seeds\"\"\"\n",
    "    random.seed(seed)\n",
    "    np.random.seed(seed)\n",
    "    os.environ[\"PYTHONHASHSEED\"] = str(seed)\n",
    "    torch.manual_seed(seed)\n",
    "    torch.cuda.manual_seed(seed)  # type: ignore\n",
    "    torch.backends.cudnn.deterministic = deterministic  # type: ignore\n",
    "    \n",
    "\n",
    "def run_inference_loop(stgs, model, loader, device):\n",
    "    model.to(device)\n",
    "    model.eval()\n",
    "    pred_list = []\n",
    "    with torch.no_grad():\n",
    "        for x, t in tqdm(loader):\n",
    "            y = model(x.to(device))\n",
    "            pred_list.append(y.sigmoid().detach().cpu().numpy())\n",
    "            # pred_list.append(y.detach().cpu().numpy())\n",
    "        \n",
    "    pred_arr = np.concatenate(pred_list)\n",
    "    del pred_list\n",
    "    return pred_arr\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "ad45fc5a",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-08-19T03:38:34.853250Z",
     "iopub.status.busy": "2025-08-19T03:38:34.852809Z",
     "iopub.status.idle": "2025-08-19T03:38:34.858044Z",
     "shell.execute_reply": "2025-08-19T03:38:34.857356Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "cpu\n"
     ]
    }
   ],
   "source": [
    "if not torch.cuda.is_available():\n",
    "    device = torch.device(\"cpu\")\n",
    "else:\n",
    "    device = torch.device(\"cuda\")\n",
    "print(device)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "cf9527ee",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-08-19T03:38:34.860776Z",
     "iopub.status.busy": "2025-08-19T03:38:34.860335Z",
     "iopub.status.idle": "2025-08-19T03:38:34.925901Z",
     "shell.execute_reply": "2025-08-19T03:38:34.925379Z"
    }
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_8/2782210807.py:12: UserWarning: Argument(s) 'always_apply' are not valid for transform Normalize\n",
      "  self._get_augmentation(aug_name)(**params)\n"
     ]
    },
    {
     "ename": "TypeError",
     "evalue": "ToTensorV2.__init__() got an unexpected keyword argument 'always_apply'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m/tmp/ipykernel_8/261766260.py\u001b[0m in \u001b[0;36m<cell line: 0>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      5\u001b[0m     \u001b[0;34m(\u001b[0m\u001b[0mtest_dir\u001b[0m \u001b[0;34m/\u001b[0m \u001b[0;34mf\"{img_id}.png\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m*\u001b[0m \u001b[0;36m11\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      6\u001b[0m     for img_id in smpl_sub[\"StudyInstanceUID\"].values]\n\u001b[0;32m----> 7\u001b[0;31m \u001b[0mtest_loader\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mget_dataloaders_for_inference\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtest_file_list\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbatch_size\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m64\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      8\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      9\u001b[0m \u001b[0mtest_preds_arr\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mzeros\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mN_FOLD\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msmpl_sub\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mN_CLASSES\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/tmp/ipykernel_8/1376822920.py\u001b[0m in \u001b[0;36mget_dataloaders_for_inference\u001b[0;34m(file_list, batch_size)\u001b[0m\n\u001b[1;32m      3\u001b[0m ):\n\u001b[1;32m      4\u001b[0m     \u001b[0;34m\"\"\"Create DataLoader\"\"\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 5\u001b[0;31m     dataset = LabeledImageDataset(\n\u001b[0m\u001b[1;32m      6\u001b[0m         \u001b[0mfile_list\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      7\u001b[0m         transform_list=[\n",
      "\u001b[0;32m/tmp/ipykernel_8/2462526932.py\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self, file_list, transform_list)\u001b[0m\n\u001b[1;32m     21\u001b[0m         \u001b[0;34m\"\"\"Initialize\"\"\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     22\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfile_list\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mfile_list\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 23\u001b[0;31m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtransform\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mImageTransformForCls\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtransform_list\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     24\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     25\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m__len__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/tmp/ipykernel_8/2782210807.py\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self, data_augmentations)\u001b[0m\n\u001b[1;32m     31\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m__init__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdata_augmentations\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mtp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mList\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mtp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mTuple\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mstr\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mDict\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     32\u001b[0m         \u001b[0;34m\"\"\"Initialize.\"\"\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 33\u001b[0;31m         \u001b[0msuper\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mImageTransformForCls\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__init__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdata_augmentations\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     34\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     35\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m__call__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0min_arrs\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mtp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mTuple\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mndarray\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m->\u001b[0m \u001b[0mtp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mTuple\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mndarray\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/tmp/ipykernel_8/2782210807.py\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self, data_augmentations)\u001b[0m\n\u001b[1;32m      9\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m__init__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdata_augmentations\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mtp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mList\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mtp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mTuple\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mstr\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mDict\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     10\u001b[0m         \u001b[0;34m\"\"\"Initialize.\"\"\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 11\u001b[0;31m         augmentations_list = [\n\u001b[0m\u001b[1;32m     12\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_get_augmentation\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0maug_name\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m**\u001b[0m\u001b[0mparams\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     13\u001b[0m             for aug_name, params in data_augmentations]\n",
      "\u001b[0;32m/tmp/ipykernel_8/2782210807.py\u001b[0m in \u001b[0;36m<listcomp>\u001b[0;34m(.0)\u001b[0m\n\u001b[1;32m     10\u001b[0m         \u001b[0;34m\"\"\"Initialize.\"\"\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     11\u001b[0m         augmentations_list = [\n\u001b[0;32m---> 12\u001b[0;31m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_get_augmentation\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0maug_name\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m**\u001b[0m\u001b[0mparams\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     13\u001b[0m             for aug_name, params in data_augmentations]\n\u001b[1;32m     14\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdata_aug\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0malbumentations\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mCompose\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0maugmentations_list\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mTypeError\u001b[0m: ToTensorV2.__init__() got an unexpected keyword argument 'always_apply'"
     ]
    }
   ],
   "source": [
    "model_dir = TRAINED_MODEL\n",
    "test_dir = TEST_RESIZED\n",
    "\n",
    "test_file_list = [\n",
    "    (test_dir / f\"{img_id}.png\", [-1] * 11)\n",
    "    for img_id in smpl_sub[\"StudyInstanceUID\"].values]\n",
    "test_loader = get_dataloaders_for_inference(test_file_list, batch_size=64)\n",
    "        \n",
    "test_preds_arr = np.zeros((N_FOLD, len(smpl_sub), N_CLASSES))    \n",
    "for fold_id in FOLDS:\n",
    "    print(f\"[fold {fold_id}]\")\n",
    "    stgs = load_setting_file(model_dir / f\"fold{fold_id}\" / \"settings.yml\")\n",
    "    # # prepare \n",
    "    stgs[\"model\"][\"params\"][\"pretrained\"] = False\n",
    "    model = MultiHeadModel(**stgs[\"model\"][\"params\"])\n",
    "    model_path = model_dir / f\"best_model_fold{fold_id}.pth\"\n",
    "    model.load_state_dict(torch.load(model_path, map_location=device))\n",
    "\n",
    "    # # inference test\n",
    "    test_pred = run_inference_loop(stgs, model, test_loader, device)\n",
    "    test_preds_arr[fold_id] = test_pred\n",
    "    \n",
    "    del model\n",
    "    torch.cuda.empty_cache()\n",
    "    gc.collect()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "36bbe9a7",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-08-19T03:38:34.928031Z",
     "iopub.status.busy": "2025-08-19T03:38:34.927723Z",
     "iopub.status.idle": "2025-08-19T03:38:34.937218Z",
     "shell.execute_reply": "2025-08-19T03:38:34.936658Z"
    }
   },
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'test_preds_arr' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m/tmp/ipykernel_8/1393381549.py\u001b[0m in \u001b[0;36m<cell line: 0>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;32mif\u001b[0m \u001b[0mCONVERT_TO_RANK\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      2\u001b[0m     \u001b[0;31m# # shape: (fold, n_example, class)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 3\u001b[0;31m     \u001b[0mtest_preds_arr\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtest_preds_arr\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0margsort\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0maxis\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0margsort\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0maxis\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      4\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0msub\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0msmpl_sub\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcopy\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mNameError\u001b[0m: name 'test_preds_arr' is not defined"
     ]
    }
   ],
   "source": [
    "if CONVERT_TO_RANK:\n",
    "    # # shape: (fold, n_example, class)\n",
    "    test_preds_arr = test_preds_arr.argsort(axis=1).argsort(axis=1)\n",
    "\n",
    "sub = smpl_sub.copy()\n",
    "sub[CLASSES] = test_preds_arr.mean(axis=0)\n",
    "    \n",
    "sub.to_csv(\"submission.csv\", index=False)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "2858a236",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-08-19T03:38:34.939424Z",
     "iopub.status.busy": "2025-08-19T03:38:34.939021Z",
     "iopub.status.idle": "2025-08-19T03:38:34.948222Z",
     "shell.execute_reply": "2025-08-19T03:38:34.947700Z"
    }
   },
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'sub' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m/tmp/ipykernel_8/1894231914.py\u001b[0m in \u001b[0;36m<cell line: 0>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0msub\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mhead\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m: name 'sub' is not defined"
     ]
    }
   ],
   "source": [
    "sub.head()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3d5c7643",
   "metadata": {},
   "outputs": [],
   "source": [
    " \n"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
